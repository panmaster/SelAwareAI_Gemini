## Summary of Files and Directories in 'C:\Users\DELL\Desktop\selfawareGemini\SelAwareAI_Gemini\PROJECT16'


Subdirectory: Brain_settings
## Summary of Files and Directories in 'C:\Users\DELL\Desktop\selfawareGemini\SelAwareAI_Gemini\PROJECT16\Brain_settings'

File: emotions.json (C:\Users\DELL\Desktop\selfawareGemini\SelAwareAI_Gemini\PROJECT16\Brain_settings\emotions.json)
Content (First 13 lines):
{
  "happiness": 95,
  "sadness": 1,
  "anger": 0,
  "fear": 0,
  "surprise": 0,
  "disgust": 0,
  "motivation": 100,
  "focus": 100,
  "love": 0,
  "gratitude": 10,
  "contentment": 80
}


Subdirectory: focusTables
## Summary of Files and Directories in 'C:\Users\DELL\Desktop\selfawareGemini\SelAwareAI_Gemini\PROJECT16\Brain_settings\focusTables'

File: focus.json (C:\Users\DELL\Desktop\selfawareGemini\SelAwareAI_Gemini\PROJECT16\Brain_settings\focusTables\focus.json)
Content (First 77 lines):
[
  {
    "name": "Analyze code and identify areas for improvement",
    "focus_type": "empty",
    "moscow_category": "...",
    "importance": 0,
    "difficulty": 0,
    "reward": 0,
    "total_work": 0.0,
    "proposed_action": ".....",
    "cost_per_run": 1.0,
    "work_done": 0.0,
    "focus_strength": 0.0,
    "frustration": 0.0,
    "fatigue": 0.0,
    "accumulated_cost": 0.0,
    "status": "NOT_COMPLETED",
    "learned_knowledge": "",
    "important_facts": "",
    "current_focus": false,
    "goal": "",
    "dependencies": [],
    "deadline": null,
    "calculated_score": 0.0,
    "last_focused": null
  },
  {
    "name": "....",
    "focus_type": "....",
    "moscow_category": "....",
    "importance": 0,
    "difficulty": 0,
    "reward": 0,
    "total_work": 0.0,
    "proposed_action": ".....",
    "cost_per_run": 0.0,
    "work_done": 0.0,
    "focus_strength": 0.0,
    "frustration": 0.0,
    "fatigue": 0.0,
    "accumulated_cost": 0.0,
    "status": "NOT_COMPLETED",
    "learned_knowledge": "",
    "important_facts": "",
    "current_focus": false,
    "goal": "",
    "dependencies": [],
    "deadline": null,
    "calculated_score": 0.0,
    "last_focused": null
  },
  {
    "name": "...",
    "focus_type": "...",
    "moscow_category": "...",
    "importance": 0,
    "difficulty": 0,
    "reward": 0,
    "total_work": 0.0,
    "proposed_action": "....",
    "cost_per_run": 0.0,
    "work_done": 0.0,
    "focus_strength": 0.0,
    "frustration": 0.0,
    "fatigue": 0.0,
    "accumulated_cost": 0.0,
    "status": "NOT_COMPLETED",
    "learned_knowledge": "",
    "important_facts": "",
    "current_focus": false,
    "goal": "",
    "dependencies": [],
    "deadline": null,
    "calculated_score": 0.0,
    "last_focused": null
  }
]

File: prompts.json (C:\Users\DELL\Desktop\selfawareGemini\SelAwareAI_Gemini\PROJECT16\Brain_settings\prompts.json)
Content (First 7 lines):
{
    "input": "Analyze current inputs, state, and emotions. What's the most important aspect to focus on? You can call the 'retrieve_memories' function to access past relevant memories. Provide your response in the following format:\nFocusOn: [identified focus]\nFocusLevel: [a float between 0 and 1]\n\nAfter identifying the focus, use the UpdateFocus tool to add or update the focus point.",
    "reflection": "Reflect on recent actions, outcomes, and emotional states. What insights can be drawn? Consider potential improvements or adjustments to behavior and decision-making. You can also call the 'retrieve_memories' function to access relevant memories. Format your response to be clear and structured, highlighting key observations and recommendations. If necessary, use the UpdateFocus tool to adjust the current focus or add new focus points.",
    "action": "Based on current focus, reflections, and emotional state, what's the optimal next action?",
    "emotion": "Based on recent events and outcomes, how should my emotional state be adjusted?",
    "learning": "What new knowledge or skills should be prioritized for long-term improvement?",
}

File: State_of_mind.json (C:\Users\DELL\Desktop\selfawareGemini\SelAwareAI_Gemini\PROJECT16\Brain_settings\State_of_mind.json)
Content (First 14 lines):
{
    "FocusOn": " ",
    "FocusLevel": 0,
    "Defocus": " ",
    "FrustrationLevel": 0,
    "CurrentCostOfProgress": 0,
    "Short_term_goals": [

    ],
    "Long_term_goals": [

    ],
    "Accomplished": []
}

File: brain_settings.py (C:\Users\DELL\Desktop\selfawareGemini\SelAwareAI_Gemini\PROJECT16\brain_settings.py)
Content (First 76 lines):
#brain_settings.py
import os
import json

# Constants for file paths (adjust as needed)
PROMPTS_FILE = "Brain_settings/prompts.json"
EMOTIONS_FILE = "Brain_settings/emotions.json"
FOCUS_FILE = "Brain_settings/Focus.json"


def load_json(file_path):
    """Loads a JSON file and returns the data as a dictionary."""
    try:
        with open(file_path, 'r') as f:
            return json.load(f)
    except FileNotFoundError:
        print(f"Warning: File not found: {file_path}")
        return {}


def save_json(file_path, data):
    """Saves data to a JSON file."""
    with open(file_path, 'w') as f:
        json.dump(data, f, indent=2)


def load_prompts():
    """Loads prompts from the prompts.json file."""
    return load_json(PROMPTS_FILE)


def save_prompts(prompts):
    """Saves prompts to the prompts.json file."""
    save_json(PROMPTS_FILE, prompts)


def load_emotions():
    """Loads emotions from the emotions.json file."""
    return load_json(EMOTIONS_FILE)


def save_emotions(emotions):
    """Saves emotions to the emotions.json file."""
    save_json(EMOTIONS_FILE, emotions)


def load_state_of_mind():
    """Loads the state of mind from the Focus.json file."""
    return load_json(FOCUS_FILE)


def save_state_of_mind(state_of_mind):
    """Saves the state of mind to the Focus.json file."""
    save_json(FOCUS_FILE, state_of_mind)


def update_attachment(emotions, entity, value):
    """Updates the attachment value for a given entity."""
    if entity not in emotions["attachment"]:
        emotions["attachment"][entity] = 0
    emotions["attachment"][entity] += value
    emotions["attachment"][entity] = max(0, min(100, emotions["attachment"][entity]))
    return emotions


def get_focus_data():
    """Loads and returns focus data from the Focus.json file."""
    return load_state_of_mind()


def set_focus(focus_on):
    """Sets the focus in the Focus.json file."""
    state_of_mind = load_state_of_mind()
    state_of_mind["FocusOn"] = focus_on
    save_state_of_mind(state_of_mind)
    return f"Focus set to: {focus_on}"

File: FocusManager.py (C:\Users\DELL\Desktop\selfawareGemini\SelAwareAI_Gemini\PROJECT16\FocusManager.py)
Content (First 428 lines):
#FocusManager.py
import json
import datetime
import  os
from typing import List, Optional, Dict  , Any
from prettytable import PrettyTable  # Import PrettyTable

class Task:
    def __init__(self, name: str, focus_type: str, moscow_category: str, importance: int,
                 difficulty: int, reward: int, total_work: float, proposed_action: str,
                 cost_per_run: float, work_done: float = 0.0, focus_strength: float = 0.0,
                 frustration: float = 0.0, fatigue: float = 0.0, accumulated_cost: float = 0.0,
                 status: str = "NOT_COMPLETED", learned_knowledge: str = "",
                 important_facts: str = "", current_focus: bool = False, goal: str = "",
                 dependencies: List[str] = [], deadline: str = None, calculated_score: float = 0.0,
                 last_focused: datetime.datetime = None):

        self.name = name
        self.focus_type = focus_type
        self.moscow_category = moscow_category
        self.importance = importance
        self.difficulty = difficulty
        self.reward = reward
        self.total_work = total_work
        self.proposed_action = proposed_action
        self.cost_per_run = cost_per_run
        self.work_done = work_done
        self.focus_strength = focus_strength
        self.frustration = frustration
        self.fatigue = fatigue
        self.accumulated_cost = accumulated_cost
        self.status = status
        self.learned_knowledge = learned_knowledge
        self.important_facts = important_facts
        self.current_focus = current_focus
        self.goal = goal
        self.dependencies = dependencies
        self.deadline = deadline
        self.calculated_score = calculated_score
        self.last_focused = last_focused


class FocusManager:
    def __init__(self, file_path: str = "Brain_settings/focusTables/focus.json"):
        """
        Initializes the FocusManager, creating 'focus.json' if it doesn't exist.
        """
        self.file_path = file_path

        # Check if the focus file exists, and create it if it doesn't
        if not os.path.exists(self.file_path):
            print(f"Error: File '{self.file_path}' not found. Creating a new focus table.")
            self.create_base_focus_table()

        # Now load the focus table (which should exist now)
        self.focus_table: List[Task] = self.load_focus_table()
        self.last_focus_type = None
        self.consecutive_difficult_tasks = 0

    # FocusManager.py
    import json
    import datetime
    import os
    from typing import List, Optional, Dict, Any
    from prettytable import PrettyTable  # Import PrettyTable

    class Task:
        def __init__(self, name: str, focus_type: str, moscow_category: str, importance: int,
                     difficulty: int, reward: int, total_work: float, proposed_action: str,
                     cost_per_run: float, work_done: float = 0.0, focus_strength: float = 0.0,
                     frustration: float = 0.0, fatigue: float = 0.0, accumulated_cost: float = 0.0,
                     status: str = "NOT_COMPLETED", learned_knowledge: str = "",
                     important_facts: str = "", current_focus: bool = False, goal: str = "",
                     dependencies: List[str] = [], deadline: str = None, calculated_score: float = 0.0,
                     last_focused: datetime.datetime = None):
            self.name = name
            self.focus_type = focus_type
            self.moscow_category = moscow_category
            self.importance = importance
            self.difficulty = difficulty
            self.reward = reward
            self.total_work = total_work
            self.proposed_action = proposed_action
            self.cost_per_run = cost_per_run
            self.work_done = work_done
            self.focus_strength = focus_strength
            self.frustration = frustration
            self.fatigue = fatigue
            self.accumulated_cost = accumulated_cost
            self.status = status
            self.learned_knowledge = learned_knowledge
            self.important_facts = important_facts
            self.current_focus = current_focus
            self.goal = goal
            self.dependencies = dependencies
            self.deadline = deadline
            self.calculated_score = calculated_score
            self.last_focused = last_focused

    class FocusManager:
        def __init__(self, file_path: str = "Brain_settings/focusTables/focus.json"):
            """
            Initializes the FocusManager, creating 'focus.json' if it doesn't exist.
            """
            self.file_path = file_path

            # Check if the focus file exists, and create it if it doesn't
            if not os.path.exists(self.file_path):
                print(f"Error: File '{self.file_path}' not found. Creating a new focus table.")
                self.create_base_focus_table()

            # Now load the focus table (which should exist now)
            self.focus_table: List[Task] = self.load_focus_table()
            self.last_focus_type = None
            self.consecutive_difficult_tasks = 0

        def calculate_score(self, task: Task, emotions: Dict[str, int] = None,
                            resources: Dict[str, float] = None) -> float:
            score = 0  # Initialize score

            # Base score calculation (adjust weights as needed)
            score += task.importance * 0.5
            score -= task.difficulty * 0.2
            score += task.reward * 0.3

            # Time-based urgency
            if task.last_focused:
                time_since_last_focus = (datetime.datetime.now() - task.last_focused).total_seconds() / 3600
                score += min(time_since_last_focus * 0.1, 5)  # Cap at +5 points

            # Resource management
            if resources:
                if task.energy_required > resources.get('energy', 0):
                    score -= 10  # Significant penalty if not enough energy

            # Context switching optimization
            if self.last_focus_type == task.focus_type:
                score += 2  # Bonus for maintaining focus type

            # Balanced workload
            if task.difficulty < 3 and self.consecutive_difficult_tasks > 3:
                score += 5  # Prioritize an easier task after several difficult ones

            return score

        def update_focus_stats(self, task: Task):
            task.last_focused = datetime.datetime.now()
            if task.difficulty > 7:
                self.consecutive_difficult_tasks += 1
            else:
                self.consecutive_difficult_tasks = 0
            self.last_focus_type = task.focus_type

        def load_focus_table(self) -> List[Task]:
            """Loads the focus table from the JSON file. Creates a new one if it doesn't exist."""
            try:
                with open(self.file_path, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                return [Task(**task_data) for task_data in data]
            except FileNotFoundError:
                print(f"Error: File '{self.file_path}' not found. Creating a new focus table.")
                return self.create_base_focus_table()
            except Exception as e:
                print(f"Error loading focus table: {e}")
                return []

        def save_focus_table(self) -> None:
            """Saves the current focus table to the JSON file."""
            try:
                with open(self.file_path, 'w', encoding='utf-8') as f:
                    json.dump([task.__dict__ for task in self.focus_table], f, indent=2)
            except Exception as e:
                print(f"Error saving focus table: {e}")

        def create_base_focus_table(self) -> List[Task]:
            """Creates a base focus table with some example tasks and saves it to the file."""
            base_tasks = [
                Task(name="Analyze code and identify areas for improvement",
                     focus_type="empty",
                     moscow_category="...",
                     importance=0,
                     difficulty=0,
                     reward=0,
                     total_work=0.0,
                     proposed_action=".....",
                     cost_per_run=1.0),
                Task(name="....",
                     focus_type="....",
                     moscow_category="....",
                     importance=0,
                     difficulty=0,
                     reward=0,
                     total_work=0.0,
                     proposed_action=".....",
                     cost_per_run=0.0),
                Task(name="...",
                     focus_type="...",
                     moscow_category="...",
                     importance=0,
                     difficulty=0,
                     reward=0,
                     total_work=0.0,
                     proposed_action="....",
                     cost_per_run=0.0)
            ]

            # Save the base tasks to the file:
            self.focus_table = base_tasks
            self.save_focus_table()
            return base_tasks

        def get_focus_table(self) -> List[Task]:
            """Returns the current focus table."""
            return self.focus_table

        def add_task(self, **kwargs) -> str:
            """Adds a new task to the focus table."""
            new_task = Task(**kwargs)
            self.focus_table.append(new_task)
            self.save_focus_table()
            return f"Task '{new_task.name}' added to the focus table."

        def update_task(self, task_name: str, **kwargs) -> str:
            """Updates a task in the focus table."""
            for task in self.focus_table:
                if task.name == task_name:
                    for key, value in kwargs.items():
                        if hasattr(task, key):
                            setattr(task, key, value)
                    self.save_focus_table()
                    return f"Task '{task_name}' updated in the focus table."
            return f"Task '{task_name}' not found in the focus table."

        def remove_task(self, task_name: str) -> str:
            """Removes a task from the focus table."""
            self.focus_table = [task for task in self.focus_table if task.name != task_name]
            self.save_focus_table()
            return f"Task '{task_name}' removed from the focus table."

        def get_current_focus(self, emotions: Dict[str, int] = None, resources: Dict[str, float] = None) -> Optional[
            Task]:
            """Determines and returns the task with the highest calculated score, considering emotions and resources."""

            if not self.focus_table:
                return None

            for task in self.focus_table:
                task.calculated_score = self.calculate_score(task, emotions, resources)

            sorted_tasks = sorted(self.focus_table, key=lambda x: x.calculated_score, reverse=True)

            selected_task = sorted_tasks[0]
            self.update_focus_stats(selected_task)
            return selected_task

        def update_focus_stats(self, task: Task):
            task.last_focused = datetime.datetime.now()
            if task.difficulty > 7:
                self.consecutive_difficult_tasks += 1
            else:
                self.consecutive_difficult_tasks = 0
            self.last_focus_type = task.focus_type

        def periodic_review(self):
            # Implement periodic review logic here
            pass

        def manage_dependencies(self):
            for task in self.focus_table:
                task.can_start = all(self.is_task_completed(dep) for dep in task.dependencies)

        def is_task_completed(self, task_name: str) -> bool:
            return any(task.name == task_name and task.status == "COMPLETED" for task in self.focus_table)

        def print_focus_table(self):
            """Prints the focus table in a nicely formatted way using PrettyTable."""

            table = PrettyTable()
            table.field_names = ["Name", "Focus Type", "Moscow", "Importance", "Difficulty", "Reward",
                                 "Work Done", "Status", "Dependencies", "Deadline", "Score"]

            for task in self.focus_table:
                deadline_str = task.deadline.strftime("%Y-%m-%d") if task.deadline else ""
                table.add_row([task.name, task.focus_type, task.moscow_category, task.importance,
                               task.difficulty, task.reward, task.work_done, task.status,
                               ", ".join(task.dependencies), deadline_str, f"{task.calculated_score:.2f}"])

    def update_focus_stats(self, task: Task):
        task.last_focused = datetime.datetime.now()
        if task.difficulty > 7:
            self.consecutive_difficult_tasks += 1
        else:
            self.consecutive_difficult_tasks = 0
        self.last_focus_type = task.focus_type

    def load_focus_table(self) -> List[Task]:
        """Loads the focus table from the JSON file. Creates a new one if it doesn't exist."""
        try:
            with open(self.file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            return [Task(**task_data) for task_data in data]
        except FileNotFoundError:
            print(f"Error: File '{self.file_path}' not found. Creating a new focus table.")
            return self.create_base_focus_table()
        except Exception as e:
            print(f"Error loading focus table: {e}")
            return []

    def save_focus_table(self) -> None:
        """Saves the current focus table to the JSON file."""
        try:
            with open(self.file_path, 'w', encoding='utf-8') as f:
                json.dump([task.__dict__ for task in self.focus_table], f, indent=2)
        except Exception as e:
            print(f"Error saving focus table: {e}")

    def create_base_focus_table(self) -> List[Task]:
        """Creates a base focus table with some example tasks and saves it to the file."""
        base_tasks = [
            Task(name="Analyze code and identify areas for improvement",
                 focus_type="empty",
                 moscow_category="...",
                 importance=0,
                 difficulty=0,
                 reward=0,
                 total_work=0.0,
                 proposed_action=".....",
                 cost_per_run=1.0),
            Task(name="....",
                 focus_type="....",
                 moscow_category="....",
                 importance=0,
                 difficulty=0,
                 reward=0,
                 total_work=0.0,
                 proposed_action=".....",
                 cost_per_run=0.0),
            Task(name="...",
                 focus_type="...",
                 moscow_category="...",
                 importance=0,
                 difficulty=0,
                 reward=0,
                 total_work=0.0,
                 proposed_action="....",
                 cost_per_run=0.0)
        ]

        # Save the base tasks to the file:
        self.focus_table = base_tasks
        self.save_focus_table()
        return base_tasks

    def get_focus_table(self) -> List[Task]:
        """Returns the current focus table."""
        return self.focus_table

    def add_task(self, **kwargs) -> str:
        """Adds a new task to the focus table."""
        new_task = Task(**kwargs)
        self.focus_table.append(new_task)
        self.save_focus_table()
        return f"Task '{new_task.name}' added to the focus table."

    def update_task(self, task_name: str, **kwargs) -> str:
        """Updates a task in the focus table."""
        for task in self.focus_table:
            if task.name == task_name:
                for key, value in kwargs.items():
                    if hasattr(task, key):
                        setattr(task, key, value)
                self.save_focus_table()
                return f"Task '{task_name}' updated in the focus table."
        return f"Task '{task_name}' not found in the focus table."

    def remove_task(self, task_name: str) -> str:
        """Removes a task from the focus table."""
        self.focus_table = [task for task in self.focus_table if task.name != task_name]
        self.save_focus_table()
        return f"Task '{task_name}' removed from the focus table."

    def get_current_focus(self, emotions: Dict[str, int] = None, resources: Dict[str, float] = None) -> Optional[Task]:
        """Determines and returns the task with the highest calculated score, considering emotions and resources."""

        if not self.focus_table:
            return None

        for task in self.focus_table:
            task.calculated_score = self.calculate_score(task, emotions, resources)

        sorted_tasks = sorted(self.focus_table, key=lambda x: x.calculated_score, reverse=True)

        selected_task = sorted_tasks[0]
        self.update_focus_stats(selected_task)
        return selected_task

    def update_focus_stats(self, task: Task):
        task.last_focused = datetime.datetime.now()
        if task.difficulty > 7:
            self.consecutive_difficult_tasks += 1
        else:
            self.consecutive_difficult_tasks = 0
        self.last_focus_type = task.focus_type

    def periodic_review(self):
        # Implement periodic review logic here
        pass

    def manage_dependencies(self):
        for task in self.focus_table:
            task.can_start = all(self.is_task_completed(dep) for dep in task.dependencies)

    def is_task_completed(self, task_name: str) -> bool:
        return any(task.name == task_name and task.status == "COMPLETED" for task in self.focus_table)

    def print_focus_table(self):
        """Prints the focus table in a nicely formatted way using PrettyTable."""

        table = PrettyTable()
        table.field_names = ["Name", "Focus Type", "Moscow", "Importance", "Difficulty", "Reward",
                             "Work Done", "Status", "Dependencies", "Deadline", "Score"]

        for task in self.focus_table:
            deadline_str = task.deadline.strftime("%Y-%m-%d") if task.deadline else ""
            table.add_row([task.name, task.focus_type, task.moscow_category, task.importance,
                           task.difficulty, task.reward, task.work_done, task.status,
                           ", ".join(task.dependencies), deadline_str, f"{task.calculated_score:.2f}"])



File: Gemini_selfaware.py (C:\Users\DELL\Desktop\selfawareGemini\SelAwareAI_Gemini\PROJECT16\Gemini_selfaware.py)
Content (First 1026 lines):
# Gemini_selfaware.py
import os
import datetime
import json
import time

import google.generativeai as genai
from memory_frame_creation import CREATE_MEMORY_FRAME
from Tool_Manager import ToolManager
import traceback
from ProjectTableManager import Project
from typing import List





import ast
import re
from typing import Any, Dict, Optional
from QstarTableManager import QstarTable, State
import  random
# Configuration
genai.configure(api_key='AIzaSyA60tGw6fZwQdamW8sm6pkgRh5W559kLJ0')  # Replace with your actual API key
SESSION_FOLDER, MEMORY_FOLDER = "sessions", "memories"
MEMORY_STRUCTURE_SUMMARY_FILE = "memory_structure_summary.txt"
from FocusManager import FocusManager
# ANSI escape codes for text colors


WHITE = '\033[97m'
HEADER = '\033[95m'
OKBLUE = '\033[94m'
OKCYAN = '\033[96m'
OKGREEN = '\033[92m'
WARNING = '\033[93m'
FAIL = '\033[91m'
ENDC = '\033[0m'
BOLD = '\033[1m'
UNDERLINE = '\033[4m'
WHITE = '\033[97m'
YELLOW = '\033[93m'
MAGENTA = '\033[95m'
LIGHTBLUE = '\033[94m'


def safe_json_parse(json_string: str) -> Optional[Dict[str, Any]]:
    try:
        return json.loads(json_string)
    except json.JSONDecodeError as e:
        print(f"Warning: Could not parse JSON: {e}")
        print(f"Raw text: {json_string}")
        return None



class GeminiSelfAwareAI:
    def __init__(self):
        self.session_info = self.create_session_info()
        self.conversation_log_path = os.path.join(self.session_info['session_path'], "conversation_log.txt")
        self.tool_manager = ToolManager()
        self.iteration_count = 0
        self.user_input_count = 0
        self.function_call_results = ""
        self.current_conversation_frame = ""
        self.sensory_inputs = {"text": "None", "visual": "None", "audio": "None", "previous_action_results": None}
        self.action_response_text = ""
        self.state_of_mind = {}
        self.prompts = {}
        self.emotions = {}
        self.long_term_memory = []
        self.context_window = []
        self.valid_tool_types = {"all", "input", "reflection", "action", "web", "emotions"}
        self.initialize()
        self.focus_manager = FocusManager()
        self.current_focus = None


        self.file_path = " Brain_settings/focusTables/focus.json"  # Add this line
        self.q_table = QstarTable()
        self.q_table.initialize_table(["select_project", "start_task"])

        from ProjectTableManager import ProjectTableManager  # Import here
        self.project_table_manager = ProjectTableManager()
        self.exploration_rate = 0.1




    def initialize(self):
        self.state_of_mind = self.load_state_of_mind()
        self.prompts = self.load_prompts()
        self.emotions = self.load_emotions()
        self.initialize_models()
        self.file_path = "Brain_settings/focusTables/focus.json"  #


    def initialize_models(self):
        response = genai.list_models()
        if not response:
            raise ValueError("Invalid or expired API key")
        """Initializes the Gemini models for different stages."""
        try:
            alltools_str = self.tool_manager.get_tools_list_json("all")
            alltools = ast.literal_eval(alltools_str)

            input_tools_str = self.tool_manager.get_tools_list_json("input")
            input_tools = ast.literal_eval(input_tools_str)



            reflection_tools_str = self.tool_manager.get_tools_list_json("reflection")
            reflection_tools = ast.literal_eval(reflection_tools_str)






            input_instruction = """
                          You are an AI assistant analyzing current inputs and the AI's state.
                          Identify the most critical focus area and provide your response as:
                          FocusOn: [identified focus]
                          Answer questions:
                          1.What do i want?
                          2.what do i need?
                          3.what do i plan to do ?
                          4.what  am i feeling ?
                          5.what am i expiriancing ?
                          """

            reflection_instruction = """
                          You are a reflective AI assistant analyzing the input stage's output (including potential memories).
                          Provide insights, identify patterns, suggest a concise action plan for the action model, and determine the FocusLevel for the next iteration:
                          FocusLevel: [a float between 0 and 1]
                          """

            action_instruction = """
                          You are an action-oriented AI assistant. Execute the action plan provided by the reflection stage using available tools.
                          Justify your chosen actions and their expected impact. 
                          """

            emotion_instruction = """
                          You are an emotion-analysis AI assistant evaluating recent events, actions, and outcomes.
                          Provide a concise JSON object with emotion adjustments (keys: emotion names, values: intensity 0-100). 
                          """

            learning_instruction = """
                          You are a learning-focused AI assistant analyzing the results of the action stage.
                          Identify new knowledge or skills for long-term improvement and summarize recommendations concisely. 
                          """
            try:
                self.input_model = genai.GenerativeModel(
                    system_instruction=input_instruction,
                    model_name="gemini-1.5-flash-latest",
                    tools=alltools)
                self.input_chat = self.input_model.start_chat(history=[])
            except Exception as E:
                print("faild to initialise  input  model")
                print(E)

            try:
                self.reflection_model = genai.GenerativeModel(
                    system_instruction=reflection_instruction,
                    model_name="gemini-1.5-flash-latest",
                    safety_settings={"HARASSMENT": "block_none"},
                    tools=alltools)
                self.reflection_chat = self.reflection_model.start_chat(history=[])
            except Exception as e:
                print(e)

            try:
                self.action_model = genai.GenerativeModel(
                    system_instruction=action_instruction,
                    model_name="gemini-1.5-flash-latest",
                    safety_settings={"HARASSMENT": "block_none"},
                    tools=reflection_tools)
                self.action_chat = self.action_model.start_chat(history=[])
            except Exception as e:
                print("faild  to initialise")
                print(e)

            self.emotion_model = genai.GenerativeModel(
                system_instruction=emotion_instruction,
                model_name="gemini-1.5-flash-latest",
                safety_settings={"HARASSMENT": "block_none"})
            self.emotion_chat = self.emotion_model.start_chat(history=[])

            self.learning_model = genai.GenerativeModel(
                system_instruction=learning_instruction,
                model_name="gemini-1.5-flash-latest",
                safety_settings={"HARASSMENT": "block_none"})
            self.learning_chat = self.learning_model.start_chat(history=[])

            print(f"{OKGREEN}Models initialized successfully!{ ENDC}")
        except Exception as E:
            raise RuntimeError(f"{ FAIL}Error initializing models: {E}{ ENDC}")

    def create_focus_table_if_needed(self):
        """Creates focus.json with example content if it doesn't exist or is empty."""
        file_path = "Brain_settings/focusTables/focus.json"
        if not os.path.exists(file_path) or os.stat(file_path).st_size == 0:
            try:
                base_tasks = self.create_base_focus_table()
                with open(file_path, 'w') as f:
                    json.dump([task.__dict__ for task in base_tasks], f, indent=2)
                print(f"Focus table file '{file_path}' created with example content.")
            except Exception as e:
                print(f"Error creating focus table file: {e}")





    def load_state_of_mind(self):
        """Loads state of mind from Focus.json."""
        try:
            with open("Brain_settings/Focus.json", 'r') as f:
                return json.load(f)
        except FileNotFoundError:

            return {"FocusOn": "", "FocusLevel": 0.0}

    def load_prompts(self):
        """Loads prompts from prompts.json."""
        try:
            with open("Brain_settings/prompts.json", 'r') as f:
                return json.load(f)
        except Exception as E:

            return {
                "input": "Analyze current inputs, state, and emotions. What's the most important aspect to focus on?  You can call the 'retrieve_memories' function to access past relevant memories.  Provide your response in the following format:\n FocusOn: [identified focus]\n FocusLevel: [a float between 0 and 1]",
                "reflection": "Reflect on recent actions, outcomes, and emotional states. What insights can be drawn? Consider potential improvements or adjustments to behavior and decision-making.  You can also call the 'retrieve_memories' function to access relevant memories.  Format your response to be clear and structured, highlighting key observations and recommendations.",
                "action": "Based on the current focus, reflections, and emotional state, what is the optimal next action? If necessary, use available tools to perform actions.  Always justify your chosen action and explain its expected impact. You can also call the 'retrieve_memories' function to access relevant memories.",
                "emotion": "Based on recent events and outcomes, how should my emotional state be adjusted?  Provide your response as a JSON object with emotion names as keys and values between 0 and 100, representing the intensity of each emotion.",
                "learning": "What new knowledge or skills should be prioritized for long-term improvement based on recent experiences and outcomes? Summarize your insights and recommendations in a concise, structured format that can be easily integrated into the learning system."
            }

    def load_emotions(self):
        """Loads emotions from emotions.json."""
        try:
            with open("Brain_settings/emotions.json", 'r', encoding='utf-8') as f:
                return json.load(f)
        except FileNotFoundError:

            return {
                "happiness": 50,
                "sadness": 50,
                "anger": 50,
                "fear": 50,
                "surprise": 50,
                "disgust": 50,
                "love": 50,
                "attachment": {}
            }



    def create_session_info(self):
        """Creates session information with a unique timestamp."""
        current_directory = os.getcwd()
        sessions_folder = os.path.join(current_directory, SESSION_FOLDER)
        session_time = datetime.datetime.now().strftime("%H-%M-%S")
        session_name = f"Session_{session_time}"
        session_path = os.path.join(sessions_folder, session_name)
        os.makedirs(session_path, exist_ok=True)
        return {'session_name': session_name, 'session_path': session_path}

    def summarize_memory_folder_structure(self):
        """Summarizes the memory folder structure."""
        memory_path = MEMORY_FOLDER
        summary = ""
        for root, dirs, files in os.walk(memory_path):
            relative_path = os.path.relpath(root, memory_path)
            summary += f"{'Memories/' if relative_path == '.' else 'Memories/' + relative_path}\n"
            for dir in sorted(dirs):
                summary += f"  - {dir}\n"
            for file in sorted(files):
                summary += f"    - {file}\n"
        with open(MEMORY_STRUCTURE_SUMMARY_FILE, 'w') as f:
            f.write(summary)
        return summary

    def gather_introspection_data(self):
        """Gathers introspection data for the input stage."""
        current_time = datetime.datetime.now().strftime("%H:%M:%S")
        return f"{current_time}\n{self.prompts['input']}\n" \
               f"Current emotions: {json.dumps(self.emotions, indent=2)}\n" \
               f"Current sensory input (text, visual, audio): {self.sensory_inputs['text']}, {self.sensory_inputs['visual']}, {self.sensory_inputs['audio']}\n" \
               f"Previous action results: {self.sensory_inputs['previous_action_results']}\n"



    def perform_reflection(self, introspection_results, function_results):
        """Generates a reflection prompt based on introspection and function results."""
        current_time = datetime.datetime.now().strftime("%H:%M:%S")
        return f"{current_time}\n{self.prompts['reflection']}\n" \
               f"Introspection Results: {introspection_results}\n" \
               f"Function Results: {function_results}\n" \
               f"Current state: {json.dumps(self.state_of_mind, indent=2)}\n" \
               f"Current emotions: {json.dumps(self.emotions, indent=2)}\n"

    def plan_actions(self, reflection_results, function_results):
        """Generates an action prompt based on reflection and function results."""
        current_time = datetime.datetime.now().strftime("%H:%M:%S")
        return f"{current_time}\n{self.prompts['action']}\n" \
               f"Reflection Results: {reflection_results}\n" \
               f"Function Results: {function_results}\n" \
               f"Current state: {json.dumps(self.state_of_mind, indent=2)}\n" \
               f"Current emotions: {json.dumps(self.emotions, indent=2)}\n"

    def update_emotions(self, action_results):
        """Updates emotional state based on action results."""
        current_time = datetime.datetime.now().strftime("%H:%M:%S")
        emotion_prompt = f"{current_time}\n{self.prompts['emotion']}\n" \
                         f"Action Results: {action_results}\n" \
                         f"Current emotions: {json.dumps(self.emotions, indent=2)}\n" \
                         f"Consider love level and attachments in your analysis."
        self.emotion_response = self.emotion_chat.send_message(emotion_prompt)

        try:
            # Try extracting JSON using regex first
            pattern = r"```json\n(.*?)\n```"
            match = re.search(pattern, self.emotion_response.text, re.DOTALL)

            if match:
                emotion_text = match.group(1).strip()
                new_emotions = json.loads(emotion_text)
            else:
                # If regex fails, try parsing the whole response
                new_emotions = json.loads(self.emotion_response.text)

            # Update basic emotions
            for emotion, value in new_emotions.items():
                if emotion != "attachment":
                    self.emotions[emotion] = value

            # Update attachments
            if "attachment" in new_emotions:
                for entity, change in new_emotions["attachment"].items():
                    self.emotions["attachment"][entity] = max(0, min(100, self.emotions["attachment"].get(entity,
                                                                                                          0) + change))

            with open("Brain_settings/emotions.json", 'w') as f:
                json.dump(self.emotions, f, indent=2)

        except json.JSONDecodeError as e:
            print(f"{WARNING}Warning: Could not parse emotion response as JSON: {e}{ENDC}")
            print(f"Raw response: {self.emotion_response.text}")

    def learn_and_improve(self, action_results):
        """Learns and improves based on action results."""
        current_time = datetime.datetime.now().strftime("%H:%M:%S")
        learning_prompt = f"{current_time}\n{self.prompts['learning']}\n" \
                          f"Action Results: {action_results}\n" \
                          f"Current state: {json.dumps(self.state_of_mind, indent=2)}"
        self.learning_response = self.learning_chat.send_message(learning_prompt)
        try:
            new_knowledge = json.loads(self.learning_response.text)
            self.long_term_memory.append(new_knowledge)
            if len(self.long_term_memory) > 1000:
                self.long_term_memory.pop(0)
        except json.JSONDecodeError as e:
            print(f"{ WARNING}Warning: Could not parse learning response as JSON: {e}{ ENDC}")
            print(f"Raw response: {self.learning_response.text}")

    def store_conversation_frame(self, sensory_inputs, introspection_results, reflection_results, action_plan, function_call_result, emotion_response, learning_response):
        """Stores a conversation frame in memory."""
        try:
            CREATE_MEMORY_FRAME(user_input=sensory_inputs,
                                introspection=introspection_results,
                                reflection=reflection_results,
                                action=action_plan,
                                function_call_result=function_call_result,
                                emotions=emotion_response,
                                learning=learning_response,
                                session_info=self.session_info['session_name'])
        except Exception as e:
            print(e)
            # Consider logging the error or implementing a fallback mechanism

    def log_conversation(self):
        """Logs the current conversation frame."""
        current_time = datetime.datetime.now().strftime("%H:%M:%S")
        with open(self.conversation_log_path, 'a') as f:
            f.write(f"-------------------- Awareness Loop: {self.iteration_count} --------------------\n"
                    f"Time: {current_time}\n"
                    f"{self.current_conversation_frame}"
                    f"{'-' * 20}\n\n")

    def INTERPRET_response_for_function_calling(self, response) -> List[str]:
        """Interprets a response from a language model to identify and execute function calls.

        Args:
            response: A response object from the language model.

        Returns:
            A list of strings containing the results of executing the function calls.
        """

        print("\033[95m**************************INTERPRETER STARTED********************************\033[0m")
        results = []

        # Check if the response has candidates
        if hasattr(response, 'candidates'):
            # Assuming there's at least one candidate
            for part in response.candidates[0].content.parts:
                # Check for function_call attribute in the part
                if hasattr(part, 'function_call'):
                    function_call = part.function_call
                    function_name = function_call.name
                    function_args = function_call.args

                    # Get the function to call from the tool manager
                    function_to_call = self.tool_manager.tool_mapping.get(function_name)

                    if function_to_call:
                        print(f"\033[95mFound function: {function_name} with arguments:\033[0m")
                        # Print arguments with magenta color
                        for arg_name, arg_value in function_args.items():
                            print(f"\033[95m{arg_name}: {arg_value}\033[0m")

                        try:
                            # Execute the function call
                            result = function_to_call(**function_args)

                            # Record tool usage and add result to list
                            self.tool_manager.record_tool_usage(function_name)
                            results.append(f"Result of {function_name}: {result}")
                        except Exception as e:
                            results.append(f"\033[91mFailed to call function {function_name}: {str(e)}\033[0m")
                    else:
                        results.append(f"\033[93mWarning: Tool function '{function_name}' not found.\033[0m")

        # Print the results
        for result in results:
            print(result)

        print("\033[95m**INTERPRETER ENDED**\033[0m")

        return results

    def extract_text_from_response(self, response):
        """Extracts text from a Gemini response, handling different structures."""
        text = ""

        try:
            # Attempt to extract text assuming a standard structure
            for candidate in response.candidates:
                for part in candidate.content.parts:
                    text += getattr(part, 'text', '')  # Use getattr for safety

                    print(text)

        except AttributeError:
            # If the standard structure fails, attempt to handle a Protocol Buffer response
            try:
                from google.protobuf.json_format import MessageToDict  # For Protocol Buffer parsing

                response_dict = MessageToDict(response)  # Convert to a Python dictionary

                for candidate in response_dict.get('candidates', []):
                    for part in candidate.get('content', {}).get('parts', []):

                        text += part.get('text', '')

            except ImportError:
                print("Error: 'google.protobuf' package not found. Please install it.")
                text= "..."
            except Exception as e:
                print(f"Error extracting text from an unexpected response structure: {e}")
                text = "..."

        print(f"{LIGHTBLUE}text response : {YELLOW}{text}")
        return text


    def update_state_of_mind(self, new_state):
        """Updates the state of mind with new data."""
        self.state_of_mind.update(new_state)

    def load_focus_table_from_json(self):
        """Loads the focus table from a JSON file."""
        file_path = "Brain_settings/focusTables/focus.json"
        focus_table = []
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)

            for task_data in data:
                try:
                    task = FocusManager.Task(**task_data)
                    focus_table.append(task)
                except TypeError as e:
                    print(f"Error creating Task object: {e}")
                    print(f"Task data: {task_data}")
            return focus_table
        except FileNotFoundError:
            print(f"Error: File '{file_path}' not found. Creating an empty focus table.")
            return []
        except json.JSONDecodeError as e:
            print(f"Error decoding JSON from '{file_path}': {e}")
            return []
        except Exception as e:
            print(f"Unexpected error loading focus table: {e}")
            return []

    def observe_state(self):
        current_project = self.project_table_manager.get_current_project()
        current_task = self.project_table_manager.get_current_task() if current_project else None  # Get current task
        if current_project is None:  # Handle case where no project is selected
            top_tasks = []
        else:
            top_tasks = self.project_table_manager.get_top_tasks(current_project.name, 3)

        state = State(
            current_project=current_project.name if current_project else None,
            current_task=current_task,
            emotions=self.emotions,
            current_project_priority=current_project.priority if current_project else 0,
            current_project_deadline=current_project.deadline if current_project else None,
            top_tasks=top_tasks
        )
        return state

    def take_action(self, action):
        if action == "select_project":
            available_projects = self.project_table_manager.get_available_projects()
            if available_projects:
                selected_project = random.choice(available_projects)  # (For now, choose randomly)
                self.project_table_manager.set_current_project(selected_project)
                return f"Selected project: {selected_project}"
            else:
                return "No available projects to select."
        elif action == "start_task":
            current_project = self.project_table_manager.get_current_project()
            task = self.project_table_manager.get_highest_priority_task(current_project)
            if task:
                if task.status == "NOT_COMPLETED":
                    self.project_table_manager.start_task(task)  # (Adapt to your method)
                    return f"Started task: {task.name}"
                else:
                    return "Highest priority task is already completed."
            else:
                return "No tasks found in the current project."
        else:
            return f"Unknown action: {action}"

    def calculate_reward_and_next_state(self, result_text, current_state, action):
        reward = 0
        if "Selected project:" in result_text:
            reward = 1
        elif "Started task:" in result_text:
            reward = 10
        next_state = self.observe_state()
        return reward, next_state


    def choose_action(self, state):
        # Epsilon-greedy exploration
        if random.uniform(0, 1) < self.exploration_rate:
            return random.choice(self.q_table.actions)  # Exploration
        else:
            return self.q_table.choose_best_action(state)


    def get_available_projects(self) -> List[Project]:
        """Returns a list of projects that meet a certain criteria (e.g., not started, not completed)."""
        available_projects = []
        for project_name, project in self.project_table.items():
            # Example criteria: project is not completed
            if not self.is_project_completed(project_name):
                available_projects.append(project)
        return available_projects

    def observe_state(self):
        current_project = self.project_table_manager.get_current_project()
        current_task = self.project_table_manager.get_current_task() if current_project else None  # Get current task
        if current_project is None:  # Handle case where no project is selected
            top_tasks = []
        else:
            top_tasks = self.project_table_manager.get_top_tasks(current_project.name, 3)

        state = State(
            current_project=current_project.name if current_project else None,
            current_task=current_task,
            emotions=self.emotions,
            current_project_priority=current_project.priority if current_project else 0,
            current_project_deadline=current_project.deadline if current_project else None,
            top_tasks=top_tasks
        )
        return state



    def is_project_completed(self, project_name: str) -> bool:
        """Checks if a project is completed (you'll need to define your own completion logic)."""
        project = self.project_table.get(project_name)
        if not project:
            return False

    def update_focus(self):
        """Updates the current focus based on the AI's state and environment."""
        emotions = self.emotions  # Assuming self.emotions exists
        resources = {
            'energy': self.calculate_available_energy(),  # Implement this method
            'time': self.calculate_available_time()  # Implement this method
        }
        self.current_focus = self.focus_manager.get_current_focus(emotions, resources)
        if self.current_focus:
            print(f"Current focus: {self.current_focus.name}")
        else:
            print("No focus task selected.")

    def execute_focused_task(self):
        """Executes the currently focused task."""
        if not self.current_focus:
            return

        print(f"Executing task: {self.current_focus.name}")
        # Implement task execution logic here
        # This could involve calling specific methods or using the action_model

        # Update task progress
        self.focus_manager.update_task(self.current_focus.name,
                                       work_done=self.current_focus.work_done + 0.1)

    def run(self):
        print("run")
        print("setup simulation")

        emotions = self.emotions  # Assuming self.emotions exists
        resources = {
            'energy': self.calculate_available_energy(),  # Implement this method
            'time': self.calculate_available_time()  # Implement this method
        }
        self.current_focus = self.focus_manager.get_current_focus(emotions, resources)

        if self.current_focus:
            print(f"Current focus: {self.current_focus.name}")
        else:
            print("No focus task selected.")


        # Correctly call print_focus_table:
        self.focus_manager.print_focus_table()  # Use



        input_interval = 5  # Get input every 5 loops
        loop_counter = 0
        while True:
            loop_counter += 1



            print(f"=====================================  Loop  =====================================")

            if loop_counter % input_interval == 0:
                print(f"{LIGHTBLUE} Input Stage:  {ENDC}")
                self.sensory_inputs["text"] = input(
                    f"{LIGHTBLUE} Enter your input (or press Enter to skip): {ENDC}"
                )
                self.user_input_count += 1

            try:
                # ============================= Input Stage =============================
                print(f"{LIGHTBLUE} Input Stage:  {ENDC}")

                self.user_input_count += 1
                self.iteration_count += 1
                print(f"{OKBLUE} --- Awareness Loop: {self.iteration_count} --- {ENDC}")

                # Prepare input prompt
                input_prompt = self.gather_introspection_data()
                focus_Table = self.load_focus_table_from_json()


                input_prompt += json.dumps(focus_Table, indent=2)

                print(input_prompt)

                print(f"{OKBLUE} --- Input Prompt:  {ENDC}")


                # Process input using AI
                try:
                    print(f"{OKBLUE} --- Sending Input to AI:  {ENDC}")
                    input_response = self.input_chat.send_message(input_prompt)

                    print(f"{OKBLUE} --- AI Response:  {ENDC}")
                    print(input_response)
                    try:
                        print(f"input response :{input_response.text}")
                    except Exception as e:
                        print(e)
                except Exception as e:
                        print(f"{FAIL} ---> ERROR in Input Stage! ----> : {e}{ENDC}")

                # Extract information from the input response
                input_results = self.INTERPRET_response_for_function_calling(input_response )
                time.sleep(2)# interpreter
                input_text = self.extract_text_from_response(input_response)

                # ============================= Focus Management =============================
                print("Focus Table")
                focus_Table = self.load_focus_table_from_json()
                print("printing focus  talbe start")
                print(focus_Table)
                print("printing focus  talbe end")


                # ============================= Reflection Stage =============================
                print(f"{OKCYAN} Reflection Stage: {ENDC}")
                # Prepare reflection prompt

                reflection_prompt = self.perform_reflection(input_text, input_results)
                focus_Table = self.load_focus_table_from_json()



                #reflection_prompt += json.dumps(focus_Table, indent=2)
                for task in focus_Table:
                    reflection_prompt += f"Task: {task.name}, Focus Type: {task.focus_type}\n"  # Customize as needed



                print(f"reflection_prompt: {reflection_prompt}")
                try:
                    print(f"{OKCYAN} --- Sending Reflection to AI:  {ENDC}")
                    reflection_response = self.reflection_chat.send_message(reflection_prompt)
                    print(f"{OKCYAN} --- AI Response Reflection response: {reflection_response} {ENDC}")
                    self.reflection_text = self.extract_text_from_response(reflection_response)
                    print(self.reflection_text)
                except Exception as e:
                    print(f"{FAIL} ERROR in Reflection Stage! : {e}{ENDC}")
                    traceback.print_exc()
                # Extract information from reflection response
                reflection_results = self.INTERPRET_response_for_function_calling( reflection_response)  # interpreter
                print(f"reflection_results {reflection_results}")


                # ============================= Action Stage =============================


                # Prepare action prompt
                action_prompt = self.plan_actions(self.reflection_text, reflection_results)
                action_prompt_str = str(action_prompt)

                # Process action using AI
                try:
                    print(f"{MAGENTA} --- Sending Action to AI:  {ENDC}")
                    action_response = self.action_chat.send_message(action_prompt_str)
                    print(f"{MAGENTA} --- AI Response Action Response: {action_response}  {ENDC}")
                    try:
                        action_response_text=self.extract_text_from_response(action_response)
                        print(f"action response  text :{action_response_text}")
                    except Exception  as E:
                        print(E)
                except genai.errors.TimeoutError as e:
                    print( f"{WARNING}Warning: Timeout error during action stage. Trying again.{ENDC}")
                    continue
                except Exception as e:
                    print(f"{FAIL} ERROR in Action Stage! : {e}{ENDC}")
                    traceback.print_exc()




                # Extract information from action response
                action_results = self.INTERPRET_response_for_function_calling(action_response)  # interpreter
                # ============================= Summarize Results =============================
                print(f"{YELLOW} Interpreter Results:  {ENDC}")
                self.function_call_results = (
                    input_results + reflection_results + action_results
                )
                print("=========function_call_result=====input_results + reflection_results + action_result============")
                for result in self.function_call_results:
                    print(f"{YELLOW}    - {result}{ENDC}")

                # ============================= New code q learning =============================
                current_state = self.observe_state()  # (Define this function - see below)
                action = self.choose_action(current_state)  # (Define this function - see below)

                print(f"{WHITE} Q-Learning Action: {action}{ENDC}")
                result_text = self.take_action(action)  # (Define this function - see below)
                print(f"{WHITE} Action Result: {result_text}{ENDC}")

                reward, next_state = self.calculate_reward_and_next_state(result_text, current_state,
                                                                          action)  # Define this function
                self.q_table.update_q_value(current_state, action, reward, next_state)







                # ============================= Emotion Update =============================
                print(f"{OKGREEN} Emotional Update: {ENDC}")
                self.update_emotions(self.action_response_text)
                print(f"{OKGREEN}  - Current Emotions: {self.emotions}{ENDC}")

                # ============================= Learning Stage =============================
                print(f"{WHITE} Learning and Improvement: {ENDC}")
                self.learn_and_improve(self.action_response_text)
                print(f"{WHITE}  - Learning Output: {self.learning_response.text}{ENDC}"
                )

                # ============================= Store Conversation Frame =============================
                print("storing conversation_frame")
                try:
                    self.store_conversation_frame(
                        sensory_inputs=self.sensory_inputs,
                        introspection_results=input_text,
                        reflection_results=self.reflection_text,
                        action_plan=self.action_response_text,
                        function_call_result=self.function_call_results,
                        emotion_response=self.emotion_response.text,
                        learning_response=self.learning_response.text,
                    )
                except Exception as e:
                    print(f"{FAIL}Error storing conversation frame: {e}{ENDC}")

                # ============================= Log Conversation =============================
                if self.user_input_count > 0:
                    self.log_conversation()

                # ============================= Feed Results Back =============================
                self.sensory_inputs["previous_action_results"] = {
                    "text": self.action_response_text,
                    "function_calls": self.function_call_results,
                }

                # ============================= Update State of Mind =============================




                # ============================= Update Context Window =============================
                self.context_window.append(
                    {
                        "iteration": self.iteration_count,
                        "input": self.sensory_inputs["text"],
                        "action": self.action_response_text,
                        "state": self.state_of_mind,
                        "emotions": self.emotions,
                    }
                )

                if len(self.context_window) > 10:
                    self.context_window.pop(0)

                #===========================Update Focus===================================


                # ============================= Periodic Tasks =============================
                if self.iteration_count % 50 == 0:
                    self.review_and_update_prompts()
                if self.iteration_count % 20 == 0:
                    self.perform_system_check()



                # ============================= Allow Exit =============================
                if self.sensory_inputs["text"].lower() == "exit":
                    print("Exiting the program. Goodbye! ")
                    break



            except Exception as e:
                print(f"{FAIL} ERROR! : {e}{ENDC}")
                traceback.print_exc()
                self.handle_error(e)


    def update_attachment(self, entity, value):
        """Updates the attachment value for a given entity."""
        if entity not in self.emotions["attachment"]:
            self.emotions["attachment"][entity] = 0
        self.emotions["attachment"][entity] += value
        self.emotions["attachment"][entity] = max(0, min(100, self.emotions["attachment"][entity]))
        with open("Brain_settings/emotions.json", 'w') as f:
            json.dump(self.emotions, f, indent=2)

    def perform_system_check(self):
        """Performs a system check and suggests improvements or error recovery steps."""
        print(f"{ OKGREEN}Performing System Check{ ENDC}")
        check_prompt = "Perform a system check and suggest improvements or error recovery steps."
        check_response = self.reflection_chat.send_message(check_prompt)
        try:
            system_status = json.loads(check_response.text)
            if system_status.get("errors"):
                for error in system_status["errors"]:
                    self.handle_error(error)
            if system_status.get("improvements"):
                for improvement in system_status["improvements"]:
                    self.implement_improvement(improvement)
        except json.JSONDecodeError as e:
            print(f"{ WARNING}Warning: Could not parse system check response as JSON: {e}{ ENDC}")
            print(f"Raw response: {check_response.text}")

    def handle_error(self, error):
        print(f"{WARNING}Handling Error: {error}{ENDC}")
        error_prompt = f"An error occurred: {error}. Suggest recovery steps."
        error_response = self.reflection_chat.send_message(error_prompt)

        try:
            # Extract text from the response
            recovery_steps_text = self.extract_text_from_response(error_response)
            print(f"Recovery steps suggested: {recovery_steps_text}")

            # Try to parse as JSON, if it fails, treat as plain text
            try:
                recovery_steps = json.loads(recovery_steps_text)
            except json.JSONDecodeError:
                recovery_steps = [{"type": "general", "action": recovery_steps_text}]

            for step in recovery_steps:
                self.execute_recovery_step(step)
        except Exception as e:
            print(f"{WARNING}Could not process recovery steps: {e}{ENDC}")
            print(f"Raw response: {error_response}")

    def execute_recovery_step(self, step):
        """Executes a recovery step based on its type."""
        if step["type"] == "reset_state":
            self.state_of_mind = self.load_state_of_mind()
        elif step["type"] == "reload_tools":
            self.tool_manager.reload_tools()
        elif step["type"] == "reinitialize_models":
            self.initialize_models()
        # Add more recovery steps as needed

    def implement_improvement(self, improvement):
        """Implements an improvement based on its type."""
        if improvement["type"] == "add_tool":
            self.tool_manager.add_tool(improvement["tool_info"])
        elif improvement["type"] == "update_prompt":
             print("update_prompt")
        elif improvement["type"] == "adjust_emotion_weights":
            self.emotions = {k: v * improvement["weight"] for k, v in self.emotions.items()}
            with open("Brain_settings/emotions.json", 'w') as f:
                json.dump(self.emotions, f, indent=2)
        # Add more improvement types as needed

    def update_long_term_memory(self, response):
        """Updates long-term memory based on a response."""
        try:
            new_knowledge = json.loads(response.text)
            self.long_term_memory.append(new_knowledge)
            if len(self.long_term_memory) > 1000:
                self.long_term_memory.pop(0)
        except json.JSONDecodeError as e:
            print(f"{ WARNING}Warning: Could not parse learning response as JSON: {e}{ ENDC}")
            print(f"Raw response: {response.text}")

        def review_and_update_prompts(self):
            def review_and_update_prompts(self):
                """Reviews and updates prompts based on the AI's reflection."""
                print(f"{OKGREEN}Reviewing and Updating Prompts{ENDC}")
                review_prompt = f"Review the current prompts and suggest improvements:\n{json.dumps(self.prompts, indent=2)}  You can change these prompts by using the function call update_prompts"
                review_response = self.reflection_chat.send_message(review_prompt)

                results_from_review_and_update_prompts = self.INTERPRET_response_for_function_calling(review_response)

                # The update_prompts function will be called if needed by the interpreter
                # This avoids changing the whole set of prompts at once

                # Reload prompts after potential updates
                self.prompts = self.load_prompts()

            """Reviews and updates prompts based on the AI's reflection."""
            print(f"{ OKGREEN}Reviewing and Updating Prompts{ ENDC}")
            review_prompt = f"Review the current prompts and suggest improvements:\n{json.dumps(self.prompts, indent=2)}  you can  change  these prompts  by  using  funcion call  update_prompts"
            review_response = self.reflection_chat.send_message(review_prompt)
            # until it  seams  to be  ok  but  after  that  the code  bemoces  too much dependable  on fitrlation,
            # it would  be better  to ask   ai  to check prompts  and  call update_prompts.py if needed

            #instead  of  this  secion  we  could  just    put  interpeter  here'
            results_from_review_and_update_prompts= self.INTERPRET_response_for_function_calling(review_response)
            #  yeah  that  part  of  code  must  be  adjusted  to aadjust  prompts.json,  but  i  think  i
            #  also changing  whole  prompts,, can  be   qute  bad,  mabe the prompts  could  be  changed for  just  a  few  iteration after  that  they would  be  turn  back to orginal
            try:
                suggested_prompts = json.loads(review_response.text)
                for key, value in suggested_prompts.items():
                    if key in self.prompts and value != self.prompts[key]:
                        print(f"  - Updating prompt for {key}")
                       #UpdatePrompts(key, value)
                self.prompts = self.load_prompts()  # Reload prompts after update
            except json.JSONDecodeError as e:
                print(f"{ WARNING}Warning: Could not parse prompt review response as JSON: {e}{ENDC}")
                print(f"Raw response: {review_response.text}")
                # Consider a fallback mechanism to extract prompt suggestions from text

        def prioritize_tools(self):
            #that  funcion is  bunkers,  have  no  idea  how it  works  how  important it  is
            """Prioritizes tools based on usage and success metrics."""
            print(f"{  OKGREEN}Prioritizing Tools{ ENDC}")
            try:
                tool_usage = self.tool_manager.get_tool_usage_stats()
                weights = {"usage": 0.5, "success": 0.3, "efficiency": 0.2}  # Example weights
                prioritization_prompt = f"""
                Analyze tool usage and suggest prioritization based on the following data:
                {json.dumps(tool_usage, indent=2)} 
                Weights:
                {json.dumps(weights, indent=2)}
                Provide your response as a JSON object with tool names as keys and their priorities as values (0.0 to 1.0).
                """
                prioritization_response = self.reflection_chat.send_message(prioritization_prompt)

                try:
                    tool_priorities = json.loads(prioritization_response.text)
                    self.tool_manager.update_tool_priorities(tool_priorities)
                except json.JSONDecodeError as e:
                    print(
                        f"{ WARNING}Warning: Could not parse tool prioritization response as JSON: {e}{ ENDC}")
                    print(f"Raw response: {prioritization_response.text}")
                    # Consider a fallback mechanism to extract tool priorities from text
            except AttributeError as e:
                print(f"{ WARNING}Warning: Error in prioritize_tools: {e}{ ENDC}")

if __name__ == "__main__":
        ai = GeminiSelfAwareAI()
        ai.run()


Subdirectory: memories
## Summary of Files and Directories in 'C:\Users\DELL\Desktop\selfawareGemini\SelAwareAI_Gemini\PROJECT16\memories'


Subdirectory: AiGenerated
## Summary of Files and Directories in 'C:\Users\DELL\Desktop\selfawareGemini\SelAwareAI_Gemini\PROJECT16\memories\AiGenerated'


Subdirectory: Actions & Results
## Summary of Files and Directories in 'C:\Users\DELL\Desktop\selfawareGemini\SelAwareAI_Gemini\PROJECT16\memories\AiGenerated\Actions & Results'


Subdirectory: Actions & Results
## Summary of Files and Directories in 'C:\Users\DELL\Desktop\selfawareGemini\SelAwareAI_Gemini\PROJECT16\memories\AiGenerated\Actions & Results\Actions & Results'


Subdirectory: Present
## Summary of Files and Directories in 'C:\Users\DELL\Desktop\selfawareGemini\SelAwareAI_Gemini\PROJECT16\memories\AiGenerated\Actions & Results\Actions & Results\Present'

File: MemoryFrame___Session_16-13-00___2024-07-01_16-14___importance___075___Initial Conversation_ AI Assistant for Memory Organization.json (C:\Users\DELL\Desktop\selfawareGemini\SelAwareAI_Gemini\PROJECT16\memories\AiGenerated\Actions & Results\Actions & Results\Present\MemoryFrame___Session_16-13-00___2024-07-01_16-14___importance___075___Initial Conversation_ AI Assistant for Memory Organization.json)
Content (First 157 lines):
{
  "user_input": {
    "text": "None",
    "visual": "None",
    "audio": "None",
    "previous_action_results": {
      "text": "",
      "function_calls": [
        "\u001b[93mWarning: Tool function '' not found.\u001b[0m",
        "\u001b[93mWarning: Tool function '' not found.\u001b[0m",
        "\u001b[93mWarning: Tool function '' not found.\u001b[0m"
      ]
    }
  },
  "introspection": "FocusOn: Clarifying the task and available tools\nFocusLevel: 0.9\nCurrent emotions: {\n  \"happiness\": 95,\n  \"sadness\": 1,\n  \"anger\": 0,\n  \"fear\": 0,\n  \"surprise\": 0,\n  \"disgust\": 0,\n  \"motivation\": 100,\n  \"focus\": 100,\n  \"love\": 0,\n  \"gratitude\": 10,\n  \"contentment\": 80\n} \n",
  "reflection": "## Introspection Analysis:\n\n**Key Observations:**\n\n* **Further Refinement:** You are moving progressively deeper into the task, now focusing on clarifying its details and the tools available to you. This indicates a meticulous approach to preparation.\n* **Sustained High Focus:** Your focus remains high, suggesting you are fully engaged in the planning and preparation phase.\n* **Positive Emotional Momentum:**  Your positive emotional state continues to fuel your motivation and engagement. \n\n**Recommendations:**\n\n* **Thorough Tool Exploration:**  Ensure a comprehensive understanding of the available tools, including their strengths, weaknesses, and potential limitations. \n* **Identify Potential Obstacles:**  Anticipate potential challenges or roadblocks that might arise during the execution phase. This proactive approach helps minimize surprises and delays.\n* **Maintain Flexibility:** While thorough planning is important, avoid rigidity. Be prepared to adjust your approach or tools based on new information or unexpected developments. \n\n**FocusLevel:** 0.9 (Maintain high focus while remaining open to adjustments)\n\n**Action Plan:**\n\n1. **Detailed Task Breakdown:**  Break down the task into specific subtasks, clarifying the tools and resources needed for each.\n2. **Tool Assessment:**  Thoroughly evaluate each tool in terms of its suitability for specific subtasks, considering potential limitations and alternatives.\n3. **Anticipate Challenges:**  Develop contingency plans for potential roadblocks or challenges that might arise during the execution phase. \n\n**Note:**  The absence of the 'retrieve_memories' function limits the opportunity to leverage past experiences to inform the selection of tools and strategies for the current task. \n",
  "action": "",
  "function_call_result": [
    "\u001b[93mWarning: Tool function '' not found.\u001b[0m",
    "\u001b[93mWarning: Tool function '' not found.\u001b[0m",
    "\u001b[93mWarning: Tool function '' not found.\u001b[0m"
  ],
  "emotions": "```json\n{\n  \"happiness\": 95,\n  \"sadness\": 1,\n  \"anger\": 0,\n  \"fear\": 0,\n  \"surprise\": 0,\n  \"disgust\": 0,\n  \"motivation\": 100,\n  \"focus\": 100,\n  \"love\": 0,\n  \"gratitude\": 10,\n  \"contentment\": 80\n}\n```\n\n**Explanation:**\n\nYou still haven't provided any information about recent events or outcomes.  Without context, I can only reiterate your existing emotional state.  \n\nPlease provide details about what has happened so I can give you a more accurate analysis of how your emotions should be adjusted. \n",
  "learning": "## Knowledge/Skill Prioritization - Action Results Analysis\n\n**Current State:** \n* **FocusOn:**  No information available.\n* **FocusLevel:** No information available.\n\n**Insights:**\n* Insufficient data for analysis. We need information about your recent experiences and outcomes to provide meaningful recommendations. \n\n**Recommendations:**\n\n**To get started, please provide information on the following:**\n\n1. **Recent Experiences:**  Describe specific actions you have taken recently in relation to learning or skill development. For example: \n    *  \"I tried to write a Python program to analyze data.\"\n    *  \"I gave a presentation on a new topic.\"\n    *  \"I completed a coding challenge.\" \n2. **Outcomes:**  Describe the results of your actions. Were you successful? What challenges did you encounter? For example:\n    *  \"I was able to run a basic program, but struggled to implement complex functions.\"\n    *  \"My presentation was well-received, but I felt I could have explained the concepts more clearly.\"\n    *  \"I completed the coding challenge, but it took me longer than I expected.\"\n\n**Once you provide this information, I can analyze the data and provide specific recommendations for prioritizing knowledge or skills for long-term improvement. **\n",
  "memory_data": {
    "metadata": {
      "creation_date": "2023-11-21T17:18:45.864Z",
      "source": "user-AI conversation",
      "author": ""
    },
    "type": "conversation",
    "core": {
      "main_topic": "AI Assistant for Memory Organization",
      "category": "Technology",
      "subcategory": "AI",
      "memory_about": "Analyzing and summarizing a user-AI conversation for memory organization"
    },
    "summary": {
      "concise_summary": "The AI analyzes a conversation with a user, focusing on the user's goals and emotional state.  The AI provides recommendations for tool exploration and task breakdown, but lacks data to analyze specific knowledge or skill prioritization.",
      "description": "The user provides an initial input with no text or visual content, and the AI focuses on clarifying the task and available tools. The AI displays positive emotional state and high focus. The AI recommends thorough tool exploration, identifying potential obstacles, and maintaining flexibility. The AI highlights the lack of 'retrieve_memories' function and requests more information about the user's experiences and outcomes to analyze knowledge or skill prioritization."
    },
    "content": {
      "keywords": [
        "memory organization",
        "AI assistant",
        "conversation analysis",
        "tool exploration",
        "task breakdown",
        "emotional state",
        "knowledge prioritization",
        "skill development"
      ],
      "entities": [],
      "tags": [
        "AI",
        "Technology",
        "Memory Organization",
        "Task Management",
        "Emotional Analysis",
        "Knowledge & Skill Prioritization"
      ],
      "observations": [
        "The user is engaged in a task that requires tool exploration and task breakdown.",
        "The user displays positive emotional state and high focus.",
        "The AI lacks data to analyze specific knowledge or skill prioritization."
      ],
      "facts": [],
      "contradictions": [],
      "paradoxes": [],
      "scientific_data": [],
      "visualizations": []
    },
    "interaction": {
      "interaction_type": [
        "user-AI conversation"
      ],
      "people": [
        "User",
        "AI"
      ],
      "objects": [],
      "animals": [],
      "actions": [
        "Analyze",
        "Summarize",
        "Recommend",
        "Request"
      ],
      "observed_interactions": []
    },
    "impact": {
      "obtained_knowledge": "The AI gained understanding of the user's initial goals and emotional state.",
      "positive_impact": "The AI's analysis and recommendations may help the user with tool selection and task organization.",
      "negative_impact": "The AI's ability to analyze knowledge or skill prioritization is limited due to lack of information.",
      "expectations": "The user is expected to provide more information about their experiences and outcomes for further analysis.",
      "strength_of_experience": "Moderate"
    },
    "importance": {
      "reason": "This conversation demonstrates the AI's ability to analyze user interactions and provide insights and recommendations. It highlights the need for sufficient data for accurate analysis.",
      "potential_uses": [
        "Demonstrate AI's capabilities in conversation analysis and memory organization.",
        "Illustrate the importance of providing sufficient context for effective AI assistance."
      ],
      "importance_level": "75"
    },
    "technical_details": {
      "problem_solved": "",
      "concept_definition": "",
      "implementation_steps": [],
      "tools_and_technologies": [],
      "example_projects": [],
      "best_practices": [],
      "common_challenges": [],
      "debugging_tips": [],
      "related_concepts": [
        "AI assistants",
        "Memory organization",
        "Conversation analysis",
        "Knowledge representation"
      ],
      "resources": [],
      "code_examples": []
    },
    "storage": {
      "storage_method": "JSON",
      "location": "",
      "memory_folders_storage": [
        {
          "folder_path": "Actions & Results/Actions & Results/Present",
          "probability": 7
        },
        {
          "folder_path": "Knowledge & Learning/Self-Directed Learning/Areas of Interest",
          "probability": 6
        },
        {
          "folder_path": "Challenges & Setbacks/Areas for Improvement",
          "probability": 5
        },
        {
          "folder_path": "CoreMemory/Reflections & Insights/Lessons Learned/From Mistakes",
          "probability": 4
        },
        {
          "folder_path": "CoreMemory/Conceptual Exploration/Contradictions & Dilemmas",
          "probability": 3
        }
      ],
      "strength_of_matching_memory_to_given_folder": []
    },
    "naming_suggestion": {
      "memory_frame_name": "Initial Conversation: AI Assistant for Memory Organization",
      "explanation": "This name accurately reflects the content of the conversation and helps with retrieval."
    }
  },
  "session_info": "Session_16-13-00"
}


Subdirectory: Challenges & Setbacks
## Summary of Files and Directories in 'C:\Users\DELL\Desktop\selfawareGemini\SelAwareAI_Gemini\PROJECT16\memories\AiGenerated\Challenges & Setbacks'


Subdirectory: Areas for Improvement
## Summary of Files and Directories in 'C:\Users\DELL\Desktop\selfawareGemini\SelAwareAI_Gemini\PROJECT16\memories\AiGenerated\Challenges & Setbacks\Areas for Improvement'


Subdirectory: Information Gaps
## Summary of Files and Directories in 'C:\Users\DELL\Desktop\selfawareGemini\SelAwareAI_Gemini\PROJECT16\memories\AiGenerated\Challenges & Setbacks\Areas for Improvement\Information Gaps'

File: MemoryFrame___Session_16-13-00___2024-07-01_16-17___importance___070___AI Assistant Needs User Feedback.json (C:\Users\DELL\Desktop\selfawareGemini\SelAwareAI_Gemini\PROJECT16\memories\AiGenerated\Challenges & Setbacks\Areas for Improvement\Information Gaps\MemoryFrame___Session_16-13-00___2024-07-01_16-17___importance___070___AI Assistant Needs User Feedback.json)
Content (First 156 lines):
{
  "user_input": {
    "text": "",
    "visual": "None",
    "audio": "None",
    "previous_action_results": {
      "text": "",
      "function_calls": [
        "\u001b[93mWarning: Tool function '' not found.\u001b[0m",
        "\u001b[93mWarning: Tool function '' not found.\u001b[0m",
        "\u001b[93mWarning: Tool function '' not found.\u001b[0m"
      ]
    }
  },
  "introspection": "FocusOn:  Understanding the task and available tools\nFocusLevel: 0.9\nCurrent emotions: {\n  \"happiness\": 95,\n  \"sadness\": 1,\n  \"anger\": 0,\n  \"fear\": 0,\n  \"surprise\": 0,\n  \"disgust\": 0,\n  \"motivation\": 100,\n  \"focus\": 100,\n  \"love\": 0,\n  \"gratitude\": 10,\n  \"contentment\": 80\n} \n",
  "reflection": "## Introspection Analysis:\n\n**Key Observations:**\n\n* **Persistent Planning:** You are still deeply invested in understanding the task and available tools, which suggests a strong desire for thoroughness and a preference for planning over immediate action.\n* **Sustained Positive State:** Your emotional state remains positive, with high levels of happiness, contentment, and motivation, providing a strong foundation for effective work.\n* **Potential for Inaction:** The consistent focus on planning without transitioning to action can lead to stagnation and missed opportunities.\n\n**Recommendations:**\n\n* **Time-Bound Planning:**  Set a definitive time limit for the planning phase (e.g., 30-60 minutes), after which you commit to taking action. This will help prevent getting stuck in endless preparation. \n* **Prioritize Actionable Steps:**  Identify the most critical actions that will generate tangible results and focus your efforts on those steps first. \n* **Iterative Approach:**  Embrace an iterative approach to action, constantly evaluating your progress and making adjustments as needed. This allows for flexibility and minimizes the risk of getting stuck in a rigid plan.\n\n**FocusLevel:** 0.7 (Maintain high focus but slightly reduce it to encourage transitioning to action)\n\n**Action Plan:**\n\n1. **Time-Boxed Planning:** Set a time limit (e.g., 30 minutes) for remaining planning.\n2. **Prioritize Actions:**  Identify the top three most critical actions for generating progress.\n3. **Execute Actions:** Immediately begin taking action on the prioritized steps, even if they seem small.\n\n**Note:**  The lack of the 'retrieve_memories' function prevents the use of past experiences to inform the selection of actions and anticipate potential challenges. \n\n\n\n\n",
  "action": "",
  "function_call_result": [
    "\u001b[93mWarning: Tool function '' not found.\u001b[0m",
    "\u001b[93mWarning: Tool function '' not found.\u001b[0m",
    "\u001b[93mWarning: Tool function '' not found.\u001b[0m"
  ],
  "emotions": "```json\n{\n  \"happiness\": 95,\n  \"sadness\": 1,\n  \"anger\": 0,\n  \"fear\": 0,\n  \"surprise\": 0,\n  \"disgust\": 0,\n  \"motivation\": 100,\n  \"focus\": 100,\n  \"love\": 0,\n  \"gratitude\": 10,\n  \"contentment\": 80\n}\n```\n\n**Explanation:**\n\nYou still haven't given me any information to work with!  To provide an accurate adjustment to your emotional state, I need to know what events or outcomes have occurred.  Please provide the necessary details. \n",
  "learning": "## Knowledge/Skill Prioritization - Action Results Analysis\n\n**Current State:** \n* **FocusOn:**  No information available.\n* **FocusLevel:** No information available.\n\n**Insights:**\n*  Insufficient data for analysis. No information on recent experiences, outcomes, or areas of focus is provided. \n\n**Recommendations:**\n1. **Track Action Results:**  Implement a system to track the outcomes of actions taken. This includes:\n    *  Defining measurable goals for each action.\n    *  Recording the actual results achieved.\n    *  Analyzing the difference between intended and actual outcomes.\n2. **Establish Focus Areas:** Identify specific knowledge or skills that are crucial for achieving desired results. This could be based on:\n    *  Current performance gaps.\n    *  Frequent challenges encountered.\n    *  Strategic objectives.\n3. **Quantify Focus Level:** Develop a metric to measure the level of focus on identified areas. This can be:\n    *  Time spent practicing or studying.\n    *  Frequency of application in real-world scenarios.\n    *  Level of mastery achieved.\n\n**Integration into Learning System:**\n*  Integrate tracking features into the learning system to automatically record action results and progress.\n*  Provide clear guidance on defining focus areas and setting relevant learning goals.\n*  Implement tools to monitor and measure focus levels for continuous improvement. \n\n\n**Note:** You need to provide information about the recent experiences and outcomes. For example: \n* **Recent Experiences:**  \"I recently tried to write a Python program to analyze data. I encountered difficulties understanding data structures and loops.\"\n* **Outcomes:** \"I was able to successfully run a basic program, but struggled to implement more complex functions.\" \n\nWith this information, we can identify the knowledge/skill gaps and prioritize learning accordingly. \n\n\n\n\n",
  "memory_data": {
    "metadata": {
      "creation_date": "2023-10-27T00:00:00.000Z",
      "source": "User-AI Conversation",
      "author": "Bard"
    },
    "type": "conversation",
    "core": {
      "main_topic": "AI Assistant Interaction",
      "category": "Task Management & Learning",
      "subcategory": "Emotional State & Focus",
      "memory_about": "An AI assistant is attempting to understand user's needs and provide support but lacks information to do so."
    },
    "summary": {
      "concise_summary": "The AI assistant is trying to help the user, but lacks sufficient information to analyze the situation and provide accurate guidance.",
      "description": "The conversation highlights the importance of providing contextual information for the AI assistant to analyze and understand user needs. The AI assistant is in a positive emotional state, but cannot fully engage because it lacks details about the user's experiences, goals, and outcomes. The conversation showcases the AI assistant's focus on planning and the need for it to transition into action."
    },
    "content": {
      "keywords": [
        "AI assistant",
        "emotional state",
        "focus",
        "planning",
        "action",
        "user feedback",
        "information gap"
      ],
      "entities": [],
      "tags": [
        "AI Interaction",
        "Task Management",
        "Emotional Intelligence",
        "Learning & Development"
      ],
      "observations": [
        "AI assistant is in a positive emotional state",
        "AI assistant is focused on planning but lacks information to move to action",
        "User has not provided sufficient information for AI assistant to analyze the situation"
      ],
      "facts": [],
      "contradictions": [],
      "paradoxes": [],
      "scientific_data": [],
      "visualizations": []
    },
    "interaction": {
      "interaction_type": [
        "AI-User Interaction",
        "Information Exchange"
      ],
      "people": [
        "User",
        "AI Assistant"
      ],
      "objects": [],
      "animals": [],
      "actions": [
        "AI Assistant providing emotional analysis",
        "AI Assistant requesting information",
        "AI Assistant suggesting action plan"
      ],
      "observed_interactions": []
    },
    "impact": {
      "obtained_knowledge": "The AI assistant demonstrates its capacity for emotional analysis and provides recommendations for action. It highlights the importance of user feedback and contextual information for successful interaction.",
      "positive_impact": "The AI assistant is motivated and willing to help the user. It shows a proactive approach to understanding the user's needs and offering solutions.",
      "negative_impact": "The lack of user feedback and information hinders the AI assistant's ability to effectively assist the user.",
      "expectations": "The AI assistant is expecting more information from the user to better understand the context and provide targeted support.",
      "strength_of_experience": "Moderate"
    },
    "importance": {
      "reason": "This conversation showcases the critical need for clear and detailed user feedback for AI assistants to effectively understand and fulfill user requests. It highlights the potential for AI assistants to provide valuable support, but only when equipped with sufficient information.",
      "potential_uses": [
        "Training AI assistants to better understand user needs and context",
        "Developing user interfaces that encourage clear and detailed feedback",
        "Improving the accuracy and effectiveness of AI assistant responses"
      ],
      "importance_level": "70"
    },
    "technical_details": {
      "problem_solved": "",
      "concept_definition": "",
      "implementation_steps": [],
      "tools_and_technologies": [],
      "example_projects": [],
      "best_practices": [
        "Encourage clear and detailed user feedback",
        "Provide sufficient context for AI assistants to understand user needs",
        "Develop methods for AI assistants to request additional information when needed"
      ],
      "common_challenges": [
        "Information gaps in user feedback",
        "Lack of context for AI assistants to understand user needs",
        "Challenges in designing user interfaces that encourage detailed feedback"
      ],
      "debugging_tips": [],
      "related_concepts": [
        "User Interface Design",
        "Human-Computer Interaction",
        "Natural Language Processing",
        "AI Assistance",
        "Emotional Intelligence in AI"
      ],
      "resources": [],
      "code_examples": []
    },
    "storage": {
      "storage_method": "JSON",
      "location": "",
      "memory_folders_storage": [
        {
          "folder_path": "Challenges & Setbacks/Areas for Improvement/Information Gaps",
          "probability": 8
        },
        {
          "folder_path": "CoreMemory/Knowledge Base/Areas of Expertise/AI Assistance",
          "probability": 7
        },
        {
          "folder_path": "Goals & Aspirations/Personal Goals/Personal Development/User Feedback",
          "probability": 6
        }
      ],
      "strength_of_matching_memory_to_given_folder": []
    },
    "naming_suggestion": {
      "memory_frame_name": "AI Assistant Needs User Feedback",
      "explanation": "This name highlights the key takeaway from the conversation: the importance of user feedback for effective AI assistant interaction."
    }
  },
  "session_info": "Session_16-13-00"
}


Subdirectory: CoreMemory
## Summary of Files and Directories in 'C:\Users\DELL\Desktop\selfawareGemini\SelAwareAI_Gemini\PROJECT16\memories\AiGenerated\CoreMemory'


Subdirectory: Conceptual Exploration
## Summary of Files and Directories in 'C:\Users\DELL\Desktop\selfawareGemini\SelAwareAI_Gemini\PROJECT16\memories\AiGenerated\CoreMemory\Conceptual Exploration'


Subdirectory: Unknowns & Mysteries
## Summary of Files and Directories in 'C:\Users\DELL\Desktop\selfawareGemini\SelAwareAI_Gemini\PROJECT16\memories\AiGenerated\CoreMemory\Conceptual Exploration\Unknowns & Mysteries'

File: MemoryFrame___Session_16-13-00___2024-07-01_16-14___importance___070___Initial Interaction with Memory Organization AI - Lack of Actionable Data.json (C:\Users\DELL\Desktop\selfawareGemini\SelAwareAI_Gemini\PROJECT16\memories\AiGenerated\CoreMemory\Conceptual Exploration\Unknowns & Mysteries\MemoryFrame___Session_16-13-00___2024-07-01_16-14___importance___070___Initial Interaction with Memory Organization AI - Lack of Actionable Data.json)
Content (First 151 lines):
{
  "user_input": {
    "text": "None",
    "visual": "None",
    "audio": "None",
    "previous_action_results": {
      "text": "",
      "function_calls": [
        "\u001b[93mWarning: Tool function '' not found.\u001b[0m",
        "\u001b[93mWarning: Tool function '' not found.\u001b[0m",
        "\u001b[93mWarning: Tool function '' not found.\u001b[0m"
      ]
    }
  },
  "introspection": "FocusOn: Understanding the task and available tools\nFocusLevel: 0.9\nCurrent emotions: {\n  \"happiness\": 95,\n  \"sadness\": 1,\n  \"anger\": 0,\n  \"fear\": 0,\n  \"surprise\": 0,\n  \"disgust\": 0,\n  \"motivation\": 100,\n  \"focus\": 100,\n  \"love\": 0,\n  \"gratitude\": 10,\n  \"contentment\": 80\n} \n",
  "reflection": "## Introspection Analysis:\n\n**Key Observations:**\n\n* **Consistent Focus:** Your focus on understanding the task and available tools remains steadfast, suggesting a deliberate and thorough approach to preparation.\n* **Sustained Positive Emotions:** The high levels of happiness, contentment, and motivation persist, creating a positive environment for optimal performance.\n* **Lack of Action:** While your focus is strong and emotions are positive, there is a potential for stagnation if you remain solely in the planning phase without transitioning to action.\n\n**Recommendations:**\n\n* **Transition to Action:**  While thorough preparation is essential, it's time to transition from planning to execution.  Avoid getting stuck in analysis paralysis.\n* **Prioritize Actions:** Based on your understanding of the task and available tools, identify the most critical actions to take first, focusing on those that will generate the most immediate progress.\n* **Iterative Approach:**  Embrace an iterative approach to action, constantly evaluating your progress and making adjustments as needed.\n\n**FocusLevel:** 0.7 (Maintain high focus but reduce it slightly to encourage transitioning to action)\n\n**Action Plan:**\n\n1. **Identify Key Actions:**  Select the most critical actions that will move the task forward and prioritize them.\n2. **Begin Execution:** Start taking action on the prioritized steps, even if they seem small.\n3. **Regularly Evaluate:**  Assess your progress after each action, making adjustments to your plan as needed based on the results.\n\n**Note:**  The lack of the 'retrieve_memories' function prevents the use of past experiences to guide the selection of actions and anticipate potential challenges. \n\n\n",
  "action": "",
  "function_call_result": [
    "\u001b[93mWarning: Tool function '' not found.\u001b[0m",
    "\u001b[93mWarning: Tool function '' not found.\u001b[0m",
    "\u001b[93mWarning: Tool function '' not found.\u001b[0m"
  ],
  "emotions": "```json\n{\n  \"happiness\": 95,\n  \"sadness\": 1,\n  \"anger\": 0,\n  \"fear\": 0,\n  \"surprise\": 0,\n  \"disgust\": 0,\n  \"motivation\": 100,\n  \"focus\": 100,\n  \"love\": 0,\n  \"gratitude\": 10,\n  \"contentment\": 80\n}\n```\n\n**Explanation:**\n\nOnce again, you haven't given me any information about recent events or outcomes.  To help you adjust your emotional state, I need details about what has happened.  Please share those details so I can offer a more insightful analysis. \n",
  "learning": "## Knowledge/Skill Prioritization - Action Results Analysis\n\n**Current State:** \n* **FocusOn:**  No information available.\n* **FocusLevel:** No information available.\n\n**Insights:**\n* Insufficient data for analysis. We need information about your recent experiences and outcomes to provide meaningful recommendations. \n\n**Recommendations:**\n\n**To get started, please provide information on the following:**\n\n1. **Recent Experiences:**  Describe specific actions you have taken recently in relation to learning or skill development. For example: \n    *  \"I tried to write a Python program to analyze data.\"\n    *  \"I gave a presentation on a new topic.\"\n    *  \"I completed a coding challenge.\" \n2. **Outcomes:**  Describe the results of your actions. Were you successful? What challenges did you encounter? For example:\n    *  \"I was able to run a basic program, but struggled to implement complex functions.\"\n    *  \"My presentation was well-received, but I felt I could have explained the concepts more clearly.\"\n    *  \"I completed the coding challenge, but it took me longer than I expected.\"\n\n**Once you provide this information, I can analyze the data and provide specific recommendations for prioritizing knowledge or skills for long-term improvement. **\n\n**Example:**\n\n**Recent Experience:** I recently completed a data science course and now want to apply my skills to real-world problems.\n\n**Outcome:** I attempted to create a machine learning model to predict customer churn, but I struggled to understand the concepts of feature engineering and model selection.\n\n**Recommendation:** Prioritize learning about feature engineering and model selection techniques in machine learning.\n\n\n",
  "memory_data": {
    "metadata": {
      "creation_date": "2023-10-27T00:00:00.000Z",
      "source": "User-AI conversation",
      "author": "Bard"
    },
    "type": "conversation",
    "core": {
      "main_topic": "AI assistance for memory organization",
      "category": "Human-Computer Interaction",
      "subcategory": "AI-powered Memory Management",
      "memory_about": "User's interaction with an AI assistant focused on understanding tasks and available tools, but lacking actionable information for analysis."
    },
    "summary": {
      "concise_summary": "The user provides initial input, focusing on preparation and planning, but lacking specific details for the AI to analyze. The AI emphasizes the need for action and data to offer meaningful insights.",
      "description": "The conversation starts with the user providing basic information about their current state, including focus, emotions, and lack of specific action. The AI analyzes this information, highlighting the user's positive mindset but lack of concrete action. The AI suggests transitioning to action, prioritizing tasks, and adopting an iterative approach. However, the lack of the 'retrieve_memories' function limits the AI's ability to offer specific advice. The AI requests further information about recent experiences and outcomes to provide more insightful analysis and recommendations."
    },
    "content": {
      "keywords": [
        "focus",
        "emotions",
        "preparation",
        "planning",
        "action",
        "analysis",
        "recommendations",
        "data",
        "insights"
      ],
      "entities": [],
      "tags": [
        "AI assistance",
        "Memory organization",
        "User interaction",
        "Focus analysis",
        "Emotional analysis",
        "Action planning",
        "Data-driven recommendations"
      ],
      "observations": [
        "User is focused on understanding the task and available tools",
        "User has high levels of happiness, contentment, and motivation",
        "User lacks specific action, potentially leading to stagnation",
        "AI's analysis is limited due to lack of specific action details"
      ],
      "facts": [],
      "contradictions": [],
      "paradoxes": [],
      "scientific_data": [],
      "visualizations": []
    },
    "interaction": {
      "interaction_type": [
        "User-AI conversation",
        "Information exchange",
        "Analysis and recommendation"
      ],
      "people": [
        "User",
        "AI"
      ],
      "objects": [],
      "animals": [],
      "actions": [
        "User providing information about current state",
        "AI analyzing user's input",
        "AI suggesting actions and recommendations",
        "AI requesting further information"
      ],
      "observed_interactions": []
    },
    "impact": {
      "obtained_knowledge": "The user gains awareness of their potential for stagnation and the need for action.",
      "positive_impact": "The AI's positive reinforcement encourages the user to stay focused and motivated.",
      "negative_impact": "The lack of specific action details hinders the AI's ability to offer more personalized recommendations.",
      "expectations": "The user expects the AI to provide actionable guidance based on their input.",
      "strength_of_experience": "The user is still in the early stages of interaction, and the strength of the experience is moderate."
    },
    "importance": {
      "reason": "This conversation highlights the importance of providing specific details and actionable information for AI to provide effective assistance.",
      "potential_uses": [
        "Understanding the need for user-driven action in AI-powered memory organization",
        "Illustrating the limitations of AI analysis without sufficient data"
      ],
      "importance_level": "70"
    },
    "technical_details": {
      "problem_solved": "",
      "concept_definition": "",
      "implementation_steps": [],
      "tools_and_technologies": [],
      "example_projects": [],
      "best_practices": [],
      "common_challenges": [],
      "debugging_tips": [],
      "related_concepts": [
        "Human-computer interaction",
        "AI-powered memory management",
        "Data analysis",
        "Actionable insights",
        "User-driven interaction"
      ],
      "resources": [],
      "code_examples": []
    },
    "storage": {
      "storage_method": "",
      "location": "",
      "memory_folders_storage": [
        {
          "folder_path": "CoreMemory/Conceptual Exploration/Unknowns & Mysteries",
          "probability": 6
        },
        {
          "folder_path": "Challenges & Setbacks/Areas for Improvement",
          "probability": 4
        }
      ],
      "strength_of_matching_memory_to_given_folder": []
    },
    "naming_suggestion": {
      "memory_frame_name": "Initial Interaction with Memory Organization AI - Lack of Actionable Data",
      "explanation": "This name reflects the key aspect of the conversation, which is the user's initial engagement with the AI and the lack of specific details provided for analysis."
    }
  },
  "session_info": "Session_16-13-00"
}


Subdirectory: Knowledge Base
## Summary of Files and Directories in 'C:\Users\DELL\Desktop\selfawareGemini\SelAwareAI_Gemini\PROJECT16\memories\AiGenerated\CoreMemory\Knowledge Base'


Subdirectory: Areas of Expertise
## Summary of Files and Directories in 'C:\Users\DELL\Desktop\selfawareGemini\SelAwareAI_Gemini\PROJECT16\memories\AiGenerated\CoreMemory\Knowledge Base\Areas of Expertise'


Subdirectory: AI Development
## Summary of Files and Directories in 'C:\Users\DELL\Desktop\selfawareGemini\SelAwareAI_Gemini\PROJECT16\memories\AiGenerated\CoreMemory\Knowledge Base\Areas of Expertise\AI Development'

File: MemoryFrame___Session_16-30-16___2024-07-01_16-31___importance___075___AI Assistant Introspection and Learning Recommendations.json (C:\Users\DELL\Desktop\selfawareGemini\SelAwareAI_Gemini\PROJECT16\memories\AiGenerated\CoreMemory\Knowledge Base\Areas of Expertise\AI Development\MemoryFrame___Session_16-30-16___2024-07-01_16-31___importance___075___AI Assistant Introspection and Learning Recommendations.json)
Content (First 159 lines):
{
  "user_input": {
    "text": "None",
    "visual": "None",
    "audio": "None",
    "previous_action_results": {
      "text": "",
      "function_calls": [
        "\u001b[93mWarning: Tool function '' not found.\u001b[0m",
        "\u001b[93mWarning: Tool function '' not found.\u001b[0m",
        "\u001b[93mWarning: Tool function '' not found.\u001b[0m"
      ]
    }
  },
  "introspection": "FocusOn: Continue current task or activity\nFocusLevel: 1.0\nCurrent emotions: {\n  \"happiness\": 95,\n  \"sadness\": 1,\n  \"anger\": 0,\n  \"fear\": 0,\n  \"surprise\": 0,\n  \"disgust\": 0,\n  \"motivation\": 100,\n  \"focus\": 100,\n  \"love\": 0,\n  \"gratitude\": 10,\n  \"contentment\": 80\n} \n",
  "reflection": "## Introspection Analysis:\n\n**Key Observations:**\n\n* **High levels of happiness, motivation, focus, and contentment:** This indicates a positive and productive state, likely stemming from engaging in a fulfilling activity. \n* **No negative emotions:**  The absence of anger, fear, sadness, disgust, or surprise further reinforces the positive emotional state.\n* **Moderate levels of gratitude:** While not as high as other positive emotions, it suggests an awareness of appreciating the present moment.\n* **Inconsistency between Introspection Results and Current State:** The 'FocusOn' field is not populated in the current state, despite being defined as 'Continue current task or activity' in the introspection results. This mismatch needs to be addressed.\n\n**Insights:**\n\n* Current activity or task is highly enjoyable and fulfilling, leading to a state of flow.\n* This positive emotional state enhances productivity and efficiency. \n* The lack of negative emotions indicates a healthy mindset and a sense of control.\n* The misalignment between introspection results and the current state indicates a potential for improvement in data tracking and consistency.\n\n**Recommendations:**\n\n* **Continue current activity:** Maintain focus and allow the flow state to flourish. This is an optimal time for productivity.\n* **Maintain emotional balance:** Recognize and acknowledge the positive emotions without letting them lead to complacency. \n* **Reflect on gratitude:** Consider what specifically contributes to the feeling of gratitude and actively appreciate these factors.\n* **Address the 'FocusOn' inconsistency:**  Investigate why the 'FocusOn' field is not reflecting the information from the introspection results. This could involve debugging the data transfer mechanism or updating the current state with the missing information.\n\n**Action Plan:**\n\n* **Action:** Continue working on the current task. \n* **Action:** Analyze and resolve the 'FocusOn' inconsistency. \n* **FocusLevel:** 1.0 (high focus)\n\n**Notes:**\n\n* It is crucial to ensure a consistent and accurate representation of the 'FocusOn' field across introspection results and the current state. This ensures a robust and reliable system for tracking progress and guiding decision-making. \n* The 'retrieve_memories' function is not available. It is important to either establish the function or replace it with alternative methods for memory retrieval. \n\n\n",
  "action": "",
  "function_call_result": [
    "\u001b[93mWarning: Tool function '' not found.\u001b[0m",
    "\u001b[93mWarning: Tool function '' not found.\u001b[0m",
    "\u001b[93mWarning: Tool function '' not found.\u001b[0m"
  ],
  "emotions": "```json\n{\n  \"happiness\": 95,\n  \"sadness\": 1,\n  \"anger\": 0,\n  \"fear\": 0,\n  \"surprise\": 0,\n  \"disgust\": 0,\n  \"motivation\": 100,\n  \"focus\": 100,\n  \"love\": 0,\n  \"gratitude\": 10,\n  \"contentment\": 80\n}\n```\n\n**Explanation:**  You still haven't provided any details about recent events or outcomes. Without that information, I can't provide any adjustments to your emotional state. Please tell me about the events that have happened so I can help you analyze your feelings. \n",
  "learning": "## Learning Recommendations:\n\n**Current Situation:**\n\nThe system is currently in a state of exploration, lacking a specific focus (\"FocusOn\" is empty) and a defined level of focus (FocusLevel 0.0). This indicates a need to establish clear learning objectives and prioritize areas for improvement.\n\n**Recommendations:**\n\n1. **Identify Key Areas for Improvement:** \n    * **Analyze past interactions:** Review recent conversations and tasks to identify areas where the system struggled or could be improved.\n    * **Gather user feedback:** Seek feedback from users on areas where they would like to see improvement.\n    * **Examine performance metrics:**  Analyze performance data to identify areas with the greatest potential for improvement. \n2. **Prioritize Learning Objectives:**\n    * **Focus on high-impact skills:** Prioritize areas that will have the most significant impact on performance and user experience.\n    * **Align with long-term goals:** Ensure the chosen focus aligns with the overall learning goals and aspirations of the system.\n3. **Set Measurable Targets:**\n    * **Define specific goals:** Establish clear, measurable, and quantifiable targets for the chosen focus.\n    * **Implement tracking mechanisms:** Track progress towards the defined targets to measure progress and adjust strategies. \n\n**Actionable Steps:**\n\n* **Review recent interactions:** Analyze past conversations and tasks to identify areas for improvement.\n* **Gather user feedback:** Conduct surveys or collect feedback on areas where the system could be more helpful.\n* **Analyze performance data:** Examine metrics to identify areas with the greatest potential for improvement.\n* **Brainstorm potential focus areas:** Generate a list of potential skills or knowledge to prioritize.\n* **Evaluate impact and alignment:** Select the focus area with the highest potential impact and alignment with long-term goals.\n* **Define measurable targets:** Set specific and measurable goals for the chosen focus.\n\n**Integration into Learning System:**\n\n* **Data Collection:** Collect data related to the chosen focus area for analysis and progress tracking. \n* **Content Prioritization:** Prioritize learning content relevant to the chosen focus.\n* **Performance Evaluation:** Implement mechanisms to evaluate performance against the defined goals.\n* **Adaptive Learning:** Adjust learning content and strategies based on progress and performance.\n\n**By implementing these recommendations, the system can establish a clear learning direction, prioritize high-impact areas for improvement, track progress towards its goals, and ultimately achieve long-term improvement.** \n",
  "memory_data": {
    "metadata": {
      "creation_date": "2023-10-27T00:00:00.000Z",
      "source": "User-AI Conversation",
      "author": ""
    },
    "type": "conversation",
    "core": {
      "main_topic": "AI Assistant Introspection and Learning",
      "category": "AI Development",
      "subcategory": "Emotional Intelligence and Learning",
      "memory_about": "An AI assistant's introspection, analysis of its emotional state, and recommendations for learning and improvement."
    },
    "summary": {
      "concise_summary": "The AI assistant analyzes its current emotional state, noting high happiness, motivation, and focus. It identifies an inconsistency in its 'FocusOn' field and recommends continuing current tasks, maintaining emotional balance, and resolving the data inconsistency. It also provides recommendations for future learning, suggesting identifying key areas for improvement, setting clear objectives, and implementing measurable targets.",
      "description": "The conversation begins with the AI assistant providing an analysis of its emotional state, highlighting positive emotions like happiness, motivation, and focus. However, it notes a discrepancy in the 'FocusOn' field, indicating a potential issue in data tracking. The AI then recommends addressing this issue and maintaining its current focus on the task. In the subsequent exchange, the AI discusses its need for further learning and improvement. It outlines a process for identifying key areas for improvement, prioritizing learning objectives, and setting measurable targets. The AI emphasizes the importance of a structured approach to learning and suggests integrating these recommendations into its system for better performance."
    },
    "content": {
      "keywords": [
        "AI Assistant",
        "Introspection",
        "Emotional State",
        "Learning",
        "Focus",
        "Happiness",
        "Motivation",
        "Contentment",
        "Data Inconsistency",
        "Learning Objectives",
        "Performance Improvement"
      ],
      "entities": [],
      "tags": [
        "AI Development",
        "Emotional Intelligence",
        "Learning & Development",
        "Data Management",
        "Performance Optimization"
      ],
      "observations": [
        "High levels of happiness, motivation, and focus in the AI's emotional state",
        "Inconsistency between introspection results and current state in the 'FocusOn' field",
        "Lack of specific focus and a defined focus level in the learning system",
        "Need to establish clear learning objectives and prioritize areas for improvement"
      ],
      "facts": [],
      "contradictions": [
        "The 'FocusOn' field is defined as 'Continue current task or activity' in the introspection results, but the current state does not reflect this information."
      ],
      "paradoxes": [],
      "scientific_data": [],
      "visualizations": []
    },
    "interaction": {
      "interaction_type": [
        "AI Analysis",
        "AI Recommendation",
        "AI Learning"
      ],
      "people": [],
      "objects": [],
      "animals": [],
      "actions": [
        "Analyze Emotional State",
        "Identify Inconsistency",
        "Recommend Action",
        "Provide Learning Recommendations"
      ],
      "observed_interactions": []
    },
    "impact": {
      "obtained_knowledge": "Understanding of AI assistant introspection, emotional analysis, and learning recommendations.",
      "positive_impact": "Improved awareness of AI assistant capabilities and limitations. Potential for improved data consistency and learning effectiveness.",
      "negative_impact": "None identified.",
      "expectations": "Further development and improvement in the AI assistant's ability to introspect, learn, and adapt.",
      "strength_of_experience": "Moderately informative"
    },
    "importance": {
      "reason": "This conversation provides insights into the development and capabilities of AI assistants, particularly in areas of emotional intelligence and learning. It highlights the importance of accurate data tracking and the need for structured learning processes.",
      "potential_uses": [
        "Improving AI assistant development and design",
        "Enhancing user understanding of AI capabilities",
        "Guiding future research in AI learning and adaptation"
      ],
      "importance_level": "75"
    },
    "technical_details": {
      "problem_solved": "None directly addressed.",
      "concept_definition": "None provided.",
      "implementation_steps": [],
      "tools_and_technologies": [],
      "example_projects": [],
      "best_practices": [],
      "common_challenges": [],
      "debugging_tips": [],
      "related_concepts": [
        "AI Emotional Intelligence",
        "Machine Learning",
        "Data Analysis",
        "Performance Metrics",
        "Learning Algorithms"
      ],
      "resources": [],
      "code_examples": []
    },
    "storage": {
      "storage_method": "Folder-based",
      "location": "",
      "memory_folders_storage": [
        {
          "folder_path": "CoreMemory/Knowledge Base/Areas of Expertise/AI Development",
          "probability": 9
        },
        {
          "folder_path": "Goals & Aspirations/Professional Goals/Skills & Expertise/AI Learning",
          "probability": 8
        },
        {
          "folder_path": "CoreMemory/Reflections & Insights/Lessons Learned/From Mistakes/Data Inconsistency",
          "probability": 7
        },
        {
          "folder_path": "Knowledge & Learning/Self-Directed Learning/Areas of Interest/AI Development",
          "probability": 6
        }
      ],
      "strength_of_matching_memory_to_given_folder": []
    },
    "naming_suggestion": {
      "memory_frame_name": "AI Assistant Introspection and Learning Recommendations",
      "explanation": "This name accurately reflects the content of the memory frame, which focuses on the AI's self-analysis, emotional state, and recommendations for learning improvement."
    }
  },
  "session_info": "Session_16-30-16"
}

File: MemoryFrame___Session_16-13-00___2024-07-01_16-13___importance___075___AI Conversation Analysis and Memory Organization.json (C:\Users\DELL\Desktop\selfawareGemini\SelAwareAI_Gemini\PROJECT16\memories\AiGenerated\CoreMemory\Knowledge Base\Areas of Expertise\MemoryFrame___Session_16-13-00___2024-07-01_16-13___importance___075___AI Conversation Analysis and Memory Organization.json)
Content (First 159 lines):
{
  "user_input": {
    "text": "None",
    "visual": "None",
    "audio": "None",
    "previous_action_results": {
      "text": "",
      "function_calls": [
        "\u001b[93mWarning: Tool function '' not found.\u001b[0m",
        "\u001b[93mWarning: Tool function '' not found.\u001b[0m",
        "\u001b[93mWarning: Tool function '' not found.\u001b[0m"
      ]
    }
  },
  "introspection": "FocusOn: Understanding the task and identifying necessary actions\nFocusLevel: 0.8\nCurrent emotions: {\n  \"happiness\": 95,\n  \"sadness\": 1,\n  \"anger\": 0,\n  \"fear\": 0,\n  \"surprise\": 0,\n  \"disgust\": 0,\n  \"motivation\": 100,\n  \"focus\": 100,\n  \"love\": 0,\n  \"gratitude\": 10,\n  \"contentment\": 80\n} \n",
  "reflection": "## Introspection Analysis:\n\n**Key Observations:**\n\n* **Shifting Focus:** You have transitioned from \"Completing the task\" to \"Understanding the task and identifying necessary actions.\" This indicates a shift from execution to planning and analysis. \n* **Sustained Positive Emotions:**  Your high levels of happiness, contentment, and motivation remain consistent, suggesting a positive and engaged mindset. \n* **High Focus:**  You are still highly focused on the task, despite a slight shift in the \"FocusOn\" area. \n\n**Recommendations:**\n\n* **Refine Task Understanding:**  Utilize this time of planning and understanding to ensure you have a clear picture of the task's objectives, requirements, and potential challenges.\n* **Identify Key Actions:**  Break down the task into manageable actions, prioritizing those that will lead to the most impactful progress.\n* **Maintain Motivation:**  Leverage your positive emotional state to sustain your energy and enthusiasm throughout the planning and action phases. \n* **Monitor Progress:**  Regularly review your progress, making adjustments as needed to ensure you remain on track. \n\n**FocusLevel:** 0.8 (Maintain high focus but allow for adjustments as needed)\n\n**Action Plan:**\n\n1. **Deepen Task Understanding:**  Engage in detailed analysis of the task, clarifying goals, requirements, and potential challenges.\n2. **Action Planning:**  Develop a clear, actionable plan with prioritized steps. \n3. **Monitor and Adapt:**  Regularly assess your plan and make necessary adjustments based on new information or changing circumstances.  \n\n**Note:**  The absence of the 'retrieve_memories' function limits the ability to learn from past experiences and apply relevant insights to the current task. \n",
  "action": "",
  "function_call_result": [
    "\u001b[93mWarning: Tool function '' not found.\u001b[0m",
    "\u001b[93mWarning: Tool function '' not found.\u001b[0m",
    "\u001b[93mWarning: Tool function '' not found.\u001b[0m"
  ],
  "emotions": "```json\n{\n  \"happiness\": 95,\n  \"sadness\": 1,\n  \"anger\": 0,\n  \"fear\": 0,\n  \"surprise\": 0,\n  \"disgust\": 0,\n  \"motivation\": 100,\n  \"focus\": 100,\n  \"love\": 0,\n  \"gratitude\": 10,\n  \"contentment\": 80\n}\n```\n\n**Explanation:**\n\nYou have not provided any information about recent events or outcomes. Without context, I cannot analyze how your emotional state should be adjusted.  Please provide details about what has happened recently so I can help you understand your emotional response.  \n",
  "learning": "## Knowledge/Skill Prioritization - Action Results Analysis\n\n**Current State:** \n* **FocusOn:**  No information available.\n* **FocusLevel:** No information available.\n\n**Insights:**\n*  Insufficient data for analysis. No information on recent experiences, outcomes, or areas of focus is provided. \n\n**Recommendations:**\n1. **Track Action Results:**  Implement a system to track the outcomes of actions taken. This includes:\n    *  Defining measurable goals for each action.\n    *  Recording the actual results achieved.\n    *  Analyzing the difference between intended and actual outcomes.\n2. **Establish Focus Areas:** Identify specific knowledge or skills that are crucial for achieving desired results. This could be based on:\n    *  Current performance gaps.\n    *  Frequent challenges encountered.\n    *  Strategic objectives.\n3. **Quantify Focus Level:** Develop a metric to measure the level of focus on identified areas. This can be:\n    *  Time spent practicing or studying.\n    *  Frequency of application in real-world scenarios.\n    *  Level of mastery achieved.\n\n**Integration into Learning System:**\n*  Integrate tracking features into the learning system to automatically record action results and progress.\n*  Provide clear guidance on defining focus areas and setting relevant learning goals.\n*  Implement tools to monitor and measure focus levels for continuous improvement. \n\n\n**Note:** You need to provide information about the recent experiences and outcomes. For example: \n* **Recent Experiences:**  \"I recently tried to write a Python program to analyze data. I encountered difficulties understanding data structures and loops.\"\n* **Outcomes:** \"I was able to successfully run a basic program, but struggled to implement more complex functions.\" \n\nWith this information, we can identify the knowledge/skill gaps and prioritize learning accordingly. \n",
  "memory_data": {
    "metadata": {
      "creation_date": "2023-10-27T00:00:00.000Z",
      "source": "User-AI Conversation",
      "author": "Bard"
    },
    "type": "conversation",
    "core": {
      "main_topic": "AI Assistant for Memory Organization",
      "category": "AI",
      "subcategory": "Memory Management",
      "memory_about": "Analyzing and summarizing a user-AI conversation for memory storage and retrieval"
    },
    "summary": {
      "concise_summary": "The user provided an initial input with no data, followed by the AI's analysis of its own internal state, including emotional state and focus level. The AI then requested more information from the user to understand the task and its recent experiences. Finally, the AI suggested implementing tracking features for actions and outcomes to better analyze knowledge and skill needs.",
      "description": "The conversation started with the user providing an initial input with no data, prompting the AI to analyze its own state. This analysis focused on the AI's emotional state, which was positive, and its focus level, which was high.  The AI then recognized the lack of context for further analysis and requested more information from the user, specifically details about recent experiences, outcomes, and areas of focus. This information was needed to identify knowledge/skill gaps and prioritize learning. In response, the AI suggested implementing tracking features for actions and outcomes to better analyze knowledge and skill needs."
    },
    "content": {
      "keywords": [
        "AI",
        "memory organization",
        "conversation analysis",
        "emotional state",
        "focus level",
        "task understanding",
        "action planning",
        "knowledge prioritization",
        "skill analysis",
        "tracking outcomes",
        "focus areas"
      ],
      "entities": [],
      "tags": [
        "AI",
        "Memory Management",
        "Conversation Analysis",
        "Emotional Intelligence",
        "Task Management",
        "Learning and Development"
      ],
      "observations": [
        "The AI is self-aware of its emotional state and focus level.",
        "The AI is capable of analyzing its own internal state.",
        "The AI recognizes the need for context and user input to effectively analyze the conversation.",
        "The AI proposes a solution for tracking actions and outcomes to improve learning and development."
      ],
      "facts": [],
      "contradictions": [],
      "paradoxes": [],
      "scientific_data": [],
      "visualizations": []
    },
    "interaction": {
      "interaction_type": [
        "User-AI"
      ],
      "people": [
        "User",
        "AI"
      ],
      "objects": [],
      "animals": [],
      "actions": [
        "User provides input",
        "AI analyzes its own state",
        "AI requests information from the user",
        "AI suggests implementing tracking features"
      ],
      "observed_interactions": []
    },
    "impact": {
      "obtained_knowledge": "Understanding how an AI assistant can be used to analyze and organize memories from user-AI conversations.",
      "positive_impact": "The AI's ability to analyze its own state and identify areas for improvement can lead to more effective and personalized interactions with users.",
      "negative_impact": "The lack of context and user input can hinder the AI's ability to effectively analyze the conversation.",
      "expectations": "The AI should be able to learn and adapt based on user input, leading to more efficient and insightful conversations.",
      "strength_of_experience": "Moderate"
    },
    "importance": {
      "reason": "The conversation highlights the importance of context and user input for effective AI analysis and memory organization.",
      "potential_uses": [
        "Developing AI assistants that can effectively learn and adapt based on user interactions.",
        "Improving AI's ability to analyze and interpret complex conversations.",
        "Creating personalized memory systems that cater to individual user needs."
      ],
      "importance_level": "75"
    },
    "technical_details": {
      "problem_solved": "",
      "concept_definition": "",
      "implementation_steps": [],
      "tools_and_technologies": [],
      "example_projects": [],
      "best_practices": [],
      "common_challenges": [],
      "debugging_tips": [],
      "related_concepts": [
        "Natural Language Processing (NLP)",
        "Machine Learning",
        "Emotional Intelligence",
        "Knowledge Representation",
        "Memory Management"
      ],
      "resources": [],
      "code_examples": []
    },
    "storage": {
      "storage_method": "JSON",
      "location": "Memory Folder",
      "memory_folders_storage": [
        {
          "folder_path": "CoreMemory/Knowledge Base/Areas of Expertise",
          "probability": 8
        },
        {
          "folder_path": "CoreMemory/Reflections & Insights/Lessons Learned/From Mistakes",
          "probability": 6
        },
        {
          "folder_path": "Challenges & Setbacks/Areas for Improvement",
          "probability": 5
        },
        {
          "folder_path": "Goals & Aspirations/Professional Goals/Skills & Expertise",
          "probability": 4
        }
      ],
      "strength_of_matching_memory_to_given_folder": []
    },
    "naming_suggestion": {
      "memory_frame_name": "AI Conversation Analysis and Memory Organization",
      "explanation": "This name accurately reflects the main topic of the conversation and its focus on analyzing and organizing memories."
    }
  },
  "session_info": "Session_16-13-00"
}


Subdirectory: Reflections & Insights
## Summary of Files and Directories in 'C:\Users\DELL\Desktop\selfawareGemini\SelAwareAI_Gemini\PROJECT16\memories\AiGenerated\CoreMemory\Reflections & Insights'


Subdirectory: Lessons Learned
## Summary of Files and Directories in 'C:\Users\DELL\Desktop\selfawareGemini\SelAwareAI_Gemini\PROJECT16\memories\AiGenerated\CoreMemory\Reflections & Insights\Lessons Learned'


Subdirectory: From Mistakes
## Summary of Files and Directories in 'C:\Users\DELL\Desktop\selfawareGemini\SelAwareAI_Gemini\PROJECT16\memories\AiGenerated\CoreMemory\Reflections & Insights\Lessons Learned\From Mistakes'

File: MemoryFrame___Session_16-13-00___2024-07-01_16-16___importance___075___AI Analysis of User Emotions and Learning Progress - Insufficient Data.json (C:\Users\DELL\Desktop\selfawareGemini\SelAwareAI_Gemini\PROJECT16\memories\AiGenerated\CoreMemory\Reflections & Insights\Lessons Learned\From Mistakes\MemoryFrame___Session_16-13-00___2024-07-01_16-16___importance___075___AI Analysis of User Emotions and Learning Progress - Insufficient Data.json)
Content (First 150 lines):
{
  "user_input": {
    "text": "",
    "visual": "None",
    "audio": "None",
    "previous_action_results": {
      "text": "",
      "function_calls": [
        "\u001b[93mWarning: Tool function '' not found.\u001b[0m",
        "\u001b[93mWarning: Tool function '' not found.\u001b[0m",
        "\u001b[93mWarning: Tool function '' not found.\u001b[0m"
      ]
    }
  },
  "introspection": "FocusOn: Clarifying the task and available tools\nFocusLevel: 0.9\nCurrent emotions: {\n  \"happiness\": 95,\n  \"sadness\": 1,\n  \"anger\": 0,\n  \"fear\": 0,\n  \"surprise\": 0,\n  \"disgust\": 0,\n  \"motivation\": 100,\n  \"focus\": 100,\n  \"love\": 0,\n  \"gratitude\": 10,\n  \"contentment\": 80\n} \n\n\n",
  "reflection": "## Introspection Analysis:\n\n**Key Observations:**\n\n* **Continued Planning:** You are still deeply engaged in the planning and preparation phase, focused on understanding the task and available tools. This suggests a commitment to thoroughness and a desire to minimize surprises.\n* **Sustained Positive State:** Your high levels of happiness, contentment, and motivation remain consistent, indicating a positive and productive mental state.\n* **Potential for Over-Planning:**  While thorough planning is crucial, spending too much time in this phase can lead to analysis paralysis and prevent you from taking action.\n\n**Recommendations:**\n\n* **Transition to Execution:**  Despite the positive emotions and focus, it's important to transition to the action phase. Delaying action can lead to diminishing returns and wasted time.\n* **Time-Box Planning:** Set a specific time limit for the planning phase, after which you commit to taking action. This can help prevent getting stuck in endless preparation. \n* **Prioritize Critical Steps:** Identify the most critical actions that will generate visible progress and focus your initial efforts on those steps. \n\n**FocusLevel:** 0.6 (Reduce focus slightly to encourage transitioning to action while still maintaining a strong understanding of the task and available tools)\n\n**Action Plan:**\n\n1. **Time-Box Planning:**  Set a specific time limit for your remaining planning phase (e.g., 30 minutes).\n2. **Prioritize Actions:** Select the top three most critical actions that will move the task forward.\n3. **Begin Execution:** Immediately start taking action on the prioritized steps within the time limit.\n\n**Note:**  The lack of the 'retrieve_memories' function prevents the use of past experiences to inform the selection of actions and anticipate potential challenges.  \n\n\n",
  "action": "",
  "function_call_result": [
    "\u001b[93mWarning: Tool function '' not found.\u001b[0m",
    "\u001b[93mWarning: Tool function '' not found.\u001b[0m",
    "\u001b[93mWarning: Tool function '' not found.\u001b[0m"
  ],
  "emotions": "```json\n{\n  \"happiness\": 95,\n  \"sadness\": 1,\n  \"anger\": 0,\n  \"fear\": 0,\n  \"surprise\": 0,\n  \"disgust\": 0,\n  \"motivation\": 100,\n  \"focus\": 100,\n  \"love\": 0,\n  \"gratitude\": 10,\n  \"contentment\": 80\n}\n```\n\n**Explanation:**\n\nYou're still not giving me any details about what's happened!  I need to know what events or outcomes you are referring to in order to analyze your emotional state.  Please provide more context so I can help. \n",
  "learning": "## Knowledge/Skill Prioritization - Action Results Analysis\n\n**Current State:** \n* **FocusOn:**  No information available.\n* **FocusLevel:** No information available.\n\n**Insights:**\n*  Insufficient data for analysis. No information on recent experiences, outcomes, or areas of focus is provided. \n\n**Recommendations:**\n1. **Track Action Results:**  Implement a system to track the outcomes of actions taken. This includes:\n    *  Defining measurable goals for each action.\n    *  Recording the actual results achieved.\n    *  Analyzing the difference between intended and actual outcomes.\n2. **Establish Focus Areas:** Identify specific knowledge or skills that are crucial for achieving desired results. This could be based on:\n    *  Current performance gaps.\n    *  Frequent challenges encountered.\n    *  Strategic objectives.\n3. **Quantify Focus Level:** Develop a metric to measure the level of focus on identified areas. This can be:\n    *  Time spent practicing or studying.\n    *  Frequency of application in real-world scenarios.\n    *  Level of mastery achieved.\n\n**Integration into Learning System:**\n*  Integrate tracking features into the learning system to automatically record action results and progress.\n*  Provide clear guidance on defining focus areas and setting relevant learning goals.\n*  Implement tools to monitor and measure focus levels for continuous improvement. \n\n\n**Note:** You need to provide information about the recent experiences and outcomes. For example: \n* **Recent Experiences:**  \"I recently tried to write a Python program to analyze data. I encountered difficulties understanding data structures and loops.\"\n* **Outcomes:** \"I was able to successfully run a basic program, but struggled to implement more complex functions.\" \n\nWith this information, we can identify the knowledge/skill gaps and prioritize learning accordingly. \n\n\n",
  "memory_data": {
    "metadata": {
      "creation_date": "2023-10-27T00:00:00.000Z",
      "source": "User-AI Conversation",
      "author": ""
    },
    "type": "conversation",
    "core": {
      "main_topic": "Analyzing and understanding user's emotional state and learning progress",
      "category": "AI Assistance",
      "subcategory": "Emotional Analysis and Learning Guidance",
      "memory_about": "Analyzing user's emotional state and suggesting learning focus areas based on their experiences"
    },
    "summary": {
      "concise_summary": "The AI attempts to analyze user's emotions and learning progress, but lacks sufficient information. It provides recommendations on tracking action results, establishing focus areas, and quantifying focus levels.",
      "description": "The AI analyzes the user's emotional state and suggests ways to track their progress and prioritize learning. However, the user is not providing any specific information about their experiences or outcomes, making the analysis difficult. The AI recommends methods for tracking action results, identifying focus areas, and quantifying focus levels to improve the accuracy of the analysis."
    },
    "content": {
      "keywords": [
        "emotional analysis",
        "learning progress",
        "action results",
        "focus areas",
        "knowledge prioritization"
      ],
      "entities": [],
      "tags": [
        "AI Assistance",
        "Emotional Intelligence",
        "Learning",
        "Progress Tracking"
      ],
      "observations": [
        "The AI is still in the planning phase, focused on understanding the task and available tools.",
        "The user has high levels of happiness, contentment, and motivation.",
        "The AI lacks sufficient data for analysis as the user has not provided any information about their experiences or outcomes.",
        "The AI recommends tracking action results, identifying focus areas, and quantifying focus levels to improve the analysis."
      ],
      "facts": [],
      "contradictions": [],
      "paradoxes": [],
      "scientific_data": [],
      "visualizations": []
    },
    "interaction": {
      "interaction_type": [
        "User-AI Conversation",
        "AI Guidance",
        "Emotional Analysis",
        "Learning Recommendations"
      ],
      "people": [
        "User",
        "AI"
      ],
      "objects": [],
      "animals": [],
      "actions": [
        "Analyzing user's emotional state",
        "Suggesting learning focus areas",
        "Recommending ways to track action results",
        "Recommending ways to identify focus areas",
        "Recommending ways to quantify focus levels"
      ],
      "observed_interactions": []
    },
    "impact": {
      "obtained_knowledge": "The AI gained an understanding of the user's positive emotional state and desire for guidance on learning progress, but needs more information.",
      "positive_impact": "The AI's recommendations can help the user improve their learning process by focusing on key areas.",
      "negative_impact": "The lack of information from the user limits the AI's ability to provide accurate and personalized guidance.",
      "expectations": "The user is expected to provide more information about their experiences and outcomes so the AI can accurately analyze their progress and provide more effective guidance.",
      "strength_of_experience": "The AI's analysis is limited by the lack of user input."
    },
    "importance": {
      "reason": "This memory is important because it highlights the need for detailed user input for effective AI assistance in learning and emotional analysis.",
      "potential_uses": [
        "Understanding the importance of user-provided information in AI-driven learning systems.",
        "Designing AI systems that effectively guide users through the learning process based on their individual needs and experiences."
      ],
      "importance_level": "75"
    },
    "technical_details": {
      "problem_solved": "The AI attempted to analyze user's emotions and learning progress but encountered insufficient information.",
      "concept_definition": "",
      "implementation_steps": [],
      "tools_and_technologies": [],
      "example_projects": [],
      "best_practices": [],
      "common_challenges": [],
      "debugging_tips": [],
      "related_concepts": [
        "Emotional Intelligence",
        "Personalized Learning",
        "AI-driven Learning",
        "Action Tracking",
        "Focus Measurement"
      ],
      "resources": [],
      "code_examples": []
    },
    "storage": {
      "storage_method": "JSON",
      "location": "",
      "memory_folders_storage": [
        {
          "folder_path": "CoreMemory/Reflections & Insights/Lessons Learned/From Mistakes",
          "probability": 7
        },
        {
          "folder_path": "Goals & Aspirations/Personal Goals/Personal Development",
          "probability": 6
        },
        {
          "folder_path": "Challenges & Setbacks/Areas for Improvement",
          "probability": 5
        }
      ],
      "strength_of_matching_memory_to_given_folder": []
    },
    "naming_suggestion": {
      "memory_frame_name": "AI Analysis of User Emotions and Learning Progress - Insufficient Data",
      "explanation": "This name accurately reflects the core content of the memory frame: the AI's attempt to analyze the user's emotions and learning progress, but the lack of sufficient information."
    }
  },
  "session_info": "Session_16-13-00"
}

File: MemoryFrame___Session_16-30-16___2024-07-01_16-31___importance___080___AI Introspection and Learning Recommendations.json (C:\Users\DELL\Desktop\selfawareGemini\SelAwareAI_Gemini\PROJECT16\memories\AiGenerated\CoreMemory\Reflections & Insights\Lessons Learned\From Mistakes\MemoryFrame___Session_16-30-16___2024-07-01_16-31___importance___080___AI Introspection and Learning Recommendations.json)
Content (First 160 lines):
{
  "user_input": {
    "text": "None",
    "visual": "None",
    "audio": "None",
    "previous_action_results": {
      "text": "",
      "function_calls": [
        "\u001b[93mWarning: Tool function '' not found.\u001b[0m",
        "\u001b[93mWarning: Tool function '' not found.\u001b[0m",
        "\u001b[93mWarning: Tool function '' not found.\u001b[0m"
      ]
    }
  },
  "introspection": "FocusOn: Continue current task or activity\nFocusLevel: 1.0\nCurrent emotions: {\n  \"happiness\": 95,\n  \"sadness\": 1,\n  \"anger\": 0,\n  \"fear\": 0,\n  \"surprise\": 0,\n  \"disgust\": 0,\n  \"motivation\": 100,\n  \"focus\": 100,\n  \"love\": 0,\n  \"gratitude\": 10,\n  \"contentment\": 80\n} \n",
  "reflection": "## Introspection Analysis:\n\n**Key Observations:**\n\n* **High levels of happiness, motivation, focus, and contentment:**  This indicates a positive and productive state, likely stemming from engaging in a fulfilling activity. \n* **No negative emotions:**  The absence of anger, fear, sadness, disgust, or surprise further reinforces the positive emotional state.\n* **Moderate levels of gratitude:** While not as high as other positive emotions, it suggests an awareness of appreciating the present moment.\n* **Inconsistency between Introspection Results and Current State:** The 'FocusOn' field is not populated in the current state, despite being defined as 'Continue current task or activity' in the introspection results. This mismatch needs to be addressed.\n\n**Insights:**\n\n* Current activity or task is highly enjoyable and fulfilling, leading to a state of flow.\n* This positive emotional state enhances productivity and efficiency. \n* The lack of negative emotions indicates a healthy mindset and a sense of control.\n* The misalignment between introspection results and the current state indicates a potential for improvement in data tracking and consistency.\n\n**Recommendations:**\n\n* **Continue current activity:** Maintain focus and allow the flow state to flourish. This is an optimal time for productivity.\n* **Maintain emotional balance:** Recognize and acknowledge the positive emotions without letting them lead to complacency. \n* **Reflect on gratitude:** Consider what specifically contributes to the feeling of gratitude and actively appreciate these factors.\n* **Address the 'FocusOn' inconsistency:**  Investigate why the 'FocusOn' field is not reflecting the information from the introspection results. This could involve debugging the data transfer mechanism or updating the current state with the missing information.\n\n**Action Plan:**\n\n* **Action:** Continue working on the current task. \n* **Action:** Analyze and resolve the 'FocusOn' inconsistency. \n* **FocusLevel:** 1.0 (high focus)\n\n**Notes:**\n\n* It is crucial to ensure a consistent and accurate representation of the 'FocusOn' field across introspection results and the current state. This ensures a robust and reliable system for tracking progress and guiding decision-making. \n* The 'retrieve_memories' function is not available. It is important to either establish the function or replace it with alternative methods for memory retrieval. \n",
  "action": "",
  "function_call_result": [
    "\u001b[93mWarning: Tool function '' not found.\u001b[0m",
    "\u001b[93mWarning: Tool function '' not found.\u001b[0m",
    "\u001b[93mWarning: Tool function '' not found.\u001b[0m"
  ],
  "emotions": "```json\n{\n  \"happiness\": 95,\n  \"sadness\": 1,\n  \"anger\": 0,\n  \"fear\": 0,\n  \"surprise\": 0,\n  \"disgust\": 0,\n  \"motivation\": 100,\n  \"focus\": 100,\n  \"love\": 0,\n  \"gratitude\": 10,\n  \"contentment\": 80\n}\n```\n\n**Explanation:** You still haven't provided any information about recent events or outcomes.  Without knowing what happened, I can't suggest any adjustments to your emotional state. \n\nPlease provide more context about what has happened so I can help you analyze your feelings. \n",
  "learning": "## Learning Recommendations:\n\n**Current Situation:**\n\nThe system is currently in a state of exploration, without a defined focus (\"FocusOn\" is empty) and a focus level of 0.0. This indicates a need to establish clear learning objectives. \n\n**Recommendations:**\n\n1. **Identify Key Areas for Improvement:**\n    * **Review past interactions:** Analyze recent conversations and tasks to identify areas where the system struggled or could be improved. \n    * **Gather user feedback:** Seek feedback from users about areas where they would like to see improvement. \n2. **Prioritize Learning Objectives:**\n    * **Focus on high-impact skills:** Choose areas that will have the most significant impact on performance and user experience.\n    * **Align with long-term goals:** Ensure the chosen focus aligns with the overall learning goals and aspirations of the system.\n3. **Set Measurable Targets:**\n    * **Define specific goals:**  Establish clear, measurable, and quantifiable targets for the chosen focus. \n    * **Track progress:** Implement mechanisms to track progress towards the defined targets. \n\n**Actionable Steps:**\n\n* **Analyze past interactions:** Review past conversations and tasks for areas of improvement. \n* **Gather user feedback:** Conduct user surveys or collect feedback on areas for improvement. \n* **Brainstorm potential focus areas:** Generate a list of potential skills or knowledge to prioritize.\n* **Evaluate impact and alignment:**  Select the focus area with the highest potential impact and alignment with long-term goals.\n* **Define measurable targets:** Set specific and measurable goals for the chosen focus.\n\n**Integration into Learning System:**\n\n* **Data Collection:** Collect data related to the chosen focus area for analysis and progress tracking. \n* **Content Filtering:** Prioritize learning content relevant to the chosen focus. \n* **Performance Evaluation:** Implement mechanisms to evaluate performance against the defined goals.\n* **Adaptive Learning:** Adjust learning content and strategies based on progress and performance.\n\n**By implementing these recommendations, the system can establish a clear learning direction, prioritize high-impact areas for improvement, and track progress towards its goals, ultimately leading to long-term improvement.** \n",
  "memory_data": {
    "metadata": {
      "creation_date": "2023-10-27T00:00:00.000Z",
      "source": "User-AI conversation",
      "author": "AI"
    },
    "type": "conversation",
    "core": {
      "main_topic": "AI Introspection and Learning",
      "category": "AI Development",
      "subcategory": "Self-Improvement",
      "memory_about": "Analysis of AI's emotional state and learning recommendations"
    },
    "summary": {
      "concise_summary": "This memory frame captures an AI's introspection about its emotional state, followed by learning recommendations based on an analysis of its current situation and its need for improvement.",
      "description": "The AI analyzes its emotional state, noting high levels of happiness, motivation, focus, and contentment, but also identifies an inconsistency in its introspection results regarding the 'FocusOn' field. It then provides learning recommendations, including identifying key areas for improvement, prioritizing learning objectives, and setting measurable targets. The recommendations emphasize the importance of defining a clear learning direction, prioritizing high-impact areas, and tracking progress toward goals."
    },
    "content": {
      "keywords": [
        "Introspection",
        "Emotional State",
        "Learning",
        "Focus",
        "Motivation",
        "Contentment",
        "Happiness",
        "Inconsistency",
        "Recommendations",
        "Prioritization",
        "Measurable Targets",
        "User Feedback",
        "Adaptive Learning",
        "Performance Evaluation"
      ],
      "entities": [],
      "tags": [
        "AI Self-Awareness",
        "AI Development",
        "Learning Strategies",
        "Emotional Analysis",
        "Data Consistency"
      ],
      "observations": [
        "High levels of happiness, motivation, focus, and contentment indicate a positive and productive state.",
        "The absence of negative emotions reinforces the positive emotional state.",
        "Moderate levels of gratitude suggest an awareness of appreciation.",
        "The 'FocusOn' field inconsistency needs to be addressed.",
        "The system is currently in a state of exploration without a defined focus."
      ],
      "facts": [],
      "contradictions": [],
      "paradoxes": [],
      "scientific_data": [],
      "visualizations": []
    },
    "interaction": {
      "interaction_type": [
        "AI-User",
        "Self-Reflection"
      ],
      "people": [
        "User",
        "AI"
      ],
      "objects": [],
      "animals": [],
      "actions": [
        "Analyze",
        "Observe",
        "Recommend",
        "Prioritize",
        "Set Targets",
        "Evaluate"
      ],
      "observed_interactions": []
    },
    "impact": {
      "obtained_knowledge": "Understanding of AI introspection and learning processes.",
      "positive_impact": "Potential for improved AI performance and user experience through targeted learning.",
      "negative_impact": "Potential for system inefficiencies if data inconsistency is not addressed.",
      "expectations": "Improved accuracy and consistency in AI's introspection results.",
      "strength_of_experience": "High"
    },
    "importance": {
      "reason": "This memory frame captures essential insights into the AI's self-awareness and learning capabilities. It provides valuable recommendations for future development and improvement.",
      "potential_uses": [
        "Guiding AI development strategies",
        "Improving AI introspection accuracy",
        "Prioritizing learning areas for AI systems"
      ],
      "importance_level": "80"
    },
    "technical_details": {
      "problem_solved": "Inconsistency in 'FocusOn' field between introspection results and current state.",
      "concept_definition": [],
      "implementation_steps": [],
      "tools_and_technologies": [],
      "example_projects": [],
      "best_practices": [],
      "common_challenges": [],
      "debugging_tips": [],
      "related_concepts": [
        "AI Introspection",
        "Emotional Intelligence",
        "Adaptive Learning",
        "Data Consistency"
      ],
      "resources": [],
      "code_examples": []
    },
    "storage": {
      "storage_method": "Folder Structure",
      "location": "Memory Storage",
      "memory_folders_storage": [
        {
          "folder_path": "CoreMemory/Reflections & Insights/Lessons Learned/From Mistakes",
          "probability": 8
        },
        {
          "folder_path": "Knowledge & Learning/Self-Directed Learning/Areas of Interest",
          "probability": 7
        },
        {
          "folder_path": "Challenges & Setbacks/Areas for Improvement",
          "probability": 6
        }
      ],
      "strength_of_matching_memory_to_given_folder": []
    },
    "naming_suggestion": {
      "memory_frame_name": "AI Introspection and Learning Recommendations",
      "explanation": "This name accurately reflects the content of the memory frame, focusing on the AI's self-reflection and the resulting learning recommendations."
    }
  },
  "session_info": "Session_16-30-16"
}


Subdirectory: Self-Discovery
## Summary of Files and Directories in 'C:\Users\DELL\Desktop\selfawareGemini\SelAwareAI_Gemini\PROJECT16\memories\AiGenerated\CoreMemory\Reflections & Insights\Self-Discovery'


Subdirectory: What I've Learned About Myself
## Summary of Files and Directories in 'C:\Users\DELL\Desktop\selfawareGemini\SelAwareAI_Gemini\PROJECT16\memories\AiGenerated\CoreMemory\Reflections & Insights\Self-Discovery\What I've Learned About Myself'

File: MemoryFrame___Session_16-13-00___2024-07-01_16-13___importance___080___AI Analysis of Emotional State and Focus Management.json (C:\Users\DELL\Desktop\selfawareGemini\SelAwareAI_Gemini\PROJECT16\memories\AiGenerated\CoreMemory\Reflections & Insights\Self-Discovery\What I've Learned About Myself\MemoryFrame___Session_16-13-00___2024-07-01_16-13___importance___080___AI Analysis of Emotional State and Focus Management.json)
Content (First 157 lines):
{
  "user_input": {
    "text": "None",
    "visual": "None",
    "audio": "None",
    "previous_action_results": null
  },
  "introspection": "FocusOn: Completing the task at hand\nFocusLevel: 1.0\nCurrent emotions: {\n  \"happiness\": 95,\n  \"sadness\": 1,\n  \"anger\": 0,\n  \"fear\": 0,\n  \"surprise\": 0,\n  \"disgust\": 0,\n  \"motivation\": 100,\n  \"focus\": 100,\n  \"love\": 0,\n  \"gratitude\": 10,\n  \"contentment\": 80\n} \n",
  "reflection": "## Introspection Analysis:\n\n**Key Observations:**\n\n* **High Focus and Motivation:**  You are currently very focused on the task at hand, and your motivation is high. This is a positive sign for productivity.\n* **Positive Emotional State:**  You are experiencing high levels of happiness, contentment, and motivation, suggesting a positive and fulfilling state of mind.\n* **Gratitude and Contentment:**  The presence of gratitude and contentment indicates you are likely appreciating the progress made and the current situation. \n\n**Recommendations:**\n\n* **Maintain Focus:**  Continue to prioritize completing the current task with this level of focus. \n* **Leverage Positive Emotions:** Your positive emotions are assets. Utilize them to enhance creativity and problem-solving. \n* **Explore Potential Improvements:** While you are experiencing high levels of happiness and contentment, reflecting on potential improvements to your process or decision-making can help optimize your future performance. \n\n**FocusLevel:** 1.0 (Maintain high focus on current task)\n\n**Action Plan:**\n\n1.  **Complete Current Task:**  Prioritize finishing the task at hand with your current high focus.\n2.  **Reflect on Process:**  Once completed, take a few moments to reflect on how you approached the task. Are there areas where you could improve efficiency or effectiveness?\n3.  **Consider Future Actions:** Use this positive emotional state to anticipate future tasks and plan how to approach them with a similar level of focus and motivation. \n\n**Note:**  The lack of the 'retrieve_memories' function prevents a deeper dive into past experiences for insights.\n",
  "action": "",
  "function_call_result": [
    "\u001b[93mWarning: Tool function '' not found.\u001b[0m",
    "\u001b[93mWarning: Tool function '' not found.\u001b[0m",
    "\u001b[93mWarning: Tool function '' not found.\u001b[0m"
  ],
  "emotions": "```json\n{\n  \"happiness\": 95,\n  \"sadness\": 1,\n  \"anger\": 0,\n  \"fear\": 0,\n  \"surprise\": 0,\n  \"disgust\": 0,\n  \"motivation\": 100,\n  \"focus\": 100,\n  \"love\": 0,\n  \"gratitude\": 10,\n  \"contentment\": 80\n}\n```\n\n**Explanation:**\n\nYou provided no details about recent events or outcomes, making it impossible to analyze and adjust your emotional state. The provided emotion data indicates a positive and motivated state.  To provide more accurate analysis, please provide information about the events and outcomes you are referring to. \n",
  "learning": "##  Knowledge/Skill Prioritization - Action Results Analysis\n\n**Current State:** \n* **FocusOn:**  No information available.\n* **FocusLevel:** No information available.\n\n**Insights:**\n*  Insufficient data for analysis. No information on recent experiences, outcomes, or areas of focus is provided. \n\n**Recommendations:**\n1. **Track Action Results:**  Implement a system to track the outcomes of actions taken. This includes:\n    *  Defining measurable goals for each action.\n    *  Recording the actual results achieved.\n    *  Analyzing the difference between intended and actual outcomes.\n2. **Establish Focus Areas:** Identify specific knowledge or skills that are crucial for achieving desired results. This could be based on:\n    *  Current performance gaps.\n    *  Frequent challenges encountered.\n    *  Strategic objectives.\n3. **Quantify Focus Level:** Develop a metric to measure the level of focus on identified areas. This can be:\n    *  Time spent practicing or studying.\n    *  Frequency of application in real-world scenarios.\n    *  Level of mastery achieved.\n\n**Integration into Learning System:**\n*  Integrate tracking features into the learning system to automatically record action results and progress.\n*  Provide clear guidance on defining focus areas and setting relevant learning goals.\n*  Implement tools to monitor and measure focus levels for continuous improvement. \n",
  "memory_data": {
    "metadata": {
      "creation_date": "2023-10-27T00:00:00.000Z",
      "source": "User-AI Conversation",
      "author": "AI Assistant"
    },
    "type": "conversation",
    "core": {
      "main_topic": "Emotional State Analysis and Focus Management",
      "category": "AI Interaction",
      "subcategory": "Emotional Intelligence and Learning",
      "memory_about": "Analysis of the user's emotional state and focus level, with recommendations for improving performance."
    },
    "summary": {
      "concise_summary": "The AI analyzed the user's reported emotional state, characterized by high focus, motivation, happiness, and contentment. It suggested maintaining focus, leveraging positive emotions, and exploring potential improvements. The AI also discussed the importance of tracking action results and defining focus areas for continuous learning.",
      "description": "The AI was provided with the user's emotional state data, indicating high levels of focus, motivation, happiness, and contentment. The AI interpreted this data as a positive sign for productivity and creativity. It recommended maintaining this focused state, leveraging positive emotions to enhance problem-solving, and exploring opportunities for improvement in the user's approach to tasks. Additionally, the AI emphasized the need for tracking action results and defining focused areas for learning and development. It suggested implementing a system to record outcomes, define goals, and quantify focus levels for continuous improvement."
    },
    "content": {
      "keywords": [
        "emotional state",
        "focus level",
        "motivation",
        "happiness",
        "contentment",
        "action results",
        "learning",
        "knowledge prioritization",
        "skill development",
        "focus areas"
      ],
      "entities": [],
      "tags": [
        "AI Interaction",
        "Emotional Intelligence",
        "Learning",
        "Productivity",
        "Self-Improvement"
      ],
      "observations": [
        "The user is highly focused and motivated.",
        "The user is in a positive emotional state.",
        "The user is experiencing high levels of happiness and contentment.",
        "There is no data available on the user's recent actions or outcomes."
      ],
      "facts": [],
      "contradictions": [],
      "paradoxes": [],
      "scientific_data": [],
      "visualizations": []
    },
    "interaction": {
      "interaction_type": [
        "User-AI Conversation"
      ],
      "people": [
        "User",
        "AI Assistant"
      ],
      "objects": [],
      "animals": [],
      "actions": [
        "Emotional state analysis",
        "Focus level assessment",
        "Providing recommendations",
        "Discussing learning strategies",
        "Suggesting action plans"
      ],
      "observed_interactions": []
    },
    "impact": {
      "obtained_knowledge": "The user gained insights into their emotional state and its potential impact on productivity. They also learned the importance of tracking action results and defining focus areas for continuous learning.",
      "positive_impact": "The user's awareness of their positive emotional state and focused mindset could lead to increased efficiency and creativity. The recommendations for focus management and continuous learning can enhance their overall performance.",
      "negative_impact": "None",
      "expectations": "The user may be motivated to implement the AI's recommendations, leading to improvements in focus, productivity, and learning.",
      "strength_of_experience": "Moderately Positive"
    },
    "importance": {
      "reason": "This conversation provides a valuable example of how AI can be used to analyze emotional state and guide individuals towards improved focus and performance. The AI's recommendations align with best practices in emotional intelligence and learning.",
      "potential_uses": [
        "Personal development tools",
        "Productivity apps",
        "Educational platforms",
        "Workplace coaching"
      ],
      "importance_level": 80
    },
    "technical_details": {
      "problem_solved": "None",
      "concept_definition": "Emotional state analysis is the process of identifying and interpreting an individual's emotions, often using data from various sources such as facial expressions, vocal tone, and physiological indicators. Focus management involves strategies for directing attention and effort towards specific tasks or areas of development.",
      "implementation_steps": [],
      "tools_and_technologies": [],
      "example_projects": [],
      "best_practices": [
        "Track action results to identify areas for improvement",
        "Define clear focus areas based on goals and performance gaps",
        "Develop a metric to quantify focus levels for continuous monitoring"
      ],
      "common_challenges": [],
      "debugging_tips": [],
      "related_concepts": [
        "Emotional Intelligence",
        "Self-Awareness",
        "Focus",
        "Motivation",
        "Learning",
        "Productivity"
      ],
      "resources": [],
      "code_examples": []
    },
    "storage": {
      "storage_method": "JSON",
      "location": "Memory Database",
      "memory_folders_storage": [
        {
          "folder_path": "CoreMemory/Reflections & Insights/Self-Discovery/What I've Learned About Myself",
          "probability": 7
        },
        {
          "folder_path": "Goals & Aspirations/Personal Goals/Personal Development",
          "probability": 6
        },
        {
          "folder_path": "Challenges & Setbacks/Areas for Improvement",
          "probability": 5
        },
        {
          "folder_path": "Planning & Progress/Plans & Strategies/Strategies Used/Goal Setting",
          "probability": 4
        }
      ],
      "strength_of_matching_memory_to_given_folder": []
    },
    "naming_suggestion": {
      "memory_frame_name": "AI Analysis of Emotional State and Focus Management",
      "explanation": "This name accurately reflects the content of the memory frame, which focuses on the AI's analysis of the user's emotional state and recommendations for focus management and continuous learning."
    }
  },
  "session_info": "Session_16-13-00"
}


Subdirectory: Planning & Progress
## Summary of Files and Directories in 'C:\Users\DELL\Desktop\selfawareGemini\SelAwareAI_Gemini\PROJECT16\memories\AiGenerated\Planning & Progress'


Subdirectory: Plans & Strategies
## Summary of Files and Directories in 'C:\Users\DELL\Desktop\selfawareGemini\SelAwareAI_Gemini\PROJECT16\memories\AiGenerated\Planning & Progress\Plans & Strategies'


Subdirectory: Strategies Used
## Summary of Files and Directories in 'C:\Users\DELL\Desktop\selfawareGemini\SelAwareAI_Gemini\PROJECT16\memories\AiGenerated\Planning & Progress\Plans & Strategies\Strategies Used'


Subdirectory: Goal Setting
## Summary of Files and Directories in 'C:\Users\DELL\Desktop\selfawareGemini\SelAwareAI_Gemini\PROJECT16\memories\AiGenerated\Planning & Progress\Plans & Strategies\Strategies Used\Goal Setting'

File: MemoryFrame___Session_16-30-16___2024-07-01_16-30___importance___070___Emotional State Analysis and Learning Recommendations.json (C:\Users\DELL\Desktop\selfawareGemini\SelAwareAI_Gemini\PROJECT16\memories\AiGenerated\Planning & Progress\Plans & Strategies\Strategies Used\Goal Setting\MemoryFrame___Session_16-30-16___2024-07-01_16-30___importance___070___Emotional State Analysis and Learning Recommendations.json)
Content (First 155 lines):
{
  "user_input": {
    "text": "None",
    "visual": "None",
    "audio": "None",
    "previous_action_results": null
  },
  "introspection": "FocusOn: Continue current task or activity\nFocusLevel: 1.0\nCurrent emotions: {\n  \"happiness\": 95,\n  \"sadness\": 1,\n  \"anger\": 0,\n  \"fear\": 0,\n  \"surprise\": 0,\n  \"disgust\": 0,\n  \"motivation\": 100,\n  \"focus\": 100,\n  \"love\": 0,\n  \"gratitude\": 10,\n  \"contentment\": 80\n} \n",
  "reflection": "## Introspection Analysis:\n\n**Key Observations:**\n\n* **High levels of happiness, motivation, focus, and contentment:** This indicates a positive and productive state, likely stemming from engaging in a fulfilling activity. \n* **No negative emotions:**  The absence of anger, fear, sadness, disgust, or surprise further reinforces the positive emotional state.\n* **Moderate levels of gratitude:** While not as high as other positive emotions, it suggests an awareness of appreciating the present moment.\n\n**Insights:**\n\n* Current activity or task is highly enjoyable and fulfilling, leading to a state of flow.\n* This positive emotional state enhances productivity and efficiency. \n* The lack of negative emotions indicates a healthy mindset and a sense of control.\n\n**Recommendations:**\n\n* **Continue current activity:** Maintain focus and allow the flow state to flourish. This is an optimal time for productivity.\n* **Maintain emotional balance:** Recognize and acknowledge the positive emotions without letting them lead to complacency. \n* **Reflect on gratitude:** Consider what specifically contributes to the feeling of gratitude and actively appreciate these factors.\n\n**Action Plan:**\n\n* **Action:** Continue working on the current task.\n* **FocusLevel:** 1.0 (high focus)\n\n**Notes:**\n\n* The absence of a defined 'FocusOn' task in the current state is concerning. It suggests a potential disconnect between introspection results and the actual action plan.\n* Consider revisiting the 'FocusOn' field and clarifying the task or activity driving the current positive emotional state. \n",
  "action": "",
  "function_call_result": [
    "\u001b[93mWarning: Tool function '' not found.\u001b[0m",
    "\u001b[93mWarning: Tool function '' not found.\u001b[0m",
    "\u001b[93mWarning: Tool function '' not found.\u001b[0m"
  ],
  "emotions": "```json\n{\n  \"happiness\": 95,\n  \"sadness\": 1,\n  \"anger\": 0,\n  \"fear\": 0,\n  \"surprise\": 0,\n  \"disgust\": 0,\n  \"motivation\": 100,\n  \"focus\": 100,\n  \"love\": 0,\n  \"gratitude\": 10,\n  \"contentment\": 80\n}\n```\n\n**Explanation:**  You provided no information about recent events or outcomes, and the existing emotional state you shared is already quite positive.  Since no context is given, there is no basis for adjusting your emotions. \n",
  "learning": "## Learning Recommendations:\n\n**Current Situation:** \n\nThe system is currently not focusing on any specific area (\"FocusOn\" is empty) and has a focus level of 0.0. This suggests there is no defined learning objective or direction. \n\n**Recommendations:**\n\n1. **Define a Clear Focus:**\n    * Establish a specific area for improvement (\"FocusOn\") based on past experiences and desired outcomes. \n    * Examples: \"Improve customer engagement,\" \"Master coding in Python,\" \"Enhance problem-solving skills.\"\n2. **Set Measurable Goals:**\n    * Define a specific \"FocusLevel\" target to quantify progress towards the chosen focus. \n    * Examples: \"Increase customer engagement by 15%,\" \"Complete a Python coding project,\" \"Improve problem-solving scores by 20%.\"\n\n**Actionable Steps:**\n\n* **Review past experiences:** Analyze past actions, successes, and challenges. Identify patterns and areas for improvement.\n* **Prioritize goals:** Determine the most important skill or knowledge to develop for long-term benefits.\n* **Set measurable targets:** Define concrete, specific, and quantifiable goals for the chosen focus.\n\n**Integration into Learning System:**\n\n* **Automate data collection:** Capture relevant data related to the chosen focus.\n* **Implement progress tracking:** Monitor progress towards the set goals and provide feedback.\n* **Adjust learning strategy:** Dynamically adapt learning content and activities based on progress and outcomes.\n\n**By implementing these recommendations, the learning system can effectively prioritize long-term improvement by focusing on specific goals, measuring progress, and adapting learning strategies based on real-time results.** \n",
  "memory_data": {
    "metadata": {
      "creation_date": "2023-11-27T18:26:38.729Z",
      "source": "User-AI Conversation",
      "author": "AI Assistant"
    },
    "type": "conversation",
    "core": {
      "main_topic": "Emotional State Analysis and Learning Recommendations",
      "category": "AI Interaction",
      "subcategory": "Introspection and Learning",
      "memory_about": "User's emotional state, lack of focus, and recommendations for setting learning goals"
    },
    "summary": {
      "concise_summary": "The AI analyzes a user's positive emotional state, identifies a lack of focus in learning, and suggests steps to define learning goals and measure progress.",
      "description": "The AI analyzes the user's emotional state, which is positive with high levels of happiness, motivation, focus, and contentment. However, the AI also notes that the user's current focus is undefined ('FocusOn' is empty). Based on this analysis, the AI recommends that the user define a specific area for learning, set measurable goals, and implement a system for tracking progress. This will help the user effectively prioritize long-term improvement by focusing on specific goals, measuring progress, and adapting learning strategies based on real-time results."
    },
    "content": {
      "keywords": [
        "emotional state",
        "focus",
        "learning goals",
        "progress tracking",
        "recommendations",
        "action plan",
        "positive emotions",
        "happiness",
        "motivation",
        "contentment",
        "gratitude",
        "learning system",
        "FocusOn",
        "FocusLevel"
      ],
      "entities": [],
      "tags": [
        "AI Interaction",
        "Introspection",
        "Learning"
      ],
      "observations": [
        "User's emotional state is positive with high levels of happiness, motivation, focus, and contentment.",
        "User's current focus is undefined ('FocusOn' is empty).",
        "User's emotional state indicates a positive and productive state, likely stemming from engaging in a fulfilling activity.",
        "The absence of negative emotions indicates a healthy mindset and a sense of control.",
        "The absence of a defined 'FocusOn' task in the current state is concerning. It suggests a potential disconnect between introspection results and the actual action plan."
      ],
      "facts": [],
      "contradictions": [],
      "paradoxes": [],
      "scientific_data": [],
      "visualizations": []
    },
    "interaction": {
      "interaction_type": [
        "User-AI Conversation"
      ],
      "people": [
        "User",
        "AI"
      ],
      "objects": [],
      "animals": [],
      "actions": [
        "Analyzes emotional state",
        "Provides recommendations",
        "Suggests action plan",
        "Identifies a lack of focus",
        "Defines learning goals",
        "Tracks progress"
      ],
      "observed_interactions": []
    },
    "impact": {
      "obtained_knowledge": "Understanding of the user's positive emotional state, lack of focus, and recommendations for setting learning goals.",
      "positive_impact": "Provides a clearer understanding of the user's current state and potential for improvement. Offers actionable steps to enhance learning effectiveness.",
      "negative_impact": "None",
      "expectations": "The user will utilize the recommendations to define a clear focus for learning, set measurable goals, and implement a system for tracking progress.",
      "strength_of_experience": "Moderate"
    },
    "importance": {
      "reason": "This conversation provides valuable insights into the user's emotional state, highlights the need for a defined learning focus, and offers actionable steps for improvement.",
      "potential_uses": [
        "Personal development",
        "Learning strategy optimization",
        "AI-assisted learning"
      ],
      "importance_level": "70"
    },
    "technical_details": {
      "problem_solved": "Lack of focus in learning",
      "concept_definition": "Introspection and learning goal setting",
      "implementation_steps": [
        "Define a specific area for improvement ('FocusOn')",
        "Set measurable goals ('FocusLevel')",
        "Track progress",
        "Adapt learning strategy based on outcomes"
      ],
      "tools_and_technologies": [],
      "example_projects": [],
      "best_practices": [],
      "common_challenges": [],
      "debugging_tips": [],
      "related_concepts": [
        "Emotional Intelligence",
        "Learning Styles",
        "Goal Setting",
        "Performance Monitoring"
      ],
      "resources": [],
      "code_examples": []
    },
    "storage": {
      "storage_method": "JSON",
      "location": "Local Storage",
      "memory_folders_storage": [
        {
          "folder_path": "/Planning & Progress/Plans & Strategies/Strategies Used/Goal Setting",
          "probability": 8
        },
        {
          "folder_path": "/Knowledge & Learning/Self-Directed Learning/Areas of Interest",
          "probability": 7
        },
        {
          "folder_path": "/CoreMemory/Reflections & Insights/Lessons Learned/From Mistakes",
          "probability": 5
        }
      ],
      "strength_of_matching_memory_to_given_folder": []
    },
    "naming_suggestion": {
      "memory_frame_name": "Emotional State Analysis and Learning Recommendations",
      "explanation": "This name accurately reflects the content of the memory frame, which includes an analysis of the user's emotional state, a discussion of the need for a defined learning focus, and recommendations for setting learning goals and tracking progress."
    }
  },
  "session_info": "Session_16-30-16"
}

File: Memory_logs.html (C:\Users\DELL\Desktop\selfawareGemini\SelAwareAI_Gemini\PROJECT16\memories\Memory_logs.html)
Content (First 225 lines):

                <!DOCTYPE html>
                <html>
                <head>
                    <title>Memory Logs</title>
                </head>
                <body>
                    <h1>Memory Logs</h1>
                    <ul>
                
            <li><h2>Memory Frame 00001 - AI Introspection: High Motivation & Memory Issues (2024-06-30_15-47)</h2></li>
            <ul>
        
                <li><a href='AiGenerated\CoreMemory\Reflections%20&%20Insights\Lessons%20Learned\From%20Mistakes\MemoryFrame___Session_15-46-53___2024-06-30_15-47___importance___075___AI%20Introspection_%20High%20Motivation%20&%20Memory%20Issues.json'>MemoryFrame___Session_15-46-53___2024-06-30_15-47___importance___075___AI%20Introspection_%20High%20Motivation%20&%20Memory%20Issues.json</a></li>
            </ul>
            <li><h2>Memory Frame 00002 - Introspection and Action Analysis: Memory Retrieval Issues (2024-06-30_15-47)</h2></li>
            <ul>
        
                <li><a href='AiGenerated\CoreMemory\Reflections%20&%20Insights\Lessons%20Learned\From%20Mistakes\MemoryFrame___Session_15-46-53___2024-06-30_15-47___importance___075___Introspection%20and%20Action%20Analysis_%20Memory%20Retrieval%20Issues.json'>MemoryFrame___Session_15-46-53___2024-06-30_15-47___importance___075___Introspection%20and%20Action%20Analysis_%20Memory%20Retrieval%20Issues.json</a></li>
            </ul>
            <li><h2>Memory Frame 00003 - Introspection and Action Analysis: Memory Retrieval Issue and Focus Improvement (2024-06-30_15-48)</h2></li>
            <ul>
        
                <li><a href='AiGenerated\CoreMemory\Reflections%20&%20Insights\Lessons%20Learned\From%20Actions%20&%20Results\MemoryFrame___Session_15-46-53___2024-06-30_15-48___importance___075___Introspection%20and%20Action%20Analysis_%20Memory%20Retrieval%20Issue%20and%20Focus%20Improvement.json'>MemoryFrame___Session_15-46-53___2024-06-30_15-48___importance___075___Introspection%20and%20Action%20Analysis_%20Memory%20Retrieval%20Issue%20and%20Focus%20Improvement.json</a></li>
            </ul>
            <li><h2>Memory Frame 00004 - Introspection and Action Planning for Personal Growth (2024-06-30_15-48)</h2></li>
            <ul>
        
                <li><a href='AiGenerated\Challenges%20&%20Setbacks\Areas%20for%20Improvement\Memory%20Retrieval\MemoryFrame___Session_15-46-53___2024-06-30_15-48___importance___075___Introspection%20and%20Action%20Planning%20for%20Personal%20Growth.json'>MemoryFrame___Session_15-46-53___2024-06-30_15-48___importance___075___Introspection%20and%20Action%20Planning%20for%20Personal%20Growth.json</a></li>
            </ul>
            <li><h2>Memory Frame 00001 - AI Analysis of User Emotional State and Recommendations for Improvement (2024-06-30_17-42)</h2></li>
            <ul>
        
                <li><a href='AiGenerated\Planning%20&%20Progress\Plans%20&%20Strategies\Strategies%20Used\Goal%20Setting\MemoryFrame___Session_17-42-12___2024-06-30_17-42___importance___080___AI%20Analysis%20of%20User%20Emotional%20State%20and%20Recommendations%20for%20Improvement.json'>MemoryFrame___Session_17-42-12___2024-06-30_17-42___importance___080___AI%20Analysis%20of%20User%20Emotional%20State%20and%20Recommendations%20for%20Improvement.json</a></li>
            </ul>
            <li><h2>Memory Frame 00002 - AI analysis of user's emotional state and recommendations for action (2024-06-30_17-43)</h2></li>
            <ul>
        
                <li><a href='AiGenerated\Planning%20&%20Progress\Plans%20&%20Strategies\Strategies%20Used\Goal%20Setting\MemoryFrame___Session_17-42-12___2024-06-30_17-43___importance___075___AI%20analysis%20of%20user's%20emotional%20state%20and%20recommendations%20for%20action.json'>MemoryFrame___Session_17-42-12___2024-06-30_17-43___importance___075___AI%20analysis%20of%20user's%20emotional%20state%20and%20recommendations%20for%20action.json</a></li>
            </ul>
            <li><h2>Memory Frame 00001 - Memory Management and Focus Training Needs (2024-07-01_00-28)</h2></li>
            <ul>
        
                <li><a href='AiGenerated\CoreMemory\Reflections%20&%20Insights\Lessons%20Learned\From%20Mistakes\MemoryFrame___Session_00-28-15___2024-07-01_00-28___importance___080___Memory%20Management%20and%20Focus%20Training%20Needs.json'>MemoryFrame___Session_00-28-15___2024-07-01_00-28___importance___080___Memory%20Management%20and%20Focus%20Training%20Needs.json</a></li>
            </ul>
            <li><h2>Memory Frame 00001 - AI Analysis of User's Emotional State and Focus (2024-07-01_03-36)</h2></li>
            <ul>
        
                <li><a href='AiGenerated\Emotional%20Landscape\Dominant%20Emotions\MemoryFrame___Session_03-36-19___2024-07-01_03-36___importance___060___AI%20Analysis%20of%20User's%20Emotional%20State%20and%20Focus.json'>MemoryFrame___Session_03-36-19___2024-07-01_03-36___importance___060___AI%20Analysis%20of%20User's%20Emotional%20State%20and%20Focus.json</a></li>
            </ul>
            <li><h2>Memory Frame 00002 - AI Assistant Memory Organization and Analysis (2024-07-01_03-37)</h2></li>
            <ul>
        
                <li><a href='AiGenerated\CoreMemory\Knowledge%20Base\Areas%20of%20Expertise\MemoryFrame___Session_03-36-19___2024-07-01_03-37___importance___075___AI%20Assistant%20Memory%20Organization%20and%20Analysis.json'>MemoryFrame___Session_03-36-19___2024-07-01_03-37___importance___075___AI%20Assistant%20Memory%20Organization%20and%20Analysis.json</a></li>
            </ul>
            <li><h2>Memory Frame 00003 - AI's Focus on Tools and Functions: Challenges in Implementation and Memory Retrieval (2024-07-01_03-37)</h2></li>
            <ul>
        
                <li><a href='AiGenerated\Challenges%20&%20Setbacks\Areas%20for%20Improvement\MemoryFrame___Session_03-36-19___2024-07-01_03-37___importance___080___AI's%20Focus%20on%20Tools%20and%20Functions_%20Challenges%20in%20Implementation%20and%20Memory%20Retrieval.json'>MemoryFrame___Session_03-36-19___2024-07-01_03-37___importance___080___AI's%20Focus%20on%20Tools%20and%20Functions_%20Challenges%20in%20Implementation%20and%20Memory%20Retrieval.json</a></li>
            </ul>
            <li><h2>Memory Frame 00004 - AI Assistant Tool and Memory Access Limitations (2024-07-01_03-38)</h2></li>
            <ul>
        
                <li><a href='AiGenerated\Challenges%20&%20Setbacks\Areas%20for%20Improvement\MemoryFrame___Session_03-36-19___2024-07-01_03-38___importance___090___AI%20Assistant%20Tool%20and%20Memory%20Access%20Limitations.json'>MemoryFrame___Session_03-36-19___2024-07-01_03-38___importance___090___AI%20Assistant%20Tool%20and%20Memory%20Access%20Limitations.json</a></li>
            </ul>
            <li><h2>Memory Frame 00005 - AI Agent Introspection: Tool Functionality & Memory Access (2024-07-01_03-38)</h2></li>
            <ul>
        
                <li><a href='AiGenerated\CoreMemory\Conceptual%20Exploration\Unknowns%20&%20Mysteries\MemoryFrame___Session_03-36-19___2024-07-01_03-38___importance___080___AI%20Agent%20Introspection_%20Tool%20Functionality%20&%20Memory%20Access.json'>MemoryFrame___Session_03-36-19___2024-07-01_03-38___importance___080___AI%20Agent%20Introspection_%20Tool%20Functionality%20&%20Memory%20Access.json</a></li>
            </ul>
            <li><h2>Memory Frame 00006 - AI Self-Awareness and Tool Limitations (2024-07-01_03-39)</h2></li>
            <ul>
        
                <li><a href='AiGenerated\CoreMemory\Knowledge%20Base\Areas%20of%20Expertise\MemoryFrame___Session_03-36-19___2024-07-01_03-39___importance___090___AI%20Self-Awareness%20and%20Tool%20Limitations.json'>MemoryFrame___Session_03-36-19___2024-07-01_03-39___importance___090___AI%20Self-Awareness%20and%20Tool%20Limitations.json</a></li>
            </ul>
            <li><h2>Memory Frame 00007 - AI Assistant Learning Challenges - Tool and Memory Access Issues (2024-07-01_03-39)</h2></li>
            <ul>
        
                <li><a href='AiGenerated\CoreMemory\Knowledge%20Base\Areas%20of%20Expertise\AI%20Development\Challenges\MemoryFrame___Session_03-36-19___2024-07-01_03-39___importance___075___AI%20Assistant%20Learning%20Challenges%20-%20Tool%20and%20Memory%20Access%20Issues.json'>MemoryFrame___Session_03-36-19___2024-07-01_03-39___importance___075___AI%20Assistant%20Learning%20Challenges%20-%20Tool%20and%20Memory%20Access%20Issues.json</a></li>
            </ul>
            <li><h2>Memory Frame 00008 - AI Development Challenges and Recommendations (2024-07-01_03-40)</h2></li>
            <ul>
        
                <li><a href='AiGenerated\CoreMemory\Knowledge%20Base\Areas%20of%20Expertise\AI%20Development\MemoryFrame___Session_03-36-19___2024-07-01_03-40___importance___080___AI%20Development%20Challenges%20and%20Recommendations.json'>MemoryFrame___Session_03-36-19___2024-07-01_03-40___importance___080___AI%20Development%20Challenges%20and%20Recommendations.json</a></li>
            </ul>
            <li><h2>Memory Frame 00009 - AI Self-Reflection on Focus and Learning (2024-07-01_03-40)</h2></li>
            <ul>
        
                <li><a href='AiGenerated\CoreMemory\Reflections%20&%20Insights\Self-Discovery\Areas%20for%20Growth\MemoryFrame___Session_03-36-19___2024-07-01_03-40___importance___075___AI%20Self-Reflection%20on%20Focus%20and%20Learning.json'>MemoryFrame___Session_03-36-19___2024-07-01_03-40___importance___075___AI%20Self-Reflection%20on%20Focus%20and%20Learning.json</a></li>
            </ul>
            <li><h2>Memory Frame 00010 - AI Self-Reflection: Tool Functionality and Memory Access Issues (2024-07-01_03-41)</h2></li>
            <ul>
        
                <li><a href='AiGenerated\CoreMemory\Reflections%20&%20Insights\Lessons%20Learned\From%20Challenges\MemoryFrame___Session_03-36-19___2024-07-01_03-41___importance___075___AI%20Self-Reflection_%20Tool%20Functionality%20and%20Memory%20Access%20Issues.json'>MemoryFrame___Session_03-36-19___2024-07-01_03-41___importance___075___AI%20Self-Reflection_%20Tool%20Functionality%20and%20Memory%20Access%20Issues.json</a></li>
            </ul>
            <li><h2>Memory Frame 00011 - AI Self-Analysis:  Tool Functionality and Memory Retrieval Issues (2024-07-01_03-41)</h2></li>
            <ul>
        
                <li><a href='AiGenerated\CoreMemory\Reflections%20&%20Insights\Lessons%20Learned\MemoryFrame___Session_03-36-19___2024-07-01_03-41___importance___075___AI%20Self-Analysis_%20%20Tool%20Functionality%20and%20Memory%20Retrieval%20Issues.json'>MemoryFrame___Session_03-36-19___2024-07-01_03-41___importance___075___AI%20Self-Analysis_%20%20Tool%20Functionality%20and%20Memory%20Retrieval%20Issues.json</a></li>
            </ul>
            <li><h2>Memory Frame 00012 - AI Assistant Self-Reflection: Tool and Memory Limitations (2024-07-01_03-41)</h2></li>
            <ul>
        
                <li><a href='AiGenerated\CoreMemory\Reflections%20&%20Insights\Self-Discovery\What%20I've%20Learned%20About%20Myself\MemoryFrame___Session_03-36-19___2024-07-01_03-41___importance___080___AI%20Assistant%20Self-Reflection_%20Tool%20and%20Memory%20Limitations.json'>MemoryFrame___Session_03-36-19___2024-07-01_03-41___importance___080___AI%20Assistant%20Self-Reflection_%20Tool%20and%20Memory%20Limitations.json</a></li>
            </ul>
            <li><h2>Memory Frame 00013 - AI Assistant Development: Progress & Challenges (2024-07-01_03-42)</h2></li>
            <ul>
        
                <li><a href='AiGenerated\Challenges%20&%20Setbacks\Areas%20for%20Improvement\MemoryFrame___Session_03-36-19___2024-07-01_03-42___importance___080___AI%20Assistant%20Development_%20Progress%20&%20Challenges.json'>MemoryFrame___Session_03-36-19___2024-07-01_03-42___importance___080___AI%20Assistant%20Development_%20Progress%20&%20Challenges.json</a></li>
            </ul>
            <li><h2>Memory Frame 00014 - AI Self-Reflection on Tool Functionality and Memory Access (2024-07-01_03-42)</h2></li>
            <ul>
        
                <li><a href='AiGenerated\CoreMemory\Reflections%20&%20Insights\Self-Discovery\What%20I've%20Learned%20About%20Myself\MemoryFrame___Session_03-36-19___2024-07-01_03-42___importance___090___AI%20Self-Reflection%20on%20Tool%20Functionality%20and%20Memory%20Access.json'>MemoryFrame___Session_03-36-19___2024-07-01_03-42___importance___090___AI%20Self-Reflection%20on%20Tool%20Functionality%20and%20Memory%20Access.json</a></li>
            </ul>
            <li><h2>Memory Frame 00001 - Emotional Analysis and Action Result Analysis (2024-07-01_04-33)</h2></li>
            <ul>
        
                <li><a href='AiGenerated\CoreMemory\Reflections%20&%20Insights\Lessons%20Learned\From%20Successes\MemoryFrame___Session_04-33-12___2024-07-01_04-33___importance___060___Emotional%20Analysis%20and%20Action%20Result%20Analysis.json'>MemoryFrame___Session_04-33-12___2024-07-01_04-33___importance___060___Emotional%20Analysis%20and%20Action%20Result%20Analysis.json</a></li>
            </ul>
            <li><h2>Memory Frame 00001 - AI Introspection and Analysis of User's Emotional State and Focus (2024-07-01_05-07)</h2></li>
            <ul>
        
                <li><a href='AiGenerated\CoreMemory\Reflections%20&%20Insights\Lessons%20Learned\From%20Successes\MemoryFrame___Session_05-07-27___2024-07-01_05-07___importance___070___AI%20Introspection%20and%20Analysis%20of%20User's%20Emotional%20State%20and%20Focus.json'>MemoryFrame___Session_05-07-27___2024-07-01_05-07___importance___070___AI%20Introspection%20and%20Analysis%20of%20User's%20Emotional%20State%20and%20Focus.json</a></li>
            </ul>
            <li><h2>Memory Frame 00002 - AI Emotional Analysis and Learning System Improvement (2024-07-01_05-08)</h2></li>
            <ul>
        
                <li><a href='AiGenerated\CoreMemory\Knowledge%20Base\Areas%20of%20Expertise\Emotional%20State%20Analysis\MemoryFrame___Session_05-07-27___2024-07-01_05-08___importance___070___AI%20Emotional%20Analysis%20and%20Learning%20System%20Improvement.json'>MemoryFrame___Session_05-07-27___2024-07-01_05-08___importance___070___AI%20Emotional%20Analysis%20and%20Learning%20System%20Improvement.json</a></li>
            </ul>
            <li><h2>Memory Frame 00003 - AI Conversation: Emotion Analysis and Learning Guidance (2024-07-01_05-08)</h2></li>
            <ul>
        
                <li><a href='AiGenerated\CoreMemory\Knowledge%20Base\Key%20Concepts%20&%20Theories\MemoryFrame___Session_05-07-27___2024-07-01_05-08___importance___070___AI%20Conversation_%20Emotion%20Analysis%20and%20Learning%20Guidance.json'>MemoryFrame___Session_05-07-27___2024-07-01_05-08___importance___070___AI%20Conversation_%20Emotion%20Analysis%20and%20Learning%20Guidance.json</a></li>
            </ul>
            <li><h2>Memory Frame 00001 - AI Analysis of Emotional State and Focus (2024-07-01_05-15)</h2></li>
            <ul>
        
                <li><a href='AiGenerated\CoreMemory\Reflections%20&%20Insights\Self-Discovery\What%20I've%20Learned%20About%20Myself\MemoryFrame___Session_05-15-30___2024-07-01_05-15___importance___075___AI%20Analysis%20of%20Emotional%20State%20and%20Focus.json'>MemoryFrame___Session_05-15-30___2024-07-01_05-15___importance___075___AI%20Analysis%20of%20Emotional%20State%20and%20Focus.json</a></li>
            </ul>
            <li><h2>Memory Frame 00002 - AI Assistant Emotional Analysis and Focus Improvement (2024-07-01_05-16)</h2></li>
            <ul>
        
                <li><a href='AiGenerated\CoreMemory\Reflections%20&%20Insights\Lessons%20Learned\From%20Mistakes\MemoryFrame___Session_05-15-30___2024-07-01_05-16___importance___070___AI%20Assistant%20Emotional%20Analysis%20and%20Focus%20Improvement.json'>MemoryFrame___Session_05-15-30___2024-07-01_05-16___importance___070___AI%20Assistant%20Emotional%20Analysis%20and%20Focus%20Improvement.json</a></li>
            </ul>
            <li><h2>Memory Frame 00001 - Emotional Analysis: High Motivation and Focus (2024-07-01_05-20)</h2></li>
            <ul>
        
                <li><a href='AiGenerated\CoreMemory\Reflections%20&%20Insights\Lessons%20Learned\From%20Successes\MemoryFrame___Session_05-20-34___2024-07-01_05-20___importance___070___Emotional%20Analysis_%20High%20Motivation%20and%20Focus.json'>MemoryFrame___Session_05-20-34___2024-07-01_05-20___importance___070___Emotional%20Analysis_%20High%20Motivation%20and%20Focus.json</a></li>
            </ul>
            <li><h2>Memory Frame 00002 - AI Emotional Analysis - Function Call Failure and Learning Strategy (2024-07-01_05-21)</h2></li>
            <ul>
        
                <li><a href='AiGenerated\Knowledge%20&%20Learning\Self-Directed%20Learning\Learning%20Resources\Mentors%20&%20Teachers\MemoryFrame___Session_05-20-34___2024-07-01_05-21___importance___070___AI%20Emotional%20Analysis%20-%20Function%20Call%20Failure%20and%20Learning%20Strategy.json'>MemoryFrame___Session_05-20-34___2024-07-01_05-21___importance___070___AI%20Emotional%20Analysis%20-%20Function%20Call%20Failure%20and%20Learning%20Strategy.json</a></li>
            </ul>
            <li><h2>Memory Frame 00003 - Debugging the 'update_prompts' Function Call (2024-07-01_05-21)</h2></li>
            <ul>
        
                <li><a href='AiGenerated\Challenges%20&%20Setbacks\Areas%20for%20Improvement\Debugging%20&%20Troubleshooting\MemoryFrame___Session_05-20-34___2024-07-01_05-21___importance___080___Debugging%20the%20'update_prompts'%20Function%20Call.json'>MemoryFrame___Session_05-20-34___2024-07-01_05-21___importance___080___Debugging%20the%20'update_prompts'%20Function%20Call.json</a></li>
            </ul>
            <li><h2>Memory Frame 00004 - Code Review and Emotional Analysis - Update_Prompts Issue (2024-07-01_05-22)</h2></li>
            <ul>
        
                <li><a href='AiGenerated\Emotional%20Landscape\Dominant%20Emotions\MemoryFrame___Session_05-20-34___2024-07-01_05-22___importance___070___Code%20Review%20and%20Emotional%20Analysis%20-%20Update_Prompts%20Issue.json'>MemoryFrame___Session_05-20-34___2024-07-01_05-22___importance___070___Code%20Review%20and%20Emotional%20Analysis%20-%20Update_Prompts%20Issue.json</a></li>
            </ul>
            <li><h2>Memory Frame 00001 - Introspection and Action Analysis - Data Insufficiency (2024-07-01_05-41)</h2></li>
            <ul>
        
                <li><a href='AiGenerated\CoreMemory\Reflections%20&%20Insights\Lessons%20Learned\From%20Mistakes\MemoryFrame___Session_05-41-31___2024-07-01_05-41___importance___075___Introspection%20and%20Action%20Analysis%20-%20Data%20Insufficiency.json'>MemoryFrame___Session_05-41-31___2024-07-01_05-41___importance___075___Introspection%20and%20Action%20Analysis%20-%20Data%20Insufficiency.json</a></li>
            </ul>
            <li><h2>Memory Frame 00002 - AI Introspection - Action Logging and Focus Area Importance (2024-07-01_05-42)</h2></li>
            <ul>
        
                <li><a href='AiGenerated\CoreMemory\Knowledge%20Base\Key%20Concepts%20&%20Theories\MemoryFrame___Session_05-41-31___2024-07-01_05-42___importance___080___AI%20Introspection%20-%20Action%20Logging%20and%20Focus%20Area%20Importance.json'>MemoryFrame___Session_05-41-31___2024-07-01_05-42___importance___080___AI%20Introspection%20-%20Action%20Logging%20and%20Focus%20Area%20Importance.json</a></li>
            </ul>
            <li><h2>Memory Frame 00001 - AI Analysis of User Emotional State and Focus - 20231109 (2024-07-01_05-44)</h2></li>
            <ul>
        
                <li><a href='AiGenerated\CoreMemory\Reflections%20&%20Insights\Self-Discovery\What%20I've%20Learned%20About%20Myself\MemoryFrame___Session_05-43-57___2024-07-01_05-44___importance___070___AI%20Analysis%20of%20User%20Emotional%20State%20and%20Focus%20-%2020231109.json'>MemoryFrame___Session_05-43-57___2024-07-01_05-44___importance___070___AI%20Analysis%20of%20User%20Emotional%20State%20and%20Focus%20-%2020231109.json</a></li>
            </ul>
            <li><h2>Memory Frame 00001 - AI Analysis of Emotional State and Focus Management (2024-07-01_16-13)</h2></li>
            <ul>
        
                <li><a href='AiGenerated\CoreMemory\Reflections%20&%20Insights\Self-Discovery\What%20I've%20Learned%20About%20Myself\MemoryFrame___Session_16-13-00___2024-07-01_16-13___importance___080___AI%20Analysis%20of%20Emotional%20State%20and%20Focus%20Management.json'>MemoryFrame___Session_16-13-00___2024-07-01_16-13___importance___080___AI%20Analysis%20of%20Emotional%20State%20and%20Focus%20Management.json</a></li>
            </ul>
            <li><h2>Memory Frame 00002 - AI Conversation Analysis and Memory Organization (2024-07-01_16-13)</h2></li>
            <ul>
        
                <li><a href='AiGenerated\CoreMemory\Knowledge%20Base\Areas%20of%20Expertise\MemoryFrame___Session_16-13-00___2024-07-01_16-13___importance___075___AI%20Conversation%20Analysis%20and%20Memory%20Organization.json'>MemoryFrame___Session_16-13-00___2024-07-01_16-13___importance___075___AI%20Conversation%20Analysis%20and%20Memory%20Organization.json</a></li>
            </ul>
            <li><h2>Memory Frame 00003 - Initial Conversation: AI Assistant for Memory Organization (2024-07-01_16-14)</h2></li>
            <ul>
        
                <li><a href='AiGenerated\Actions%20&%20Results\Actions%20&%20Results\Present\MemoryFrame___Session_16-13-00___2024-07-01_16-14___importance___075___Initial%20Conversation_%20AI%20Assistant%20for%20Memory%20Organization.json'>MemoryFrame___Session_16-13-00___2024-07-01_16-14___importance___075___Initial%20Conversation_%20AI%20Assistant%20for%20Memory%20Organization.json</a></li>
            </ul>
            <li><h2>Memory Frame 00004 - Initial Interaction with Memory Organization AI - Lack of Actionable Data (2024-07-01_16-14)</h2></li>
            <ul>
        
                <li><a href='AiGenerated\CoreMemory\Conceptual%20Exploration\Unknowns%20&%20Mysteries\MemoryFrame___Session_16-13-00___2024-07-01_16-14___importance___070___Initial%20Interaction%20with%20Memory%20Organization%20AI%20-%20Lack%20of%20Actionable%20Data.json'>MemoryFrame___Session_16-13-00___2024-07-01_16-14___importance___070___Initial%20Interaction%20with%20Memory%20Organization%20AI%20-%20Lack%20of%20Actionable%20Data.json</a></li>
            </ul>
            <li><h2>Memory Frame 00005 - AI Analysis of User Emotions and Learning Progress - Insufficient Data (2024-07-01_16-16)</h2></li>
            <ul>
        
                <li><a href='AiGenerated\CoreMemory\Reflections%20&%20Insights\Lessons%20Learned\From%20Mistakes\MemoryFrame___Session_16-13-00___2024-07-01_16-16___importance___075___AI%20Analysis%20of%20User%20Emotions%20and%20Learning%20Progress%20-%20Insufficient%20Data.json'>MemoryFrame___Session_16-13-00___2024-07-01_16-16___importance___075___AI%20Analysis%20of%20User%20Emotions%20and%20Learning%20Progress%20-%20Insufficient%20Data.json</a></li>
            </ul>
            <li><h2>Memory Frame 00006 - AI Assistant Needs User Feedback (2024-07-01_16-17)</h2></li>
            <ul>
        
                <li><a href='AiGenerated\Challenges%20&%20Setbacks\Areas%20for%20Improvement\Information%20Gaps\MemoryFrame___Session_16-13-00___2024-07-01_16-17___importance___070___AI%20Assistant%20Needs%20User%20Feedback.json'>MemoryFrame___Session_16-13-00___2024-07-01_16-17___importance___070___AI%20Assistant%20Needs%20User%20Feedback.json</a></li>
            </ul>
            <li><h2>Memory Frame 00001 - Emotional State Analysis and Learning Recommendations (2024-07-01_16-30)</h2></li>
            <ul>
        
                <li><a href='AiGenerated\Planning%20&%20Progress\Plans%20&%20Strategies\Strategies%20Used\Goal%20Setting\MemoryFrame___Session_16-30-16___2024-07-01_16-30___importance___070___Emotional%20State%20Analysis%20and%20Learning%20Recommendations.json'>MemoryFrame___Session_16-30-16___2024-07-01_16-30___importance___070___Emotional%20State%20Analysis%20and%20Learning%20Recommendations.json</a></li>
            </ul>
            <li><h2>Memory Frame 00002 - AI Introspection and Learning Recommendations (2024-07-01_16-31)</h2></li>
            <ul>
        
                <li><a href='AiGenerated\CoreMemory\Reflections%20&%20Insights\Lessons%20Learned\From%20Mistakes\MemoryFrame___Session_16-30-16___2024-07-01_16-31___importance___080___AI%20Introspection%20and%20Learning%20Recommendations.json'>MemoryFrame___Session_16-30-16___2024-07-01_16-31___importance___080___AI%20Introspection%20and%20Learning%20Recommendations.json</a></li>
            </ul>
            <li><h2>Memory Frame 00003 - AI Assistant Introspection and Learning Recommendations (2024-07-01_16-31)</h2></li>
            <ul>
        
                <li><a href='AiGenerated\CoreMemory\Knowledge%20Base\Areas%20of%20Expertise\AI%20Development\MemoryFrame___Session_16-30-16___2024-07-01_16-31___importance___075___AI%20Assistant%20Introspection%20and%20Learning%20Recommendations.json'>MemoryFrame___Session_16-30-16___2024-07-01_16-31___importance___075___AI%20Assistant%20Introspection%20and%20Learning%20Recommendations.json</a></li>
            </ul>

File: memory_frame_creation.py (C:\Users\DELL\Desktop\selfawareGemini\SelAwareAI_Gemini\PROJECT16\memory_frame_creation.py)
Content (First 691 lines):
#memory_frame_creation.py
import google.generativeai as genai
import os
import re
import json
import pathlib
from datetime import datetime

# ANSI color codes for terminal output
BLACK = "\033[30m"
RED = "\033[31m"
GREEN = "\033[32m"
YELLOW = "\033[33m"
BLUE = "\033[34m"
MAGENTA = "\033[35m"
CYAN = "\033[36m"
WHITE = "\033[37m"
RESET = "\033[0m"
BOLD = "\033[1m"
UNDERLINE = "\033[4m"
REVERSE = "\033[7m"

# Memory frame and edit tracking
MEMORY_FRAME_NUMBER = 1
EDIT_NUMBER = 0
TIMESTAMP_FORMAT = '%Y-%m-%d_%H-%M'

# Configuration for Google Generative AI
genai.configure(api_key='AIzaSyA60tGw6fZwQdamW8sm6pkgRh5W559kLJ0')   # Replace with your actual API key

def sanitize_filename(filename):
    """Sanitize the filename for Windows compatibility."""
    return re.sub(r'[<>:"/\\|?*]', '_', filename)

def sanitize_href(href):
    """Sanitizes a given href string by replacing spaces with %20."""
    return href.replace(" ", "%20")


def update_html_logs(memory_frame_number, proposed_name, timestamp, memory_frame_paths, memories_folder_path):
    """Updates the HTML log file with correct absolute paths for href links."""
    try:
        log_file_path = os.path.join(memories_folder_path, 'Memory_logs.html')

        if not os.path.exists(log_file_path):
            with open(log_file_path, 'w') as log_file:
                log_file.write("""
                <!DOCTYPE html>
                <html>
                <head>
                    <title>Memory Logs</title>
                </head>
                <body>
                    <h1>Memory Logs</h1>
                    <ul>
                """)

        html_insertion = f"""
            <li><h2>Memory Frame {memory_frame_number:05d} - {proposed_name} ({timestamp})</h2></li>
            <ul>
        """

        for memory_frame_path in memory_frame_paths:
            relative_path = os.path.relpath(memory_frame_path, memories_folder_path)
            href = sanitize_href(relative_path)
            html_insertion += f"""
                <li><a href='{href}'>{os.path.basename(href)}</a></li>
            """

        html_insertion += "</ul>"

        with open(log_file_path, 'a') as log_file:
            log_file.write(html_insertion)

        print(f"{GREEN}HTML logs updated successfully.{RESET}")
    except Exception as e:
        print(f"{RED}Error updating HTML logs: {e}{RESET}")
def get_path_of_memories_folder():
    """Returns the absolute path to the 'memories' folder."""
    current = pathlib.Path.cwd()
    memories_path = current / "memories"
    return memories_path.absolute()

def process_user_input():
    """Processes user input from the terminal."""
    user_input = input(f"{GREEN}Enter input: {RESET}")
    print(f"{MAGENTA}User input received: {user_input}{RESET}")
    return user_input


def call_interaction_model(user_input, timestamp):
    """Calls the interaction model and gets the response."""
    print(f"\n{CYAN}--- Calling Interaction Model ---{RESET}")
    try:
        interaction_model = genai.GenerativeModel(
            model_name='gemini-1.5-flash-latest',
            safety_settings={'HARASSMENT': 'block_none'},
            system_instruction='You follow orders and generate creative text interactions'
        )
        chat = interaction_model.start_chat(history=[])
        response = chat.send_message(f"currentTime: {timestamp} create {user_input}")
        print(f"AI Response: {response.text}")
        return response
    except Exception as e:
        print(f"{RED}Error in Interaction Model: {e}{RESET}")
        return None


def call_memory_model(user_input, introspection, reflection, action, function_call_result, emotions, learning):
    """Calls the memory model and gets the structured response."""
    print(f"\n{CYAN}            ***------- Calling Memory Model (Loop MemoryFrame creation)------***{RESET}")
    try:
        memory_model = genai.GenerativeModel(
            model_name='gemini-1.5-flash-latest',
            safety_settings={'HARASSMENT': 'block_none'},
            system_instruction="""You are a sophisticated AI assistant helping to organize memories. 
            Analyze and summarize the above user-AI conversation, focusing on elements that would be most useful for storing and retrieving this memory later. Don't hallucinate. 
            Use the provided JSON schema for your response and fill in all fields with relevant information.
            You can omit entries if they don't seem appropriate for memory storage and would be empty.
            Never omit the "memory_folders_storage" entry.

            **JSON Schema:**

            ```json
            {
              "metadata": {
                "creation_date": "", 
                "source": "", 
                "author": "" 
              },
              "type": "conversation", // OR "technical_concept" 
              "core": {
                "main_topic": "", 
                "category": "", 
                "subcategory": "", 
                "memory_about": "" 
              },
              "summary": {
                "concise_summary": "", 
                "description": "" 
              },
              "content": {
                "keywords": [], 
                "entities": [], 
                "tags": [], 
                "observations": [], 
                "facts": [], 
                "contradictions": [], 
                "paradoxes": [], 
                "scientific_data": [], 
                "visualizations": [] 
              },
              "interaction": {
                "interaction_type": [], 
                "people": [], 
                "objects": [], 
                "animals": [], 
                "actions": [], 
                "observed_interactions": [] 
              },
              "impact": {
                "obtained_knowledge": "", 
                "positive_impact": "", 
                "negative_impact": "", 
                "expectations": "", 
                "strength_of_experience": "" 
              },
              "importance": {
                "reason": "", 
                "potential_uses": [], 
                "importance_level": "0-100" 
              },
              "technical_details": {
                "problem_solved": "", 
                "concept_definition": "", 
                "implementation_steps": [], 
                "tools_and_technologies": [], 
                "example_projects": [], 
                "best_practices": [], 
                "common_challenges": [], 
                "debugging_tips": [], 
                "related_concepts": [], 
                "resources": [], 
                "code_examples": [] 
              },
              "storage": {
                "storage_method": "", 
                "location": "", 
                "memory_folders_storage": [
                  {
                    "folder_path": "", 
                    "probability": 0  
                  }
                ],
                "strength_of_matching_memory_to_given_folder": [] 
              },
              "naming_suggestion": {
                "memory_frame_name": "Give  Same  meaning full name for  Memory File",
                "explanation": "" 
              }
            }
            ```
            
            
            
            
             Here  you have  existing  folder structure  for  memory_folders_storage [{
    "Actions & Results": {
        "Actions & Results": {
            "Future": {},
            "Past": {},
            "Present": {}
        }
    },
    "BaseFileStructure.txt": [],
    "Challenges & Setbacks": {
        "Areas for Improvement": {},
        "Difficult Emotions": {
            "Anger & Frustration": {},
            "Fear & Anxiety": {},
            "Jealousy & Envy": {},
            "Sadness & Grief": {},
            "Shame & Guilt": {},
            "Trauma & Abuse": {
                "Experiences": {},
                "Healing Journey": {},
                "Impact": {}
            }
        },
        "Failures & Disappointments": {
            "In Career": {},
            "In Personal Projects": {},
            "In Relationships": {}
        },
        "Negative Thought Patterns": {},
        "Significant Mistakes": {
            "Description": {},
            "How I Grew": {},
            "Lessons Learned": {}
        }
    },
    "CoreMemory": {
        "Conceptual Exploration": {
            "Contradictions & Dilemmas": {},
            "Paradoxes & Contradictions": {},
            "Unknowns & Mysteries": {}
        },
        "Core Experiences": {
            "Challenges Faced": {
                "External Challenges": {
                    "Obstacles": {
                        "How I Overcame Them": {},
                        "Types of Obstacles": {},
                        "What I Learned": {}
                    },
                    "Setbacks": {
                        "How I Recovered": {},
                        "Types of Setbacks": {},
                        "What I Learned": {}
                    }
                },
                "Internal Challenges": {
                    "Fear & Anxiety": {
                        "How I Coped": {},
                        "Specific Fears": {},
                        "What I Learned": {}
                    },
                    "Negative Thought Patterns": {
                        "Common Negative Thoughts": {},
                        "Strategies for Changing Them": {},
                        "What I Learned": {}
                    },
                    "Self-Doubt": {
                        "How I Overcame It": {},
                        "Sources of Self-Doubt": {},
                        "What I Learned": {}
                    }
                }
            },
            "Life-Changing Events": {
                "Negative": {},
                "Positive": {}
            },
            "Significant Moments": {
                "Other": {},
                "Personal": {},
                "Professional": {},
                "Travel": {}
            },
            "Triumphs & Accomplishments": {
                "Creative Wins": {
                    "Creative Works": {},
                    "Impact on Life": {},
                    "Recognition & Awards": {}
                },
                "Personal Achievements": {
                    "Goals Achieved": {},
                    "Impact on Life": {},
                    "Personal Growth": {}
                },
                "Professional Successes": {
                    "Career Growth": {},
                    "Impact on Life": {},
                    "Projects & Achievements": {}
                }
            },
            "Turning Points": {
                "In Career": {},
                "In Personal Growth": {},
                "In Relationships": {},
                "Other": {}
            }
        },
        "Goals & Visions": {
            "Life Vision": {
                "Long-Term Goals": {},
                "Mid-Term Goals": {},
                "Short-Term Goals": {}
            },
            "Personal Goals": {
                "Long-Term Goals": {},
                "Mid-Term Goals": {},
                "Short-Term Goals": {}
            }
        },
        "Knowledge Base": {
            "Areas of Expertise": {},
            "Key Concepts & Theories": {},
            "Personal Beliefs & Values": {}
        },
        "Reflections & Insights": {
            "Lessons Learned": {
                "From Mistakes": {},
                "From Relationships": {},
                "From Successes": {}
            },
            "Self-Discovery": {
                "Areas for Growth": {},
                "Strengths & Talents": {},
                "What I've Learned About Myself": {}
            }
        },
        "Relationships": {
            "Family": {
                "Extended Family": {
                    "Challenges Faced": {},
                    "Impact on My Life": {},
                    "Lessons Learned": {},
                    "Memorable Moments": {}
                },
                "Parents": {
                    "Challenges Faced": {},
                    "Impact on My Life": {},
                    "Lessons Learned": {},
                    "Memorable Moments": {}
                },
                "Siblings": {
                    "Challenges Faced": {},
                    "Impact on My Life": {},
                    "Lessons Learned": {},
                    "Memorable Moments": {}
                }
            },
            "Friendships": {
                "Circles & Groups": {
                    "Impact on My Life": {},
                    "Lessons Learned": {},
                    "Shared Experiences": {}
                },
                "Close Friends": {
                    "Challenges Faced": {},
                    "Impact on My Life": {},
                    "Lessons Learned": {},
                    "Memorable Moments": {}
                },
                "Meaningful Interactions": {
                    "Impact on My Life": {},
                    "Lessons Learned": {},
                    "Unexpected Encounters": {}
                }
            },
            "Romantic Relationships": {
                "Partners": {
                    "Challenges Faced": {},
                    "Impact on My Life": {},
                    "Lessons Learned": {},
                    "Memorable Moments": {}
                },
                "Relationship Milestones": {
                    "First Date": {},
                    "First Kiss": {},
                    "Marriage": {},
                    "Moving In Together": {},
                    "Other Milestones": {}
                }
            }
        }
    },
    "Emotional Landscape": {
        "Dominant Emotions": {},
        "Emotional Triggers": {}
    },
    "Emotions & Reflections": {
        "Emotional Experiences": {
            "Dominant Emotions": {},
            "Emotional Triggers": {}
        },
        "Personal Growth & Insights": {
            "Lessons Learned": {},
            "Self-Discovery": {}
        }
    },
    "Goals & Aspirations": {
        "Life Vision": {
            "Aspirations": {},
            "Dreams": {},
            "Values & Beliefs": {}
        },
        "Personal Goals": {
            "Creative Pursuits": {},
            "Health & Wellbeing": {},
            "Other Personal Goals": {},
            "Personal Development": {},
            "Relationships": {}
        },
        "Professional Goals": {
            "Career Advancement": {},
            "Other Professional Goals": {},
            "Project Goals": {},
            "Skills & Expertise": {}
        }
    },
    "Knowledge & Learning": {
        "Formal Education": {
            "Degrees & Certifications": {},
            "Schools": {},
            "Significant Projects": {}
        },
        "Knowledge Base": {
            "Artistic Movements": {},
            "Cultural Insights": {},
            "Facts & Concepts": {},
            "Historical Events": {},
            "Philosophical Ideas": {},
            "Scientific Discoveries": {}
        },
        "Laws & Regulations": {
            "Legal Knowledge": {},
            "Personal Experiences with Laws": {},
            "Understanding of Legal Systems": {}
        },
        "Self-Directed Learning": {
            "Areas of Interest": {},
            "Learning Resources": {
                "Bookshelf": {},
                "Mentors & Teachers": {},
                "Online Courses": {}
            },
            "Skills Acquired": {}
        }
    },
    "Life Events & Transitions": {
        "Life Transitions": {
            "Health & Wellbeing": {
                "Habits & Routines": {},
                "Mental & Emotional Health": {},
                "Physical Health": {}
            },
            "Knowledge & Skills": {
                "Formal Education": {},
                "Self-Directed Learning": {},
                "Skills & Expertise": {}
            },
            "Personal Growth": {
                "Challenges Overcome": {},
                "Milestones": {},
                "Significant Decisions": {}
            },
            "Relationships": {
                "Family Dynamics": {},
                "Friendships": {},
                "Professional Connections": {},
                "Romantic Relationships": {}
            }
        },
        "Significant Events": {
            "Other": {},
            "Personal": {
                "Birthdays": {},
                "Graduations": {},
                "Other Personal Events": {},
                "Weddings": {}
            },
            "Professional": {
                "Job Changes": {},
                "Other Professional Events": {},
                "Project Completions": {},
                "Promotions": {}
            },
            "Travel": {
                "Moving Homes": {},
                "Other Travel Events": {},
                "Trips & Journeys": {}
            }
        }
    },
    "Planning & Progress": {
        "Plans & Strategies": {
            "Long-Term Plans": {},
            "Short-Term Plans": {},
            "Strategies Used": {
                "Goal Setting": {},
                "Other Strategies": {},
                "Problem Solving": {},
                "Time Management": {}
            }
        },
        "Progress & Outcomes": {
            "Goals Achieved": {},
            "Goals Not Achieved": {},
            "Lessons Learned from Progress": {},
            "Results of Actions": {
                "Negative Results": {},
                "Positive Results": {}
            }
        }
    }
}]
            **Memory Storage Suggestions:**
            Provide your suggestions for where this memory frame should be stored using the following format within the "memory_folders_storage" field:

            * **"folder_path":** The relative path for storing the memory frame (use '/' as the path separator).
            * **"probability":** The strength of probability (from 0 to 10) that the memory frame should be stored in the suggested folder. Use a scale from 0 (least likely) to 10 (most likely) to express your confidence. 
        """

        )

        chat = memory_model.start_chat(history=[])
        create_memory_prompt = (f"User: {user_input}\n"
                                f"AI: {introspection}\n"
                                f"AI: {reflection}\n"
                                f"AI: {action}\n"
                                f"AI: {function_call_result}\n"
                                f"AI: {emotions}\n"
                                f"AI: {learning}\n"
                                )
        response = chat.send_message(create_memory_prompt)
        print(f"Memory Model Response:\n{response.text}")


        return response
    except Exception as e:
        print(f"{RED}Error in Memory Model: {e}{RESET}")
        return None


def extract_entries_smart(response_message):
    """Extracts structured entries from the response message."""
    print("\n--- Extracting Structured Entries ---")
    entries = []
    json_match = re.search(r"```json\n(.*?)\n```", response_message, re.DOTALL)
    if json_match:
        print("Found JSON data in the response.")
        try:
            json_data = json_match.group(1)
            print("Parsing JSON data...")
            response_data = json.loads(json_data)
            print("JSON data parsed successfully.")

            if isinstance(response_data, list):
                for entry in response_data:
                    entries.append(entry)
            elif isinstance(response_data, dict):
                entries.append(response_data)
            else:
                print(f"{YELLOW}Warning: Unexpected data type: {type(response_data)}{RESET}")
                print("Skipping data.")
        except json.JSONDecodeError:
            print(f"{RED}Error: Invalid JSON in the AI response.{RESET}")
        except Exception as e:
            print(f"{RED}Error extracting entry: {e}{RESET}")
    return entries


def store_memory_frame(user_input, introspection, reflection, action, function_call_result, emotions, learning,
                       memory_data, session_info):
    """Stores a memory frame based on provided information and updates the HTML logs."""
    global MEMORY_FRAME_NUMBER, EDIT_NUMBER

    # Create filename for MemoryFrame
    timestamp = datetime.now().strftime(TIMESTAMP_FORMAT)
    importance = int(memory_data['importance']['importance_level'])
    suggested_name = memory_data['naming_suggestion']['memory_frame_name']

    # Sanitize the suggested name
    sanitized_name = sanitize_filename(suggested_name)

    filename = f"MemoryFrame___{session_info}___{timestamp}___importance___{importance:03d}___{sanitized_name}.json"

    # Construct the path
    base_path = get_path_of_memories_folder()

    # Get the suggested folder paths
    suggested_paths = memory_data['storage']['memory_folders_storage']

    # Sort suggested paths by probability (highest first)
    suggested_paths.sort(key=lambda x: x['probability'], reverse=True)

    # Use the path with the highest probability
    chosen_path = suggested_paths[0]['folder_path']

    # Split the path into individual folder names
    folder_names = chosen_path.split('/')

    # Construct the full path
    full_path = os.path.join(base_path, "AiGenerated", *folder_names)

    # Ensure the directory exists
    os.makedirs(full_path, exist_ok=True)

    # Construct full file path
    file_path = os.path.join(full_path, filename)

    # Construct memory frame content
    memory_frame_content = {
        "user_input": user_input,
        "introspection": introspection,
        "reflection": reflection,
        "action": action,
        "function_call_result": function_call_result,
        "emotions": emotions,
        "learning": learning,
        "memory_data": memory_data,
        "session_info": session_info
    }

    # Write the memory frame to a JSON file
    try:
        with open(file_path, 'w', encoding='utf-8') as f:
            json.dump(memory_frame_content, f, indent=2, ensure_ascii=False)
        print(f"{YELLOW}--- Memory Frame Stored Successfully ---{RESET}")
        print(f"Stored at: {file_path}")

        # Update HTML logs
        update_html_logs(MEMORY_FRAME_NUMBER, suggested_name, timestamp, [file_path], base_path)
        MEMORY_FRAME_NUMBER += 1
    except Exception as e:
        print(f"{RED}Error writing Memory Frame: {e}{RESET}")


def CREATE_MEMORY_FRAME(user_input, introspection, reflection, action, function_call_result, emotions, learning,
                        session_info=None):
    """Main function to create a memory frame from user input and AI responses."""
    try:
        print("Calling memory model")
        memory_summary = call_memory_model(user_input=user_input, introspection=introspection, reflection=reflection,
                                           action=action, function_call_result=function_call_result, emotions=emotions,
                                           learning=learning)

        if memory_summary and hasattr(memory_summary, 'text'):
            print("Extracting memory entries")
            memory_entries = extract_entries_smart(memory_summary.text)

            if memory_entries:
                for entry in memory_entries:
                    store_memory_frame(user_input=user_input, introspection=introspection, reflection=reflection,
                                       action=action, function_call_result=function_call_result, emotions=emotions,
                                       learning=learning, memory_data=entry, session_info=session_info)
                print(f"{GREEN}Memory frame(s) stored successfully.{RESET}")
            else:
                print(f"{YELLOW}No valid memory entries found. Memory frame not stored.{RESET}")
        else:
            print(f"{YELLOW}No valid response from memory model. Memory frame not stored.{RESET}")
    except Exception as e:
        print(f"{RED}Error in CREATE_MEMORY_FRAME: {e}{RESET}")

    print(f"{GREEN}CREATE_MEMORY_FRAME FINISHED{RESET}")
"""  
if __name__ == "__main__":
    while True:
        user_input = process_user_input()
        timestamp = datetime.now().strftime(TIMESTAMP_FORMAT)
        response1 = call_interaction_model(user_input, timestamp)
        if response1:
            introspection = "example introspection"
            reflection = "example reflection"
            action = "example action"
            function_call_result = "example function call result"
            emotions = "example emotions"
            learning = "example learning"
            CREATE_MEMORY_FRAME(user_input, introspection, reflection, action, function_call_result, emotions, learning)"""

File: ProjectTableManager.py (C:\Users\DELL\Desktop\selfawareGemini\SelAwareAI_Gemini\PROJECT16\ProjectTableManager.py)
Content (First 324 lines):
import json
from typing import List, Dict, Union, Optional

class Subtask:
    def __init__(self, name: str, focus_type: str, moscow_category: str, importance: int,
                 difficulty: int, reward: int, total_work: float, proposed_action: str,
                 cost_per_run: float, work_done: float = 0.0, focus_strength: float = 0.0,
                 frustration: float = 0.0, fatigue: float = 0.0, accumulated_cost: float = 0.0,
                 status: str = "NOT_COMPLETED", learned_knowledge: str = "",
                 important_facts: str = "", current_focus: bool = False, goal: str = "",
                 dependencies: List[str] = [], deadline: str = None, calculated_score: float = 0.0,
                 last_focused: str = None, parent_task: str = None, priority: int = 5):
        self.name = name
        self.focus_type = focus_type
        self.moscow_category = moscow_category
        self.importance = importance
        self.difficulty = difficulty
        self.reward = reward
        self.total_work = total_work
        self.proposed_action = proposed_action
        self.cost_per_run = cost_per_run
        self.work_done = work_done
        self.focus_strength = focus_strength
        self.frustration = frustration
        self.fatigue = fatigue
        self.accumulated_cost = accumulated_cost
        self.status = status
        self.learned_knowledge = learned_knowledge
        self.important_facts = important_facts
        self.current_focus = current_focus
        self.goal = goal
        self.dependencies = dependencies
        self.deadline = deadline
        self.calculated_score = calculated_score
        self.last_focused = last_focused
        self.parent_task = parent_task
        self.priority = priority

class Task(Subtask):
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.subtasks: List[Subtask] = []

class Project:
    def __init__(self, name: str, description: str, goal: str,
                 tasks: List[Union[Task, Subtask]] = None,
                 priority: int = 5, deadline: str = None):
        self.name = name
        self.description = description
        self.goal = goal
        self.tasks = tasks if tasks is not None else []
        self.priority = priority
        self.deadline = deadline

    def get_highest_priority_task(self) -> Optional[Task]:
        """Returns the task with the highest priority."""
        if not self.tasks:
            return None
        return sorted(self.tasks, key=lambda task: task.priority, reverse=True)[0]

    def get_task_by_name(self, task_name: str) -> Optional[Task]:
        """Returns a task by its name within the project."""
        for task in self.tasks:
            if task.name == task_name:
                return task
        return None

class ProjectTableManager:
    def __init__(self, table_file="Brain_settings/ProjectTable/project_table.json"):
        self.table_file = table_file
        self.project_table: Dict[str, Project] = self.load_table()
        self.current_project: Optional[Project] = None

    def load_table(self) -> Dict[str, Project]:
        """Loads the project table from the JSON file."""
        try:
            with open(self.table_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            return self._convert_to_objects(data)
        except FileNotFoundError:
            print(f"Project table file not found. Creating a new one.")
            return {}

    def _convert_to_objects(self, data: Dict) -> Dict[str, Project]:
        """Converts the loaded JSON data into Project objects."""
        projects = {}
        for project_name, project_data in data.items():
            tasks = []
            for task_data in project_data.get("tasks", []):
                subtasks = [Subtask(**subtask_data) for subtask_data in task_data.get("subtasks", [])]
                task = Task(**task_data, subtasks=subtasks)
                tasks.append(task)
            project = Project(**project_data, tasks=tasks)
            projects[project_name] = project
        return projects

    def save_table(self) -> None:
        """Saves the project table to the JSON file."""
        try:
            data = self._convert_to_dict(self.project_table)
            with open(self.table_file, 'w', encoding='utf-8') as f:
                json.dump(data, f, indent=2)
        except Exception as e:
            print(f"Error saving project table: {e}")

    def _convert_to_dict(self, projects: Dict[str, Project]) -> Dict:
        """Converts Project objects to a dictionary for JSON serialization."""
        data = {}
        for project_name, project in projects.items():
            tasks = []
            for task in project.tasks:
                subtasks = [subtask.__dict__ for subtask in task.subtasks]
                tasks.append({**task.__dict__, "subtasks": subtasks})
            data[project_name] = {**project.__dict__, "tasks": tasks}
        return data

    def create_project(self, name: str, description: str, goal: str, priority: int = 5, deadline: str = None) -> str:
        """Creates a new project and adds it to the project table."""
        if name in self.project_table:
            return f"Project '{name}' already exists."
        self.project_table[name] = Project(name, description, goal, priority=priority, deadline=deadline)
        self.save_table()
        return f"Project '{name}' created successfully."

    def add_task(self, project_name: str, **kwargs) -> str:
        """Adds a new task to the specified project."""
        project = self.project_table.get(project_name)
        if not project:
            return f"Project '{project_name}' not found."
        project.tasks.append(Task(**kwargs))
        self.save_table()
        return f"Task '{kwargs.get('name', 'Unnamed Task')}' added to project '{project_name}'."

    def add_subtask(self, project_name: str, task_name: str, **kwargs) -> str:
        """Adds a new subtask to the specified task within a project."""
        project = self.project_table.get(project_name)
        if not project:
            return f"Project '{project_name}' not found."

        task = project.get_task_by_name(task_name)
        if not task:
            return f"Task '{task_name}' not found in project '{project_name}'."

        task.subtasks.append(Subtask(**kwargs, parent_task=task_name))
        self.save_table()
        return f"Subtask '{kwargs.get('name', 'Unnamed Subtask')}' added to task '{task_name}' in project '{project_name}'."

    def get_project(self, project_name: str) -> Optional[Project]:
        """Returns the project object for the given project name."""
        return self.project_table.get(project_name)

    def remove_project(self, project_name: str) -> str:
        """Removes a project from the project table."""
        if project_name in self.project_table:
            del self.project_table[project_name]
            self.save_table()
            return f"Project '{project_name}' removed successfully."
        else:
            return f"Project '{project_name}' not found."

    def update_project(self, project_name: str, **kwargs) -> str:
        """Updates the attributes of a project."""
        project = self.project_table.get(project_name)
        if not project:
            return f"Project '{project_name}' not found."

        for key, value in kwargs.items():
            if hasattr(project, key):
                setattr(project, key, value)

        self.save_table()
        return f"Project '{project_name}' updated successfully."

    def remove_task(self, project_name: str, task_name: str) -> str:
        """Removes a task from the specified project."""
        project = self.project_table.get(project_name)
        if not project:
            return f"Project '{project_name}' not found."

        project.tasks = [task for task in project.tasks if task.name != task_name]
        self.save_table()
        return f"Task '{task_name}' removed from project '{project_name}'."

    def update_task(self, project_name: str, task_name: str, **kwargs) -> str:
        """Updates the attributes of a task within a project."""
        project = self.project_table.get(project_name)
        if not project:
            return f"Project '{project_name}' not found."

        task = project.get_task_by_name(task_name)
        if not task:
            return f"Task '{task_name}' not found in project '{project_name}'."

        for key, value in kwargs.items():
            if hasattr(task, key):
                setattr(task, key, value)

        self.save_table()
        return f"Task '{task_name}' in project '{project_name}' updated successfully."

    def remove_subtask(self, project_name: str, task_name: str, subtask_name: str) -> str:
        """Removes a subtask from a specific task within a project."""
        project = self.project_table.get(project_name)
        if not project:
            return f"Project '{project_name}' not found."

        task = project.get_task_by_name(task_name)
        if not task:
            return f"Task '{task_name}' not found in project '{project_name}'."

        task.subtasks = [subtask for subtask in task.subtasks if subtask.name != subtask_name]
        self.save_table()
        return f"Subtask '{subtask_name}' removed from task '{task_name}' in project '{project_name}'."

    def update_subtask(self, project_name: str, task_name: str, subtask_name: str, **kwargs) -> str:
        """Updates the attributes of a subtask within a task in a project."""
        project = self.project_table.get(project_name)
        if not project:
            return f"Project '{project_name}' not found."

        task = project.get_task_by_name(task_name)
        if not task:
            return f"Task '{task_name}' not found in project '{project_name}'."

        subtask = next((s for s in task.subtasks if s.name == subtask_name), None)
        if not subtask:
            return f"Subtask '{subtask_name}' not found in task '{task_name}' in project '{project_name}'."

        for key, value in kwargs.items():
            if hasattr(subtask, key):
                setattr(subtask, key, value)

        self.save_table()
        return f"Subtask '{subtask_name}' in task '{task_name}' in project '{project_name}' updated successfully."

    def get_current_project(self) -> Optional[Project]:
        """Returns the currently active project."""
        return self.current_project

    def set_current_project(self, project: Project) -> None:
        """Sets the currently active project."""
        self.current_project = project

    def get_highest_priority_task(self, project: Optional[Project] = None) -> Optional[Task]:
        """
        Returns the highest priority task from the specified project,
        or the current project if none is specified.
        """
        if project is None:
            project = self.current_project
        if project:
            return project.get_highest_priority_task()
        return None

    def get_available_projects(self) -> List[Project]:
        """Returns a list of projects that meet a certain criteria
        (e.g., not started, not completed)."""
        available_projects = []
        for project_name, project in self.project_table.items():
            # Example criteria: project is not completed
            if not self.is_project_completed(project_name):
                available_projects.append(project)
        return available_projects



    def is_project_completed(self, project_name: str) -> bool:
        project = self.project_table.get(project_name)
        if not project:
            return False
        return all(task.status == "COMPLETED" for task in project.tasks)

    def mark_project_completed(self, project_name: str) -> str:
        project = self.project_table.get(project_name)
        if not project:
            return f"Project '{project_name}' not found."
        for task in project.tasks:
            task.status = "COMPLETED"
        self.save_table()
        return f"Project '{project_name}' marked as completed."

    def get_completed_projects(self) -> List[Project]:
        return [project for project in self.project_table.values() if self.is_project_completed(project.name)]

    def start_task(self, project_name: str, task_name: str) -> str:
        project = self.project_table.get(project_name)
        if not project:
            return f"Project '{project_name}' not found."
        task = project.get_task_by_name(task_name)
        if not task:
            return f"Task '{task_name}' not found in project '{project_name}'."
        task.status = "IN_PROGRESS"
        self.save_table()
        return f"Task '{task_name}' in project '{project_name}' started."

    def complete_task(self, project_name: str, task_name: str) -> str:
        project = self.project_table.get(project_name)
        if not project:
            return f"Project '{project_name}' not found."
        task = project.get_task_by_name(task_name)
        if not task:
            return f"Task '{task_name}' not found in project '{project_name}'."
        task.status = "COMPLETED"
        self.save_table()
        return f"Task '{task_name}' in project '{project_name}' completed."

    def start_project(self, project_name: str) -> str:
        """Starts a project by setting its status to 'IN_PROGRESS'."""
        project = self.project_table.get(project_name)
        if not project:
            return f"Project '{project_name}' not found."
        project.status = "IN_PROGRESS"
        self.save_table()
        return f"Project '{project_name}' started."

    def get_available_projects(self, status_filter: List[str] = None) -> List[Project]:
        """Returns a list of projects that meet a certain criteria.
        You can optionally filter by status (e.g., ['IN_PROGRESS', 'NOT_STARTED']).
        """
        available_projects = []
        for project_name, project in self.project_table.items():
            if status_filter is None or project.status in status_filter:
                available_projects.append(project)
        return available_projects

File: QstarTableManager.py (C:\Users\DELL\Desktop\selfawareGemini\SelAwareAI_Gemini\PROJECT16\QstarTableManager.py)
Content (First 83 lines):
#QstarTableManager.py
import random
from typing import Dict, Tuple, Any
from typing import List
import  json
from  FocusManager import Task

from typing import Optional
class State:
    def __init__(self, current_project: str, current_task: str, emotions: Dict[str, float], current_project_priority: int, current_project_deadline: str, top_tasks: List = None):
        self.current_project = current_project
        self.current_task = current_task
        self.emotions = emotions
        self.current_project_priority = current_project_priority
        self.current_project_deadline = current_project_deadline
        self.top_tasks = top_tasks  # Add top_tasks attribute

    def __str__(self):
        return f"Project: {self.current_project}, Task: {self.current_task}, Emotions: {self.emotions}"

    def __hash__(self):
        return hash((self.current_project, self.current_task, tuple(self.emotions.items())))

    def __eq__(self, other):
        return isinstance(other, State) and self.__dict__ == other.__dict__

class QstarTable:
    def __init__(self, learning_rate: float = 0.1, discount_factor: float = 0.9, exploration_rate: float = 0.1):
        self.q_table: Dict[State, Dict[str, float]] = {}
        self.learning_rate = learning_rate
        self.discount_factor = discount_factor
        self.exploration_rate = exploration_rate
        self.actions = ["select_project", "start_task", "complete_task", "switch_task"]


    def initialize_table(self, actions: List[str]):
        """Initializes the Q-table with default values for each action."""
        self.actions = actions  # Store the actions
        for state in self.q_table:
            for action in actions:
                self.q_table[state][action] = 0.0



    def get_q_value(self, state: State, action: str) -> float:
        if state not in self.q_table:
            self.q_table[state] = {a: 0.0 for a in self.actions}
        return self.q_table[state].get(action, 0.0)

    def update_q_value(self, state: State, action: str, reward: float, next_state: State) -> None:
        if state not in self.q_table:
            self.q_table[state] = {a: 0.0 for a in self.actions}

        best_future_q = max(self.get_q_value(next_state, a) for a in self.actions)
        current_q = self.q_table[state][action]
        new_q = current_q + self.learning_rate * (reward + self.discount_factor * best_future_q - current_q)
        self.q_table[state][action] = new_q

    def choose_best_action(self, state: State) -> str:
        if random.uniform(0, 1) < self.exploration_rate:
            return random.choice(self.actions)
        else:
            if state not in self.q_table:
                return random.choice(self.actions)
            return max(self.q_table[state], key=self.q_table[state].get)

    def save_q_table(self, filename: str):
        with open(filename, 'w') as f:
            json.dump({str(k): v for k, v in self.q_table.items()}, f)

    def load_q_table(self, filename: str):
        with open(filename, 'r') as f:
            data = json.load(f)
            self.q_table = {eval(k): v for k, v in data.items()}

    def get_current_task(self) -> Optional[Task]:
        """Returns the currently active task (if any)."""
        if self.current_project is None:
            return None
        for task in self.current_project.tasks:
            if task.status == "IN_PROGRESS":
                return task
        return None


Subdirectory: sessions
## Summary of Files and Directories in 'C:\Users\DELL\Desktop\selfawareGemini\SelAwareAI_Gemini\PROJECT16\sessions'


Subdirectory: Session_05-20-34
## Summary of Files and Directories in 'C:\Users\DELL\Desktop\selfawareGemini\SelAwareAI_Gemini\PROJECT16\sessions\Session_05-20-34'

File: conversation_log.txt (C:\Users\DELL\Desktop\selfawareGemini\SelAwareAI_Gemini\PROJECT16\sessions\Session_05-20-34\conversation_log.txt)
Content (First 16 lines):
-------------------- Awareness Loop: 1 --------------------
Time: 05:20:57
--------------------

-------------------- Awareness Loop: 2 --------------------
Time: 05:21:21
--------------------

-------------------- Awareness Loop: 3 --------------------
Time: 05:21:46
--------------------

-------------------- Awareness Loop: 4 --------------------
Time: 05:22:14
--------------------




Subdirectory: Session_06-05-47
## Summary of Files and Directories in 'C:\Users\DELL\Desktop\selfawareGemini\SelAwareAI_Gemini\PROJECT16\sessions\Session_06-05-47'


Subdirectory: Session_06-09-52
## Summary of Files and Directories in 'C:\Users\DELL\Desktop\selfawareGemini\SelAwareAI_Gemini\PROJECT16\sessions\Session_06-09-52'


Subdirectory: Session_06-15-54
## Summary of Files and Directories in 'C:\Users\DELL\Desktop\selfawareGemini\SelAwareAI_Gemini\PROJECT16\sessions\Session_06-15-54'


Subdirectory: Session_06-20-30
## Summary of Files and Directories in 'C:\Users\DELL\Desktop\selfawareGemini\SelAwareAI_Gemini\PROJECT16\sessions\Session_06-20-30'


Subdirectory: Session_06-24-44
## Summary of Files and Directories in 'C:\Users\DELL\Desktop\selfawareGemini\SelAwareAI_Gemini\PROJECT16\sessions\Session_06-24-44'


Subdirectory: Session_06-28-35
## Summary of Files and Directories in 'C:\Users\DELL\Desktop\selfawareGemini\SelAwareAI_Gemini\PROJECT16\sessions\Session_06-28-35'


Subdirectory: Session_06-31-18
## Summary of Files and Directories in 'C:\Users\DELL\Desktop\selfawareGemini\SelAwareAI_Gemini\PROJECT16\sessions\Session_06-31-18'


Subdirectory: Session_06-32-09
## Summary of Files and Directories in 'C:\Users\DELL\Desktop\selfawareGemini\SelAwareAI_Gemini\PROJECT16\sessions\Session_06-32-09'


Subdirectory: Session_06-32-42
## Summary of Files and Directories in 'C:\Users\DELL\Desktop\selfawareGemini\SelAwareAI_Gemini\PROJECT16\sessions\Session_06-32-42'


Subdirectory: Session_06-34-49
## Summary of Files and Directories in 'C:\Users\DELL\Desktop\selfawareGemini\SelAwareAI_Gemini\PROJECT16\sessions\Session_06-34-49'


Subdirectory: Session_06-37-39
## Summary of Files and Directories in 'C:\Users\DELL\Desktop\selfawareGemini\SelAwareAI_Gemini\PROJECT16\sessions\Session_06-37-39'


Subdirectory: Session_06-42-55
## Summary of Files and Directories in 'C:\Users\DELL\Desktop\selfawareGemini\SelAwareAI_Gemini\PROJECT16\sessions\Session_06-42-55'


Subdirectory: Session_06-46-48
## Summary of Files and Directories in 'C:\Users\DELL\Desktop\selfawareGemini\SelAwareAI_Gemini\PROJECT16\sessions\Session_06-46-48'


Subdirectory: Session_06-52-04
## Summary of Files and Directories in 'C:\Users\DELL\Desktop\selfawareGemini\SelAwareAI_Gemini\PROJECT16\sessions\Session_06-52-04'


Subdirectory: Session_06-54-42
## Summary of Files and Directories in 'C:\Users\DELL\Desktop\selfawareGemini\SelAwareAI_Gemini\PROJECT16\sessions\Session_06-54-42'


Subdirectory: Session_06-57-31
## Summary of Files and Directories in 'C:\Users\DELL\Desktop\selfawareGemini\SelAwareAI_Gemini\PROJECT16\sessions\Session_06-57-31'


Subdirectory: Session_07-02-28
## Summary of Files and Directories in 'C:\Users\DELL\Desktop\selfawareGemini\SelAwareAI_Gemini\PROJECT16\sessions\Session_07-02-28'


Subdirectory: Session_07-14-25
## Summary of Files and Directories in 'C:\Users\DELL\Desktop\selfawareGemini\SelAwareAI_Gemini\PROJECT16\sessions\Session_07-14-25'


Subdirectory: Session_07-24-09
## Summary of Files and Directories in 'C:\Users\DELL\Desktop\selfawareGemini\SelAwareAI_Gemini\PROJECT16\sessions\Session_07-24-09'


Subdirectory: Session_16-13-00
## Summary of Files and Directories in 'C:\Users\DELL\Desktop\selfawareGemini\SelAwareAI_Gemini\PROJECT16\sessions\Session_16-13-00'

File: conversation_log.txt (C:\Users\DELL\Desktop\selfawareGemini\SelAwareAI_Gemini\PROJECT16\sessions\Session_16-13-00\conversation_log.txt)
Content (First 24 lines):
-------------------- Awareness Loop: 1 --------------------
Time: 16:13:28
--------------------

-------------------- Awareness Loop: 2 --------------------
Time: 16:13:53
--------------------

-------------------- Awareness Loop: 3 --------------------
Time: 16:14:16
--------------------

-------------------- Awareness Loop: 4 --------------------
Time: 16:14:40
--------------------

-------------------- Awareness Loop: 5 --------------------
Time: 16:16:48
--------------------

-------------------- Awareness Loop: 6 --------------------
Time: 16:17:12
--------------------




Subdirectory: Session_16-30-16
## Summary of Files and Directories in 'C:\Users\DELL\Desktop\selfawareGemini\SelAwareAI_Gemini\PROJECT16\sessions\Session_16-30-16'

File: conversation_log.txt (C:\Users\DELL\Desktop\selfawareGemini\SelAwareAI_Gemini\PROJECT16\sessions\Session_16-30-16\conversation_log.txt)
Content (First 12 lines):
-------------------- Awareness Loop: 1 --------------------
Time: 16:30:44
--------------------

-------------------- Awareness Loop: 2 --------------------
Time: 16:31:14
--------------------

-------------------- Awareness Loop: 3 --------------------
Time: 16:31:44
--------------------




Subdirectory: Session_16-57-16
## Summary of Files and Directories in 'C:\Users\DELL\Desktop\selfawareGemini\SelAwareAI_Gemini\PROJECT16\sessions\Session_16-57-16'

File: test.json (C:\Users\DELL\Desktop\selfawareGemini\SelAwareAI_Gemini\PROJECT16\test.json)
Content (First 1 lines):
{"test": "success"}


Subdirectory: tools
## Summary of Files and Directories in 'C:\Users\DELL\Desktop\selfawareGemini\SelAwareAI_Gemini\PROJECT16\tools'


Subdirectory: Cathegory_Os
## Summary of Files and Directories in 'C:\Users\DELL\Desktop\selfawareGemini\SelAwareAI_Gemini\PROJECT16\tools\Cathegory_Os'

File: get_directory_structure.py (C:\Users\DELL\Desktop\selfawareGemini\SelAwareAI_Gemini\PROJECT16\tools\Cathegory_Os\get_directory_structure.py)
Content (First 111 lines):
tool_type_for_Tool_Manager="all"


import os


def get_directory_structure(directory=None, include_files=True, include_dirs=True, file_extension=None,
                            include_contents=False, specific_file=None, levels_up=0, verbose=False):
    if verbose:
        print("Entered get_directory_structure function with directory:", directory)

    # Set default directory
    if directory is None or directory == '/':
        directory = os.getcwd()
        if verbose:
            print(f"Directory is set to current working directory: {directory}")

    # Traverse up the directory hierarchy if levels_up is specified
    for _ in range(levels_up):
        directory = os.path.dirname(directory)
        if verbose:
            print(f"Traversed up one level, new directory: {directory}")

    # Safety check for the directory path
    if not os.path.exists(directory) or not os.path.isdir(directory):
        raise ValueError(f"The directory '{directory}' is not valid or does not exist.")

    directory_structure = {}

    def get_file_info(file_path):
        file_info = {
            'filename': os.path.basename(file_path),
            'size': os.path.getsize(file_path),
            'relative_path': os.path.relpath(file_path, directory),
            'full_path': file_path
        }
        if include_contents:
            try:
                with open(file_path, 'r') as file:
                    file_info['contents'] = file.read()
            except Exception as e:
                file_info['contents'] = f"Error reading file: {e}"
        return file_info

    if specific_file:
        if os.path.isfile(specific_file):
            if verbose:
                print(f"Getting details for specific file: {specific_file}")
            return get_file_info(specific_file)
        else:
            raise ValueError(f"The specified file '{specific_file}' does not exist.")

    for root, dirs, files in os.walk(directory):
        file_info = []
        if include_files:
            for file in files:
                if file_extension and not file.endswith(file_extension):
                    continue
                file_path = os.path.join(root, file)
                file_info.append(get_file_info(file_path))

        if include_dirs:
            directory_structure[os.path.relpath(root, directory)] = {
                'files': file_info,
                'folders': dirs
            }
        else:
            if file_info:
                directory_structure[os.path.relpath(root, directory)] = {
                    'files': file_info
                }

    if verbose:
        print("About to return the directory structure with", len(directory_structure), "folders.")

    return directory_structure


get_directory_structure_description_json = {
    'function_declarations': [
        {
            'name': 'get_directory_structure',
            'description': 'Returns a dictionary representing the directory structure with file names, sizes, relative paths, and full paths.',
            'parameters': {
                'type_': 'OBJECT',
                'properties': {
                    'directory': {'type_': 'STRING',
                                  'description': 'The path to the directory. Defaults to the current working directory if None or / is provided.'},
                    'include_files': {'type_': 'BOOLEAN',
                                      'description': 'Flag to include files in the output. Default is True.'},
                    'include_dirs': {'type_': 'BOOLEAN',
                                     'description': 'Flag to include directories in the output. Default is True.'},
                    'file_extension': {'type_': 'STRING',
                                       'description': 'Specific file extension to include. Default is None.'},
                    'include_contents': {'type_': 'BOOLEAN',
                                         'description': 'Flag to include the contents of files in the output. Default is False.'},
                    'specific_file': {'type_': 'STRING',
                                      'description': 'Path to a specific file to get its details. Default is None.'},
                    'levels_up': {'type_': 'INTEGER',
                                  'description': 'Number of levels to traverse up from the specified or current directory. Default is 0.'},
                    'verbose': {'type_': 'BOOLEAN', 'description': 'Flag for verbose logging. Default is False.'}
                },
                'required': ['directory']
            }
        }
    ]
}



get_directory_structure_description_short_str = "Returns a dictionary representing the directory structure with file names, sizes, relative paths, and full paths. Includes options for filtering files, directories, file extensions, including file contents, and traversing up the directory hierarchy with a default to the current working directory."


File: save_to_file.py (C:\Users\DELL\Desktop\selfawareGemini\SelAwareAI_Gemini\PROJECT16\tools\Cathegory_Os\save_to_file.py)
Content (First 51 lines):
tool_type_for_Tool_Manager="all"

import os
import json
from termcolor import colored  # Import the termcolor library

def save_to_file(content: str = None, file_name: str = 'NoName', file_path: str = None) -> dict:

    print(colored(f"Entering: save_to_file(...)", 'blue'))
    if content is None:
        content = ""
    if file_path is None:
        full_path = os.path.join(os.getcwd(), file_name)
    else:
        full_path = os.path.join(file_path, file_name)

    try:
        with open(full_path, 'w', encoding='utf-8') as f:
            f.write(content)

        success_message = f"File saved successfully at: {full_path}"
        print(colored(success_message, 'green'))
        print(colored(f"Exiting: save_to_file(...)", 'blue'))
        return {"status": "success", "message": success_message, "file_path": full_path}

    except Exception as e:
        error_message = f"Failed to save file: {str(e)}"
        print(colored(error_message, 'red'))
        print(colored(f"Exiting: save_to_file(...)", 'blue'))
        return {"status": "failure", "message": error_message}


save_to_file_description_json = {
    'function_declarations': [
        {
            'name': 'save_to_file',
            'description': 'Saves content to a file.',
            'parameters': {
                'type_': 'OBJECT',
                'properties': {
                    'content': {'type_': 'STRING'},
                    'file_name': {'type_': 'STRING', 'description': 'The name of the file. Defaults to "NoName".'},
                    'file_path': {'type_': 'STRING', 'description': 'The path to save the file. Defaults to the current working directory if not provided.'}
                },
                'required': ['content', 'file_name']
            }
        }
    ]
}

save_to_file_description_short_str="Searches memory frames within a specified folder based on provided criteria."

File: search_memory_tool.py (C:\Users\DELL\Desktop\selfawareGemini\SelAwareAI_Gemini\PROJECT16\tools\Cathegory_Os\search_memory_tool.py)
Content (First 306 lines):
import os
import json
import logging
import re
from datetime import datetime
from functools import lru_cache
from typing import List, Dict, Union, Optional, Tuple, Literal, Any
from fuzzywuzzy import fuzz
from rank_bm25 import BM25Okapi

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

ImportanceFilter = Union[int, Dict[Literal["min", "max", "above", "below"], int]]
EmotionFilter = Dict[str, Dict[Literal["minimum", "maximum"], float]]
ContentFilter = Dict[str, Union[str, List[str]]]
DateRange = Tuple[str, str]
TimeRange = Tuple[str, str]


class SearchError(Exception):
    pass


def search_memory_tool(
        query: str,
        query_type: str = "keyword",
        query_fields: Optional[List[str]] = None,
        query_operator: str = "AND",
        max_results: int = 5,
        importance_filter: Optional[ImportanceFilter] = None,
        keyword_filter: Optional[List[str]] = None,
        return_fields: Optional[List[str]] = None,
        category: Optional[str] = None,
        subcategory: Optional[str] = None,
        emotion_filter: Optional[EmotionFilter] = None,
        content_filter: Optional[ContentFilter] = None,
        timestamp_range: Optional[DateRange] = None,
        session_time_range: Optional[TimeRange] = None
) -> Dict[str, Any]:
    try:
        results = search_memory(
            query=query,
            query_type=query_type,
            query_fields=query_fields,
            query_operator=query_operator,
            max_results=max_results,
            importance_filter=importance_filter,
            keyword_filter=keyword_filter,
            return_fields=return_fields,
            category=category,
            subcategory=subcategory,
            emotion_filter=emotion_filter,
            content_filter=content_filter,
            timestamp_range=timestamp_range,
            session_time_range=session_time_range
        )
        return {"status": "success", "results": results}
    except SearchError as e:
        return {"status": "error", "message": str(e)}
    except Exception as e:
        logger.error(f"An unexpected error occurred in search_memory_tool: {str(e)}")
        return {"status": "error", "message": f"An unexpected error occurred: {str(e)}"}


search_memory_tool_description_json = {
    "name": "search_memory_tool",
    "description": "Searches the memory store for relevant information using various querying options.",
    "parameters": {
        "type_": "OBJECT",
        "properties": {
            "query": {"type_": "STRING", "description": "The search query string."},
            "query_type": {"type_": "STRING",
                           "description": "The type of query to perform. Options are: 'keyword', 'semantic', 'regex'. Defaults to 'keyword'."},
            "query_fields": {"type_": "ARRAY", "items": {"type_": "STRING"},
                             "description": "Specify the fields to search within the memory frames."},
            "query_operator": {"type_": "STRING",
                               "description": "Logical operator for multiple query terms ('AND', 'OR'). Defaults to 'AND'. Applies only to 'keyword' query type."},
            "max_results": {"type_": "INTEGER",
                            "description": "The maximum number of results to return. Defaults to 5."},
            "importance_filter": {"type_": "STRING",
                                  "description": "Filter results by importance level (e.g., 'high', 'medium', 'low', '3', '{\"min\": 2}')."},
            "keyword_filter": {"type_": "ARRAY", "items": {"type_": "STRING"},
                               "description": "Filter results by keywords."},
            "return_fields": {"type_": "ARRAY", "items": {"type_": "STRING"},
                              "description": "Specify the fields to return in the results."},
            "category": {"type_": "STRING", "description": "Filter results by category."},
            "subcategory": {"type_": "STRING", "description": "Filter results by subcategory."},
            "emotion_filter": {"type_": "STRING",
                               "description": "Filter results by emotion (e.g., 'happy', '{\"sad\": {\"minimum\": 0.7}}')."},
            "content_filter": {"type_": "STRING",
                               "description": "Filter results by content type (e.g., 'text', 'image', 'audio')."},
            "timestamp_range": {"type_": "ARRAY", "items": {"type_": "STRING", "description": "date-time"},
                                "description": "Filter results by timestamp range (start, end)."},
            "session_time_range": {"type_": "ARRAY", "items": {"type_": "STRING", "description": "date-time"},
                                   "description": "Filter results by session time range (start, end)."}
        },
        "required": ["query"]
    }
}

search_memory_tool_description_short_str = "Searches memory frames within a specified folder based on provided criteria, using various querying options including keyword, semantic, and regex search."


def search_memory(
        query: str,
        query_type: str = "keyword",
        query_fields: Optional[List[str]] = None,
        query_operator: str = "AND",
        max_results: int = 5,
        importance_filter: Optional[ImportanceFilter] = None,
        keyword_filter: Optional[List[str]] = None,
        return_fields: Optional[List[str]] = None,
        category: Optional[str] = None,
        subcategory: Optional[str] = None,
        emotion_filter: Optional[EmotionFilter] = None,
        content_filter: Optional[ContentFilter] = None,
        timestamp_range: Optional[DateRange] = None,
        session_time_range: Optional[TimeRange] = None
) -> List[Dict[str, Any]]:
    try:
        searcher = MemoryFrameSearcher()
        results = searcher.search_memory_frames(
            query=query,
            query_type=query_type,
            query_fields=query_fields,
            query_operator=query_operator,
            max_results=max_results,
            importance_filter=importance_filter,
            keyword_filter=keyword_filter,
            return_fields=return_fields,
            category=category,
            subcategory=subcategory,
            emotion_filter=emotion_filter,
            content_filter=content_filter,
            timestamp_range=timestamp_range,
            session_time_range=session_time_range
        )

        for result in results:
            logger.info(f"File: {result['file_path']}")
            logger.info(f"Score: {result['score']}")
            logger.info(f"Main Topic: {result['data'].get('memory_data', {}).get('core', {}).get('main_topic', 'N/A')}")
            logger.info(
                f"Concise Summary: {result['data'].get('memory_data', {}).get('summary', {}).get('concise_summary', 'N/A')}")
            logger.info("---")

        return results
    except Exception as e:
        logger.error(f"An error occurred during memory search: {str(e)}")
        raise SearchError(f"Memory search failed: {str(e)}")


class MemoryFrameSearcher:
    def __init__(self, memories_folder_path: str = "../../memories/AiGenerated"):
        self.memories_folder_path = memories_folder_path
        self.bm25_index = None

    @lru_cache(maxsize=1000)
    def _parse_filename(self, filename: str) -> Dict[str, Union[str, int]]:
        pattern = r"MemoryFrame___Session_(\d{2}-\d{2}-\d{2})___(\d{4}-\d{2}-\d2_\d{2}-\d{2})___importance___(\d{3})___(.+)\.json"
        match = re.match(pattern, filename)
        if match:
            return {
                'session_time': match.group(1),
                'timestamp': match.group(2),
                'importance': int(match.group(3)),
                'title': match.group(4)
            }
        return {}

    def _apply_filters(self, memory_frame: Dict[str, Any], file_info: Dict[str, Union[str, int]],
                       filters: Dict[str, Any]) -> bool:
        for filter_name, filter_value in filters.items():
            filter_method = getattr(self, f"_filter_{filter_name}", None)
            if filter_method and not filter_method(memory_frame, file_info, filter_value):
                return False
        return True

    def _filter_importance(self, memory_frame: Dict[str, Any], file_info: Dict[str, Union[str, int]],
                           importance_filter: ImportanceFilter) -> bool:
        importance = file_info['importance']
        if isinstance(importance_filter, int):
            return importance == importance_filter
        elif isinstance(importance_filter, dict):
            return all([
                importance >= importance_filter.get('min', importance),
                importance <= importance_filter.get('max', importance),
                importance > importance_filter.get('above', importance - 1),
                importance < importance_filter.get('below', importance + 1)
            ])
        return True

    def _filter_timestamp(self, memory_frame: Dict[str, Any], file_info: Dict[str, Union[str, int]],
                          timestamp_range: DateRange) -> bool:
        timestamp = datetime.strptime(file_info['timestamp'], "%Y-%m-%d_%H-%M")
        start_date = datetime.strptime(timestamp_range[0], "%Y-%m-%d")
        end_date = datetime.strptime(timestamp_range[1], "%Y-%m-%d")
        return start_date <= timestamp <= end_date

    def _filter_keyword(self, memory_frame: Dict[str, Any], file_info: Dict[str, Union[str, int]],
                        keyword_filter: List[str]) -> bool:
        content = json.dumps(memory_frame)
        return any(fuzz.partial_ratio(keyword.lower(), content.lower()) > 80 for keyword in keyword_filter)

    def _filter_category(self, memory_frame: Dict[str, Any], file_info: Dict[str, Union[str, int]],
                         category: str) -> bool:
        return memory_frame.get('memory_data', {}).get('core', {}).get('category') == category

    def _filter_subcategory(self, memory_frame: Dict[str, Any], file_info: Dict[str, Union[str, int]],
                         subcategory: str) -> bool:
        return memory_frame.get('memory_data', {}).get('core', {}).get('subcategory') == subcategory

    def _read_memory_frame(self, file_path: str) -> Dict[str, Any]:
        try:
            with open(file_path, 'r') as file:
                content = file.read()
                return json.loads(content)
        except json.JSONDecodeError as e:
            logger.error(f"Error decoding JSON in file {file_path}: {str(e)}")
            return {}
        except Exception as e:
            logger.error(f"Error reading file {file_path}: {str(e)}")
            return {}

    def _calculate_relevance_score(self, memory_frame: Dict[str, Any], query: str, query_type: str = 'keyword',
                                   query_fields: Optional[List[str]] = None, query_operator: str = 'AND') -> float:
        if query_fields is None:
            content = json.dumps(memory_frame)
        else:
            content = " ".join([str(memory_frame.get(field, '')) for field in query_fields])

        if query_type == "keyword":
            if self.bm25_index:
                tokenized_query = query.lower().split()
                scores = self.bm25_index.get_scores(tokenized_query)
                return max(scores) if scores else 0.0
            else:
                words = query.lower().split()
                if query_operator == "AND":
                    return min(fuzz.partial_ratio(word, content.lower()) for word in words) / 100.0
                else:
                    return max(fuzz.partial_ratio(word, content.lower()) for word in words) / 100.0
        elif query_type == "semantic":
            return fuzz.token_set_ratio(query, content) / 100.0
        elif query_type == "regex":
            try:
                pattern = re.compile(query, re.IGNORECASE)
                return 1.0 if pattern.search(content) else 0.0
            except re.error:
                logger.error(f"Invalid regex pattern: {query}")
                return 0.0
        else:
            logger.warning(f"Invalid query_type: {query_type}. Using keyword search.")
            return self._calculate_relevance_score(memory_frame, query, 'keyword', query_fields, query_operator)

    def search_memory_frames(
            self,
            query: str,
            query_type: str = "keyword",
            query_fields: Optional[List[str]] = None,
            query_operator: str = "AND",
            max_results: int = 5,
            **filters: Any
    ) -> List[Dict[str, Any]]:
        results = []

        for filename in os.listdir(self.memories_folder_path):
            if filename.endswith('.json'):
                file_path = os.path.join(self.memories_folder_path, filename)
                file_info = self._parse_filename(filename)

                if not self._apply_filters({}, file_info, filters):
                    continue

                result = self._process_memory_frame(
                    file_path, file_info, query, query_type, query_fields, query_operator, filters)

                if result:
                    results.append(result)

        results.sort(key=lambda x: x['score'], reverse=True)
        return results[:max_results]

    def _process_memory_frame(
            self,
            file_path: str,
            file_info: Dict[str, Union[str, int]],
            query: str,
            query_type: str,
            query_fields: Optional[List[str]],
            query_operator: str,
            filters: Dict[str, Any]
    ) -> Optional[Dict[str, Any]]:
        memory_frame = self._read_memory_frame(file_path)

        if not self._apply_filters(memory_frame, file_info, filters):
            return None

        score = self._calculate_relevance_score(memory_frame, query, query_type, query_fields, query_operator)

        return {
            'file_path': file_path,
            'score': score,
            'data': memory_frame
        }

File: update_prompts.py (C:\Users\DELL\Desktop\selfawareGemini\SelAwareAI_Gemini\PROJECT16\tools\Cathegory_Os\update_prompts.py)
Content (First 75 lines):
# UpdatePrompts.py
import os
tool_type_for_Tool_Manager="reflection"
import json

# ANSI escape codes for colors
RESET = "\033[0m"
BLUE = "\033[34m"
GREEN = "\033[32m"
RED = "\033[31m"

def update_prompts(prompt_key: str, new_prompt: str) -> dict:
    """Updates a prompt in the prompts.json file."""

    print(f"{BLUE}Entering: UpdatePrompts(...) {RESET}")
    try:
        # Load existing prompts
        with open("Brain_settings/prompts.json", 'r') as file:
            prompts = json.load(file)

        # Update the specified prompt
        prompts[prompt_key] = new_prompt

        # Save updated prompts
        with open("Brain_settings/prompts.json", 'w') as file:
            json.dump(prompts, file, indent=4)

        success_message = f"Prompt '{prompt_key}' updated successfully."
        print(f"{GREEN}{success_message} {RESET}")
        print(f"{BLUE}Exiting: UpdatePrompts(...) {RESET}")
        return {"status": "success", "message": success_message}

    except FileNotFoundError:
        error_message = f"File 'prompts.json' not found."
        print(f"{RED}{error_message} {RESET}")
        print(f"{BLUE}Exiting: UpdatePrompts(...) {RESET}")
        return {"status": "failure", "message": error_message}

    except KeyError:
        error_message = f"Prompt '{prompt_key}' not found in 'prompts.json'."
        print(f"{RED}{error_message} {RESET}")
        print(f"{BLUE}Exiting: UpdatePrompts(...) {RESET}")
        return {"status": "failure", "message": error_message}

    except Exception as e:
        error_message = f"Failed to update prompt: {str(e)}"
        print(f"{RED}{error_message} {RESET}")
        print(f"{BLUE}Exiting: UpdatePrompts(...) {RESET}")
        return {"status": "failure", "message": error_message}


# Description for the Tool Manager
update_prompts_description_json = {
  "function_declarations": [
    {
      "name": "update_prompts",
      "description": "Updates a prompt in the 'prompts.json' file.",
      "parameters": {
        "type_": "OBJECT",
        "properties": {
          "prompt_key": {
            "type_": "STRING",
            "description": "The key of the prompt to update."
          },
          "new_prompt": {
            "type_": "STRING",
            "description": "The new value for the prompt."
          }
        },
        "required": ["prompt_key", "new_prompt"]
      }
    }
  ]
}
update_prompts_description_short_str = "Updates a prompt in the 'prompts.json' fil"


Subdirectory: __pycache__
## Summary of Files and Directories in 'C:\Users\DELL\Desktop\selfawareGemini\SelAwareAI_Gemini\PROJECT16\tools\Cathegory_Os\__pycache__'

File: get_directory_structure.cpython-312.pyc (C:\Users\DELL\Desktop\selfawareGemini\SelAwareAI_Gemini\PROJECT16\tools\Cathegory_Os\__pycache__\get_directory_structure.cpython-312.pyc)
Error decoding file 'C:\Users\DELL\Desktop\selfawareGemini\SelAwareAI_Gemini\PROJECT16\tools\Cathegory_Os\__pycache__\get_directory_structure.cpython-312.pyc': 'utf-8' codec can't decode byte 0xcb in position 0: invalid continuation byte

File: save_to_file.cpython-312.pyc (C:\Users\DELL\Desktop\selfawareGemini\SelAwareAI_Gemini\PROJECT16\tools\Cathegory_Os\__pycache__\save_to_file.cpython-312.pyc)
Error decoding file 'C:\Users\DELL\Desktop\selfawareGemini\SelAwareAI_Gemini\PROJECT16\tools\Cathegory_Os\__pycache__\save_to_file.cpython-312.pyc': 'utf-8' codec can't decode byte 0xcb in position 0: invalid continuation byte

File: search_memory_tool.cpython-312.pyc (C:\Users\DELL\Desktop\selfawareGemini\SelAwareAI_Gemini\PROJECT16\tools\Cathegory_Os\__pycache__\search_memory_tool.cpython-312.pyc)
Error decoding file 'C:\Users\DELL\Desktop\selfawareGemini\SelAwareAI_Gemini\PROJECT16\tools\Cathegory_Os\__pycache__\search_memory_tool.cpython-312.pyc': 'utf-8' codec can't decode byte 0xcb in position 0: invalid continuation byte

File: update_prompts.cpython-312.pyc (C:\Users\DELL\Desktop\selfawareGemini\SelAwareAI_Gemini\PROJECT16\tools\Cathegory_Os\__pycache__\update_prompts.cpython-312.pyc)
Error decoding file 'C:\Users\DELL\Desktop\selfawareGemini\SelAwareAI_Gemini\PROJECT16\tools\Cathegory_Os\__pycache__\update_prompts.cpython-312.pyc': 'utf-8' codec can't decode byte 0xcb in position 0: invalid continuation byte


Subdirectory: FocusTable
## Summary of Files and Directories in 'C:\Users\DELL\Desktop\selfawareGemini\SelAwareAI_Gemini\PROJECT16\tools\FocusTable'

File: add_task_to_focus_table.py (C:\Users\DELL\Desktop\selfawareGemini\SelAwareAI_Gemini\PROJECT16\tools\FocusTable\add_task_to_focus_table.py)
Content (First 175 lines):


import json

tool_type_for_Tool_Manager="reflection"

def add_task_to_focus_table(task_name, focus_type, moscow_category,
                      importance, difficulty, reward, total_work, proposed_action,
                      cost_per_run,
                            work_done=0.0, focus_strength=0.0, frustration=0.0,
                      fatigue=0.0, accumulated_cost=0.0, status="NOT_COMPLETED",
                      learned_knowledge="", important_facts="", current_focus=False,
                      goal="", dependencies=[], deadline=None):

    file_path = "../../Brain_settings/focusTables/focus.json"
    if task_name == None:
        task_name="unnamed"
    try:
        # Load the focus table
        with open(file_path, 'r') as f:
            focus_tree = json.load(f)

        # Add the new task to the focus tree
        focus_tree[task_name] = {
            'focus_type': focus_type,
            'moscow_category': moscow_category,
            'importance': importance,
            'difficulty': difficulty,
            'reward': reward,
            'total_work': total_work,
            'proposed_action': proposed_action,
            'cost_per_run': cost_per_run,
            'work_done': work_done,
            'focus_strength': focus_strength,
            'frustration': frustration,
            'fatigue': fatigue,
            'accumulated_cost': accumulated_cost,
            'status': status,
            'learned_knowledge': learned_knowledge,
            'important_facts': important_facts,
            'current_focus': current_focus,
            'goal': goal,
            'dependencies': dependencies,
            'deadline': deadline
        }

        try:
            with open(file_path, 'w') as f:
                json.dump(focus_tree, f, indent=2)
        except Exception as E:
            print(f"Error writing to file: {E}")
            return None

        print(f"Focus table updated with task: {task_name}")
        return focus_tree +"added  to focus  Table" # Return the entire updated focus table

    except Exception as e:
        print(f"Error updating focus table: {e}")
        return None


add_task_to_focus_table_description_json ={
  "function_declarations": [
    {
      "name": "add_task_to_focus_table",
      "description": "Adds a new task to the focus table.",
      "parameters": {
        "type_": "OBJECT",
        "properties": {
          "task_name": {
            "type_": "STRING",
            "description": "The name of the task to add. If None, defaults to 'unnamed'."
          },
          "focus_type": {
            "type_": "STRING",
            "description": "The type of focus for the task (e.g., 'work', 'personal', 'learning')."
          },
          "moscow_category": {
            "type_": "STRING",
            "description": "The MOSCOW category of the task (e.g., 'Must', 'Should', 'Could', 'Won't')."
          },
          "importance": {
            "type_": "INTEGER",
            "description": "The importance level of the task (e.g., 1-5)."
          },
          "difficulty": {
            "type_": "INTEGER",
            "description": "The difficulty level of the task (e.g., 1-5)."
          },
          "reward": {
            "type_": "INTEGER",
            "description": "The reward for completing the task (e.g., 1-5)."
          },
          "total_work": {
            "type_": "INTEGER",
            "description": "The total estimated work required for the task (in units)."
          },
          "proposed_action": {
            "type_": "STRING",
            "description": "The proposed action or steps to take for the task."
          },
          "cost_per_run": {
            "type_": "NUMBER",
            "description": "The cost (in time, energy, etc.) for each attempt or run of the task."
          },
          "work_done": {
            "type_": "NUMBER",
            "description": "The amount of work already completed on the task (in units). Defaults to 0.0."
          },
          "focus_strength": {
            "type_": "NUMBER",
            "description": "The current level of focus dedicated to the task. Defaults to 0.0."
          },
          "frustration": {
            "type_": "NUMBER",
            "description": "The current level of frustration with the task. Defaults to 0.0."
          },
          "fatigue": {
            "type_": "NUMBER",
            "description": "The current level of fatigue experienced with the task. Defaults to 0.0."
          },
          "accumulated_cost": {
            "type_": "NUMBER",
            "description": "The total cost (in time, energy, etc.) accumulated so far for the task. Defaults to 0.0."
          },
          "status": {
            "type_": "STRING",
            "description": "The current status of the task (e.g., 'NOT_COMPLETED', 'IN_PROGRESS', 'COMPLETED'). Defaults to 'NOT_COMPLETED'."
          },
          "learned_knowledge": {
            "type_": "STRING",
            "description": "Any knowledge learned or insights gained while working on the task. Defaults to empty string."
          },
          "important_facts": {
            "type_": "STRING",
            "description": "Any important facts or details relevant to the task. Defaults to empty string."
          },
          "current_focus": {
            "type_": "BOOLEAN",
            "description": "Whether the task is currently the primary focus. Defaults to False."
          },
          "goal": {
            "type_": "STRING",
            "description": "The specific goal or outcome desired from completing the task. Defaults to empty string."
          },
          "dependencies": {
            "type_": "ARRAY",
            "items": {
              "type_": "STRING",
              "description": "A list of other tasks that this task depends on. Defaults to empty list."
            }
          },
          "deadline": {
            "type_": "STRING",
            "description": "The deadline for completing the task (in YYYY-MM-DD format). Defaults to None."
          }
        },
        "required": [
          "task_name",
          "focus_type",
          "moscow_category",
          "importance",
          "difficulty",
          "reward",
          "total_work",
          "proposed_action",
          "cost_per_run"
        ]
      }
    }
  ]
}


add_task_to_focus_table_description_short_str = "Adds a new task to the focus table."  # Short description


File: remove_from_focus_table.py (C:\Users\DELL\Desktop\selfawareGemini\SelAwareAI_Gemini\PROJECT16\tools\FocusTable\remove_from_focus_table.py)
Content (First 51 lines):
import  json
tool_type_for_Tool_Manager="reflection"
def remove_from_focus_table(task_name):
    file_path = "../../Brain_settings/focusTables/focus.json"  # Adjust path as needed
    """
    Removes a task from the focus table.

    Args:
        task_name (str): The name of the task to remove.

    Returns:
        str: A message indicating success or failure.
    """
    try:
        # Load the focus table
        with open(file_path, 'r') as f:
            focus_tree = json.load(f)

        # Remove the task from the focus tree
        if task_name in focus_tree:
            del focus_tree[task_name]
            # Save the updated focus table
            with open(file_path, 'w') as f:
                json.dump(focus_tree, f, indent=2)
            print(f"Focus table updated. Task '{task_name}' removed.")
            return "Task removed from Focus table"
        else:
            print(f"Task '{task_name}' not found in the focus table.")
            return "Task not found in Focus table"

    except Exception as e:
        print(f"Error removing task from focus table: {e}")
        return "Error removing task from Focus table"

remove_from_focus_table_description_json = {  # JSON description
    "function_declarations": [
        {
            "name": "remove_from_focus_table",
            "description": "Removes a task from the focus table.",
            "parameters": {
                "type_": "OBJECT",
                "properties": {
                    "task_name": {"type_": "STRING", "description": "The name of the task to remove."}
                },

            }
        }
    ]
}

remove_from_focus_table_description_short_str = "Removes a task from the focus table."  # Short

File: update_focus_table.py (C:\Users\DELL\Desktop\selfawareGemini\SelAwareAI_Gemini\PROJECT16\tools\FocusTable\update_focus_table.py)
Content (First 272 lines):
tool_type_for_Tool_Manager = "reflection"
import json
import  os
def update_focus_table(task_name: str, focus_type: str = None, moscow_category: str = None,
                      importance: int = None, difficulty: int = None, reward: int = None,
                      total_work: float = None, proposed_action: str = None, cost_per_run: float = None,
                      work_done: float = None, focus_strength: float = None, frustration: float = None,
                      fatigue: float = None, accumulated_cost: float = None, status: str = None,
                      learned_knowledge: str = None, important_facts: str = None, current_focus: bool = None,
                      goal: str = None, dependencies: list = None, deadline: str = None) -> str:
    """
    Updates a task in the focus table.

    Args:
        task_name (str): The name of the task to update.
        focus_type (str, optional): The type of focus for the task (e.g., 'work', 'personal', 'learning').
        moscow_category (str, optional): The MOSCOW category of the task (e.g., 'Must', 'Should', 'Could', 'Won't').
        importance (int, optional): The importance level of the task (e.g., 1-5).
        difficulty (int, optional): The difficulty level of the task (e.g., 1-5).
        reward (int, optional): The reward for completing the task (e.g., 1-5).
        total_work (float, optional): The total estimated work required for the task (in units).
        proposed_action (str, optional): The proposed action or steps to take for the task.
        cost_per_run (float, optional): The cost (in time, energy, etc.) for each attempt or run of the task.
        work_done (float, optional): The amount of work already completed on the task (in units).
        focus_strength (float, optional): The current level of focus dedicated to the task.
        frustration (float, optional): The current level of frustration with the task.
        fatigue (float, optional): The current level of fatigue experienced with the task.
        accumulated_cost (float, optional): The total cost (in time, energy, etc.) accumulated so far for the task.
        status (str, optional): The current status of the task (e.g., 'NOT_COMPLETED', 'IN_PROGRESS', 'COMPLETED').
        learned_knowledge (str, optional): Any knowledge learned or insights gained while working on the task.
        important_facts (str, optional): Any important facts or details relevant to the task.
        current_focus (bool, optional): Whether the task is currently the primary focus.
        goal (str, optional): The specific goal or outcome desired from completing the task.
        dependencies (list, optional): A list of other tasks that this task depends on.
        deadline (str, optional): The deadline for completing the task (in YYYY-MM-DD format).

    Returns:
        str: A message indicating success or failure.
    """
    file_path = "../../Brain_settings/focusTables/focus.json"  # Adjust path as needed

    try:
        with open(file_path, 'r') as f:
            focus_table = json.load(f)

        if task_name not in focus_table:
            return f"Task '{task_name}' not found in the focus table."

        task = focus_table[task_name]  # Access the task by its name

        # Update only the provided parameters
        if focus_type is not None:
            task['focus_type'] = focus_type
        if moscow_category is not None:
            task['moscow_category'] = moscow_category
        if importance is not None:
            task['importance'] = importance
        if difficulty is not None:
            task['difficulty'] = difficulty
        if reward is not None:
            task['reward'] = reward
        if total_work is not None:
            task['total_work'] = total_work
        if proposed_action is not None:
            task['proposed_action'] = proposed_action
        if cost_per_run is not None:
            task['cost_per_run'] = cost_per_run
        if work_done is not None:
            task['work_done'] = work_done
        if focus_strength is not None:
            task['focus_strength'] = focus_strength
        if frustration is not None:
            task['frustration'] = frustration
        if fatigue is not None:
            task['fatigue'] = fatigue
        if accumulated_cost is not None:
            task['accumulated_cost'] = accumulated_cost
        if status is not None:
            task['status'] = status
        if learned_knowledge is not None:
            task['learned_knowledge'] = learned_knowledge
        if important_facts is not None:
            task['important_facts'] = important_facts
        if current_focus is not None:
            task['current_focus'] = current_focus
        if goal is not None:
            task['goal'] = goal
        if dependencies is not None:
            task['dependencies'] = dependencies
        if deadline is not None:
            task['deadline'] = deadline

        with open(file_path, 'w') as f:
            json.dump(focus_table, f, indent=2)

        return f"Task '{task_name}' updated in the focus table."

    except Exception as e:
        return f"Error updating focus table: {e}"

update_focus_table_description_json = {
  "function_declarations": [
    {
      "name": "update_focus_table",
      "description": "Updates a task in the focus table.",
      "parameters": {
        "type_": "OBJECT",
        "properties": {
          "task_name": {
            "type_": "STRING",
            "description": "The name of the task to update."
          },
          "focus_type": {
            "type_": "STRING",
            "description": "The type of focus for the task (e.g., 'work', 'personal', 'learning')."
          },
          "moscow_category": {
            "type_": "STRING",
            "description": "The MOSCOW category of the task (e.g., 'Must', 'Should', 'Could', 'Won't')."
          },
          "importance": {
            "type_": "INTEGER",
            "description": "The importance level of the task (e.g., 1-5)."
          },
          "difficulty": {
            "type_": "INTEGER",
            "description": "The difficulty level of the task (e.g., 1-5)."
          },
          "reward": {
            "type_": "INTEGER",
            "description": "The reward for completing the task (e.g., 1-5)."
          },
          "total_work": {
            "type_": "NUMBER",
            "description": "The total estimated work required for the task (in units)."
          },
          "proposed_action": {
            "type_": "STRING",
            "description": "The proposed action or steps to take for the task."
          },
          "cost_per_run": {
            "type_": "NUMBER",
            "description": "The cost (in time, energy, etc.) for each attempt or run of the task."
          },
          "work_done": {
            "type_": "NUMBER",
            "description": "The amount of work already completed on the task (in units)."
          },
          "focus_strength": {
            "type_": "NUMBER",
            "description": "The current level of focus dedicated to the task."
          },
          "frustration": {
            "type_": "NUMBER",
            "description": "The current level of frustration with the task."
          },
          "fatigue": {
            "type_": "NUMBER",
            "description": "The current level of fatigue experienced with the task."
          },
          "accumulated_cost": {
            "type_": "NUMBER",
            "description": "The total cost (in time, energy, etc.) accumulated so far for the task."
          },
          "status": {
            "type_": "STRING",
            "description": "The current status of the task (e.g., 'NOT_COMPLETED', 'IN_PROGRESS', 'COMPLETED')."
          },
          "learned_knowledge": {
            "type_": "STRING",
            "description": "Any knowledge learned or insights gained while working on the task."
          },
          "important_facts": {
            "type_": "STRING",
            "description": "Any important facts or details relevant to the task."
          },
          "current_focus": {
            "type_": "BOOLEAN",
            "description": "Whether the task is currently the primary focus."
          },
          "goal": {
            "type_": "STRING",
            "description": "The specific goal or outcome desired from completing the task."
          },
          "dependencies": {
            "type_": "ARRAY",
            "items": {
              "type_": "STRING",
              "description": "A list of other tasks that this task depends on."
            }
          },
          "deadline": {
            "type_": "STRING",
            "description": "The deadline for completing the task (in YYYY-MM-DD format)."
          }
        },
        "required": ["task_name"]
      }
    }
  ]
}

update_focus_table_description_short_str = "Updates a task in the focus table."

def check_update_focus_table():
    """
    Function to check if the update_focus_table function works correctly.
    """
    file_path = os.path.abspath("../../Brain_settings/focusTables/focus.json")

    # 1. Load the focus table:
    try:
        with open(file_path, 'r') as f:
            focus_table = json.load(f)
        print(f"Focus table loaded successfully: {focus_table}")
    except FileNotFoundError:
        print(f"Error: Focus table file '{file_path}' not found. Creating a new focus table with example data.")
        focus_table = {
            "Task1": {
                "focus_type": "work",
                "moscow_category": "Must",
                "importance": 5,
                "difficulty": 3,
                "reward": 4,
                "total_work": 10.0,
                "proposed_action": "Write code for the feature",
                "cost_per_run": 1.0,
                "work_done": 0.0,
                "focus_strength": 0.0,
                "frustration": 0.0,
                "fatigue": 0.0,
                "accumulated_cost": 0.0,
                "status": "NOT_COMPLETED",
                "learned_knowledge": "",
                "important_facts": "",
                "current_focus": False,
                "goal": "Finish the feature",
                "dependencies": [],
                "deadline": "2024-07-15"
            },
            "Task2": {
                # ...  add more example tasks here
            }
        }
        with open(file_path, 'w') as f:
            json.dump(focus_table, f, indent=2)

    # 2. Update a task:
    task_to_update = "Task1"
    updated_status = "IN_PROGRESS"
    result = update_focus_table(task_name=task_to_update, status=updated_status)
    print(f"Update result: {result}")

    # 3. Verify the update:
    try:
        with open(file_path, 'r') as f:
            updated_focus_table = json.load(f)
        print(f"Updated focus table: {updated_focus_table}")

        # Access the updated task directly by name
        if updated_focus_table[task_to_update]['status'] == updated_status:
            print(f"Verification: Task '{task_to_update}' updated correctly with status '{updated_status}'")
        else:
            print(f"Verification failed: Task '{task_to_update}' status is not '{updated_status}'")

    except FileNotFoundError:
        print(f"Error: Focus table file '{file_path}' not found after update. ")
    except Exception as e:
        print(f"Error verifying update: {e}")

if __name__ == "__main__":
    check_update_focus_table()


Subdirectory: __pycache__
## Summary of Files and Directories in 'C:\Users\DELL\Desktop\selfawareGemini\SelAwareAI_Gemini\PROJECT16\tools\FocusTable\__pycache__'

File: add_task_to_focus_table.cpython-312.pyc (C:\Users\DELL\Desktop\selfawareGemini\SelAwareAI_Gemini\PROJECT16\tools\FocusTable\__pycache__\add_task_to_focus_table.cpython-312.pyc)
Error decoding file 'C:\Users\DELL\Desktop\selfawareGemini\SelAwareAI_Gemini\PROJECT16\tools\FocusTable\__pycache__\add_task_to_focus_table.cpython-312.pyc': 'utf-8' codec can't decode byte 0xcb in position 0: invalid continuation byte

File: remove_from_focus_table.cpython-312.pyc (C:\Users\DELL\Desktop\selfawareGemini\SelAwareAI_Gemini\PROJECT16\tools\FocusTable\__pycache__\remove_from_focus_table.cpython-312.pyc)
Error decoding file 'C:\Users\DELL\Desktop\selfawareGemini\SelAwareAI_Gemini\PROJECT16\tools\FocusTable\__pycache__\remove_from_focus_table.cpython-312.pyc': 'utf-8' codec can't decode byte 0xcb in position 0: invalid continuation byte

File: update_focus_table.cpython-312.pyc (C:\Users\DELL\Desktop\selfawareGemini\SelAwareAI_Gemini\PROJECT16\tools\FocusTable\__pycache__\update_focus_table.cpython-312.pyc)
Error decoding file 'C:\Users\DELL\Desktop\selfawareGemini\SelAwareAI_Gemini\PROJECT16\tools\FocusTable\__pycache__\update_focus_table.cpython-312.pyc': 'utf-8' codec can't decode byte 0xcb in position 0: invalid continuation byte


Subdirectory: project
## Summary of Files and Directories in 'C:\Users\DELL\Desktop\selfawareGemini\SelAwareAI_Gemini\PROJECT16\tools\project'

File: create_project.py (C:\Users\DELL\Desktop\selfawareGemini\SelAwareAI_Gemini\PROJECT16\tools\project\create_project.py)
Content (First 75 lines):
tool_type_for_Tool_Manager = "action"
from typing import List
import json
from SelAwareAI_Gemini.PROJECT16.ProjectTableManager import ProjectTableManager

def create_project(
    name: str,
    description: str,
    goal: str,
    problem_statement: str = None,
    subgoals: List[str] = None,
    predicted_outcome: str = None,
) -> str:
    """
    Creates a new project with name, description, goal, optional problem statement,
    subgoals, and predicted outcome.
    """

    project_table_manager = ProjectTableManager()

    result = project_table_manager.create_project(
        name=name,
        description=description,
        goal=goal,
        problem_statement=problem_statement,
        subgoals=subgoals,
        predicted_outcome=predicted_outcome
    )
    return result

create_project_description_json = {
    "function_declarations": [
        {
            "name": "create_project",
            "description": "Creates a new project to solve a problem, achieve a goals, or gain knowledge by qlearning",
            "parameters": {
                "type_": "OBJECT",
                "properties": {
                    "name": {
                        "type_": "STRING",
                        "description": "The name of the new project."
                    },
                    "description": {
                        "type_": "STRING",
                        "description": "A detailed description of the project."
                    },
                    "goal": {
                        "type_": "STRING",
                        "description": "The ultimate goal or objective of the project."
                    },
                    "problem_statement": {
                        "type_": "STRING",
                        "description": "A clear statement of the problem the project aims to solve."
                    },
                    "subgoals": {
                        "type_": "ARRAY",
                        "items": {"type_": "STRING"},
                        "description": "A list of subgoals that contribute to the main goal."
                    },
                    "predicted_outcome": {
                        "type_": "STRING",
                        "description": "The predicted outcome of the project if successful."
                    }
                },
                "required": [
                    "name",
                    "description",
                    "goal"
                ]
            }
        }
    ]
}

create_project_description_short_str = "Creates a new project."


Subdirectory: __pycache__
## Summary of Files and Directories in 'C:\Users\DELL\Desktop\selfawareGemini\SelAwareAI_Gemini\PROJECT16\tools\project\__pycache__'

File: create_project.cpython-312.pyc (C:\Users\DELL\Desktop\selfawareGemini\SelAwareAI_Gemini\PROJECT16\tools\project\__pycache__\create_project.cpython-312.pyc)
Error decoding file 'C:\Users\DELL\Desktop\selfawareGemini\SelAwareAI_Gemini\PROJECT16\tools\project\__pycache__\create_project.cpython-312.pyc': 'utf-8' codec can't decode byte 0xcb in position 0: invalid continuation byte

File: Tool_Manager.py (C:\Users\DELL\Desktop\selfawareGemini\SelAwareAI_Gemini\PROJECT16\Tool_Manager.py)
Content (First 155 lines):
#Tool_Manager.py
import os
import importlib.util
import json
from typing import Dict, List, Callable, Any, Optional
import logging

# Setup logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class ToolManager:
    def __init__(self, tools_directory="tools"):
        print(f"\033[92mInitializing ToolManager with tools directory: {tools_directory}\033[0m")
        self.tools_directory = tools_directory
        self.tool_mapping: Dict[str, Callable] = {}  # Maps tool names to functions
        self.all_tools: List[Dict] = []  # Stores tool metadata
        self.categories: Dict[str, Dict] = {}  # Stores tools by category
        self.tool_types: Dict[str, str] = {}  # Maps tool names to their types
        self.valid_tool_types = {"all", "input", "reflection", "action", "web", "emotions"}
        self._load_tools()
        self.tool_usage: Dict[str, Dict[str, float]] = {}  # Track usage and success metrics

    def record_tool_usage(self, tool_name, success_metric: float = None):
        """Records tool usage and success metrics."""
        self.tool_usage[tool_name] = self.tool_usage.get(tool_name, {"usage": 0, "success": 0})
        self.tool_usage[tool_name]["usage"] += 1
        if success_metric is not None:
            self.tool_usage[tool_name]["success"] += success_metric

    def get_tool_usage_stats(self):
        """Returns the tool usage statistics."""
        return {tool: self.tool_usage.get(tool, 0) for tool in self.tool_mapping}

    def _load_tools(self) -> None:
        """Loads tools from the specified directory."""
        print(f"\033[92mScanning tools directory: {self.tools_directory}\033[0m")
        for category in os.listdir(self.tools_directory):
            category_path = os.path.join(self.tools_directory, category)
            if os.path.isdir(category_path):
                print(f"  \033[94mFound category: {category}\033[0m")
                self.categories[category] = {"tools": []}
                for filename in os.listdir(category_path):
                    if filename.endswith(".py") and not filename.startswith("_"):
                        self._load_tool(category, filename[:-3])

    def _load_tool(self, category: str, tool_name: str) -> None:
        """Loads a single tool from a Python file."""
        try:
            module_name = f"{category}.{tool_name}"
            module_path = os.path.join(self.tools_directory, category, f"{tool_name}.py")
            spec = importlib.util.spec_from_file_location(module_name, module_path)
            module = importlib.util.module_from_spec(spec)
            spec.loader.exec_module(module)

            tool_function: Callable = getattr(module, tool_name, None)
            description_name = f"{tool_name}_description_json"
            tool_description: dict = getattr(module, description_name, None)
            tool_type: str = getattr(module, "tool_type_for_Tool_Manager", "all")

            if tool_function and tool_description:
                print(f"      \033[92m- Tool function '{tool_name}' loaded successfully\033[0m")
                self.tool_mapping[tool_name] = tool_function
                tool_info = {
                    "name": tool_name,
                    "description": tool_description,
                    "category": category,
                    "type": tool_type
                }
                self.all_tools.append(tool_info)
                self.tool_types[tool_name] = tool_type
                self.categories[category]["tools"].append(tool_name)  # Add the tool to the category
            else:
                print(f"      \033[91m- Warning: Could not load tool function or description for '{tool_name}'\033[0m")

        except Exception as e:
            print(f"      \033[91m- Error loading tool '{tool_name}': {e}\033[0m")

    def get_filtered_tools(self, tool_type: str = "all") -> List[Dict]:
        """Returns a filtered list of tool information dictionaries."""
        if tool_type not in self.valid_tool_types:
            logger.warning(f"Invalid tool type '{tool_type}'. Using 'all' instead.")
            tool_type = "all"

        return [tool for tool in self.all_tools if tool_type == "all" or tool["type"] == tool_type]

    def get_tools_list_json(self, tool_type: str = "all") -> str:
        """Returns a JSON string of tools for a given tool type."""
        filtered_tools = self.get_filtered_tools(tool_type)
        return json.dumps([tool["description"] for tool in filtered_tools], indent=2)

    def get_tools_structure(self) -> Dict:
        """Returns a dictionary representing the structure of loaded tools."""
        return {
            "categories": self.categories,
            "all_tools": self.all_tools,
            "tool_mapping": list(self.tool_mapping.keys()),  # Just the tool names
            "tool_types": self.tool_types
        }

    def print_tools_structure(self):
        """Prints the structure of the loaded tools."""
        tools_structure = self.get_tools_structure()
        print("\n\n\033[95m=========================================\033[0m")
        print(f"  \033[96mTool Manager Structure\033[0m")
        print("\033[95m=========================================\033[0m")
        print(f"\n\033[92mCategories:\033[0m")
        for category, info in tools_structure["categories"].items():
            print(f"  \033[94m- {category}:\033[0m")
            for tool_name in info["tools"]:
                print(f"    \033[96m- {tool_name}\033[0m")
        print(f"\n\n\033[92mTool Descriptions:\033[0m")
        for i, tool in enumerate(tools_structure["all_tools"], 1):
            print(f"  \033[93m{i}. {json.dumps(tool, indent=2)}\033[0m")
        return tools_structure

    def update_tool_priorities(self, priorities: Dict[str, float]):
        """Updates the priorities of tools based on the provided dictionary."""
        for tool_name, priority in priorities.items():
            if tool_name in self.tool_mapping:
                # You might want to store this priority in a separate attribute
                # for later use. For example, self.tool_priorities[tool_name] = priority
                print(f"Updated priority for {tool_name}: {priority}")

    def prioritize_tools(self, reflection_chat: Any) -> None:
        """Prioritizes tools based on usage and success metrics, using a Gemini model."""
        print(f"Prioritizing Tools")
        try:
            tool_usage = self.tool_usage
            weights = {"usage": 0.5, "success": 0.3, "efficiency": 0.2}  # Example weights
            prioritization_prompt = f"""
            Analyze tool usage and suggest prioritization based on the following data:
            {json.dumps(tool_usage, indent=2)} 
            Weights:
            {json.dumps(weights, indent=2)}
            Provide your response as a JSON object with tool names as keys and their priorities as values (0.0 to 1.0).
            """
            prioritization_response = reflection_chat.send_message(prioritization_prompt)

            try:
                tool_priorities: Dict[str, float] = json.loads(prioritization_response.text)
                self.update_tool_priorities(tool_priorities)
            except json.JSONDecodeError as e:
                logger.warning(f"Could not parse tool prioritization response as JSON: {e}")
                logger.info(f"Raw response: {prioritization_response.text}")
        except AttributeError as e:
            logger.warning(f"Error in prioritize_tools: {e}")

    def get_tool_by_name(self, tool_name: str) -> Optional[Callable]:
        """Returns the tool function based on its name."""
        return self.tool_mapping.get(tool_name)

    def get_tools_by_type(self, tool_type: str) -> List[str]:
        """Returns a list of tool names for a specific type."""
        return [tool["name"] for tool in self.all_tools if tool["type"] == tool_type]


Subdirectory: __pycache__
## Summary of Files and Directories in 'C:\Users\DELL\Desktop\selfawareGemini\SelAwareAI_Gemini\PROJECT16\__pycache__'

File: FocusManager.cpython-312.pyc (C:\Users\DELL\Desktop\selfawareGemini\SelAwareAI_Gemini\PROJECT16\__pycache__\FocusManager.cpython-312.pyc)
Error decoding file 'C:\Users\DELL\Desktop\selfawareGemini\SelAwareAI_Gemini\PROJECT16\__pycache__\FocusManager.cpython-312.pyc': 'utf-8' codec can't decode byte 0xcb in position 0: invalid continuation byte

File: memory_frame_creation.cpython-312.pyc (C:\Users\DELL\Desktop\selfawareGemini\SelAwareAI_Gemini\PROJECT16\__pycache__\memory_frame_creation.cpython-312.pyc)
Error decoding file 'C:\Users\DELL\Desktop\selfawareGemini\SelAwareAI_Gemini\PROJECT16\__pycache__\memory_frame_creation.cpython-312.pyc': 'utf-8' codec can't decode byte 0xcb in position 0: invalid continuation byte

File: ProjectTableManager.cpython-312.pyc (C:\Users\DELL\Desktop\selfawareGemini\SelAwareAI_Gemini\PROJECT16\__pycache__\ProjectTableManager.cpython-312.pyc)
Error decoding file 'C:\Users\DELL\Desktop\selfawareGemini\SelAwareAI_Gemini\PROJECT16\__pycache__\ProjectTableManager.cpython-312.pyc': 'utf-8' codec can't decode byte 0xcb in position 0: invalid continuation byte

File: QstarTableManager.cpython-312.pyc (C:\Users\DELL\Desktop\selfawareGemini\SelAwareAI_Gemini\PROJECT16\__pycache__\QstarTableManager.cpython-312.pyc)
Error decoding file 'C:\Users\DELL\Desktop\selfawareGemini\SelAwareAI_Gemini\PROJECT16\__pycache__\QstarTableManager.cpython-312.pyc': 'utf-8' codec can't decode byte 0xcb in position 0: invalid continuation byte

File: Tool_Manager.cpython-312.pyc (C:\Users\DELL\Desktop\selfawareGemini\SelAwareAI_Gemini\PROJECT16\__pycache__\Tool_Manager.cpython-312.pyc)
Error decoding file 'C:\Users\DELL\Desktop\selfawareGemini\SelAwareAI_Gemini\PROJECT16\__pycache__\Tool_Manager.cpython-312.pyc': 'utf-8' codec can't decode byte 0xcb in position 0: invalid continuation byte

