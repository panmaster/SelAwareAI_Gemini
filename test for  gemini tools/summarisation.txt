## Summary of Files and Directories in 'C:\Users\DELL\Desktop\selfawareGemini\SelAwareAI_Gemini\test for  gemini tools'

File: artificial_memories_creation________DEVELOPER_TOOL.py (C:\Users\DELL\Desktop\selfawareGemini\SelAwareAI_Gemini\test for  gemini tools\artificial_memories_creation________DEVELOPER_TOOL.py)
Content (First 405 lines):
import google.generativeai as genai
import os
import json
import re
from datetime import datetime
from collections import defaultdict
import time
import random
import pathlib

categories = [
   "coding","ai","agi", "code base","deep learning", "back propagation", "examples", "knowlage base", "jepa", "transfromres","openai"
]

genai.configure(api_key='AIzaSyDRJJmMsB7WQXQ8P0mKTCHf9VIx5uprTw8')  # Replace with your actual API key
BLACK = "\033[30m"
RED = "\033[31m"
GREEN = "\033[32m"
YELLOW = "\033[33m"
BLUE = "\033[34m"
MAGENTA = "\033[35m"
CYAN = "\033[36m"
WHITE = "\033[37m"
RESET = "\033[0m"


def sanitize_href(href, memories_folder_path):
    """Sanitizes a given href string by replacing spaces with %20."""
    href = href.replace(" ", "%20")  # Replace spaces with %20
    return href

def update_html_logs(memory_frame_number, proposed_name, timestamp, memory_frame_paths, memories_folder_path):
    """Updates the HTML log file with CORRECT absolute paths for href links."""
    try:
        log_file_path = os.path.join(memories_folder_path, 'Memory_logs.html')

        if not os.path.exists(log_file_path):
            with open(log_file_path, 'w') as log_file:
                log_file.write("""
                   <!DOCTYPE html>
                   <html>
                   <head>
                       <title>Memory Logs</title>
                   </head>
                   <body>
                       <h1>Memory Logs</h1>
                       <ul>
                   """)

        html_insertion = f"""
               <li><h2>Memory Frame {memory_frame_number:05d} - {proposed_name} ({timestamp})</h2></li>
               <ul>
           """

        for memory_frame_path in memory_frame_paths:
            # Calculate the relative path from the "memories" folder
            relative_path = os.path.relpath(memory_frame_path, memories_folder_path)

            # Construct the href using the relative path
            href = f'memories/{relative_path}'  # Correctly create the relative path

            html_insertion += f"""
                       <li><a href='{href}'>{os.path.basename(href)}</a></li> 
                   """

        html_insertion += "</ul>"

        with open(log_file_path, 'a') as log_file:
            log_file.write(html_insertion)

        print(f"{GREEN}HTML logs updated successfully.{RESET}")
    except Exception as e:
        print(f"Error updating HTML logs: {e}")




# --- Global Variables ---
MEMORY_FRAME_NUMBER = 1
EDIT_NUMBER = 0
counter = 0
TIMESTAMP_FORMAT = '%Y-%m-%d_%H-%M'
print(counter)


def Get_path_of_memories_folder():
    """Returns the absolute path to the 'memories' folder."""
    current = pathlib.Path.cwd()
    memories_path = current / "memories"
    return memories_path.absolute()


path_o_Memories_folder = Get_path_of_memories_folder()

# Example usage:
memories_folder = Get_path_of_memories_folder()
print(f"Memories folder path: {memories_folder}")


def process_user_input():
    global counter
    global categories
    print(f"CREATION OF A  MEMORY = loop  number  {counter}")

    counter = counter + 1
    random_number = random.randint(1, 100)
    randomiser = random_number * random_number - counter + counter * counter
    randomiser_str = str(randomiser)

    prompt_construction = f"{counter} Create  information  base: categories {categories}    randomiser={randomiser_str}   create  exampke code  for  knowlagebase"

    user_input = prompt_construction

    return user_input














def call_interaction_model(user_input, timestamp):
    print(f"\n{CYAN}--- Calling Interaction Model ---{RESET}")
    try:
        interaction_model = genai.GenerativeModel(
            model_name='gemini-1.5-flash-latest',
            safety_settings={'HARASSMENT': 'block_none'},
            system_instruction=""" you fallow user  orders ,Technology adn  CodeBases"""
        )
        chat = interaction_model.start_chat(history=[])
        response = chat.send_message(f"currentTime: {timestamp} create {user_input}")
        print(f"AI Response: {response.text}")
        return response
    except Exception as e:
        print(f"Error in Interaction Model: {e}")
        return None


def call_memory_model(user_input, response1_text):
    print(f"\n{CYAN}--- Calling Memory Model ---{RESET}")
    try:
        memory_model = genai.GenerativeModel(
            model_name='gemini-1.5-flash-latest',
            safety_settings={'HARASSMENT': 'block_none'},
            system_instruction="""You are a sophisticated AI assistant helping to organize memories. 
            Analyze and summarize the above user-AI conversation, focusing on elements that would be most useful for storing and retrieving this memory later. Don't hallucinate. 
            Use the provided JSON schema for your response and fill in all fields with relevant information.
            You can omit entries if they don't seem appropriate for memory storage and would be empty.
            Never omit the "memory_folders_storage" entry.

            **JSON Schema:**

            ```json
            {
              "metadata": {
                "creation_date": "", 
                "source": "", 
                "author": "" 
              },
              "type": "conversation", // OR "technical_concept" 
              "core": {
                "main_topic": "", 
                "category": "", 
                "subcategory": "", 
                "memory_about": "" 
              },
              "summary": {
                "concise_summary": "", 
                "description": "" 
              },
              "content": {
                "keywords": [], 
                "entities": [], 
                "tags": [], 
                "observations": [], 
                "facts": [], 
                "contradictions": [], 
                "paradoxes": [], 
                "scientific_data": [], 
                "visualizations": [] 
              },
              "interaction": {
                "interaction_type": [], 
                "people": [], 
                "objects": [], 
                "animals": [], 
                "actions": [], 
                "observed_interactions": [] 
              },
              "impact": {
                "obtained_knowledge": "", 
                "positive_impact": "", 
                "negative_impact": "", 
                "expectations": "", 
                "strength_of_experience": "" 
              },
              "importance": {
                "reason": "", 
                "potential_uses": [], 
                "importance_level": "0-100" 
              },
              "technical_details": {
                "problem_solved": "", 
                "concept_definition": "", 
                "implementation_steps": [], 
                "tools_and_technologies": [], 
                "example_projects": [], 
                "best_practices": [], 
                "common_challenges": [], 
                "debugging_tips": [], 
                "related_concepts": [], 
                "resources": [], 
                "code_examples": [] 
              },
              "storage": {
                "storage_method": "", 
                "location": "", 
                "memory_folders_storage": [
                  {
                    "folder_path": "", 
                    "probability": 0  
                  }
                ],
                "strength_of_matching_memory_to_given_folder": [] 
              },
              "naming_suggestion": {
                "memory_frame_name": "Give  Same  meaning full name for  Memory File",
                "explanation": "" 
              }
            }
            ```

            **Memory Storage Suggestions:**
            Provide your suggestions for where this memory frame should be stored using the following format within the "memory_folders_storage" field:

            * **"folder_path":** The relative path for storing the memory frame (use '/' as the path separator).
            * **"probability":** The strength of probability (from 0 to 10) that the memory frame should be stored in the suggested folder. Use a scale from 0 (least likely) to 10 (most likely) to express your confidence. 
        """
        )
        chat = memory_model.start_chat(history=[])
        create_memory_prompt = f"User: {user_input}\nAI: {response1_text}"
        response = chat.send_message(create_memory_prompt)
        print(f"Memory Model Response:\n{response.text}")
        return response
    except Exception as e:
        print(f"Error in Memory Model: {e}")
        return None


def extract_entries_smart(response_message):
    """
    Extracts structured entries from the AI response containing JSON data.

    Args:
        response_message (str): The raw text response from the AI model.

    Returns:
        list: A list of dictionaries, where each dictionary represents an extracted entry.
              Returns an empty list if no JSON data is found.
    """
    print("\n--- Extracting Structured Entries ---")
    entries = []
    json_match = re.search(r"```json\n(.*?)\n```", response_message, re.DOTALL)
    if json_match:
        print("Found JSON data in the response.")
        try:
            json_data = json_match.group(1)
            print("Parsing JSON data...")
            response_data = json.loads(json_data)
            print("JSON data parsed successfully.")

            # --- Correctly populate the 'entry' dictionary ---
            entry = defaultdict(lambda: defaultdict(list))
            for key, value in response_data.items():
                if isinstance(value, dict):  # Handle nested dictionaries
                    for sub_key, sub_value in value.items():
                        entry[key][sub_key] = sub_value
                else:
                    entry[key] = value

            print("Handling 'storage' field...")
            entry["storage"] = {
                "storage_method": "",
                "location": "",
                "memory_folders_storage": response_data.get("storage", {}).get("memory_folders_storage", []),
                "strength_of_matching_memory_to_given_folder": []
            }
            print("Validating probabilities in 'memory_folders_storage'...")
            for folder_info in entry["storage"]["memory_folders_storage"]:
                try:
                    probability = folder_info.get("probability")
                    if probability is not None and isinstance(probability, int) and not 0 <= probability <= 10:
                        print(
                            f"Warning: Invalid probability value '{probability}' found in memory_folders_storage. Valid range is 0 to 10."
                        )
                except Exception as e:
                    print(f"Error validating probability in 'memory_folders_storage': {e}")
            print(f"Appending extracted entry: {dict(entry)}")
            entries.append(dict(entry))
        except json.JSONDecodeError:
            print("Error: Invalid JSON in the AI response.")
        except Exception as e:
            print(f"Error extracting entry: {e}")
    return entries





def store_memory_frame(user_input, response1_text, response2_text, memory_data):
    """Saves memory frame data and updates the HTML log."""
    global MEMORY_FRAME_NUMBER, EDIT_NUMBER

    timestamp = datetime.now().strftime(TIMESTAMP_FORMAT)
    proposed_name = memory_data.get("naming_suggestion", {}).get("memory_frame_name", "UnnamedMemory")
    importance = memory_data.get("importance", {}).get("importance_level", "UnknownImportance")

    print(f"\n{YELLOW}--- Storing Memory Frame: {proposed_name} ---{RESET}")

    # Load Connection Map
    connection_map = load_connection_map()

    memory_frame_paths = []
    for folder_info in memory_data.get("storage", {}).get("memory_folders_storage", []):
        folder_path = folder_info.get("folder_path", "")
        probability = folder_info.get("probability", 0)

        target_folder_path = connection_map.get(folder_path, os.path.join(
            os.path.abspath(os.path.dirname(__file__)), "memories", "NewGeneratedbyAI", folder_path
        ))
        # Normalize the target_folder_path:
        target_folder_path = target_folder_path.replace("\\", "/")
        os.makedirs(target_folder_path, exist_ok=True)

        memory_frame_name = (
            f"MemoryFrame_{MEMORY_FRAME_NUMBER:05d}_"
            f"{timestamp}_probabilityOfMatching_{probability}_"
            f"importance_{importance}__{proposed_name}.json"
        )
        memory_frame_path = os.path.join(target_folder_path, memory_frame_name)
        memory_frame_paths.append(memory_frame_path)

        memory_frame_data = {
            "input": user_input,
            "response1": response1_text,
            "response2": response2_text,
            "memory_data": memory_data,
            "timestamp": timestamp,
            "edit_number": EDIT_NUMBER
        }

        try:
            with open(memory_frame_path, 'w') as file:
                json.dump(memory_frame_data, file, indent=4)
            print(f"{GREEN}Memory frame saved successfully at: {memory_frame_path}{RESET}")
        except Exception as e:
            print(f"{RED}Error saving memory frame: {e}{RESET}")

    # Get the full memories folder path
    memories_folder_path = os.path.abspath(os.path.join(os.path.dirname(__file__), "memories"))

    update_html_logs(MEMORY_FRAME_NUMBER, proposed_name, timestamp, memory_frame_paths, memories_folder_path)
    MEMORY_FRAME_NUMBER += 1
    EDIT_NUMBER = 0


def load_connection_map():
    """Loads the folder connection map from the Memory_connections_map.txt file."""
    connection_map = {}
    try:
        script_path = os.path.abspath(os.path.dirname(__file__))
        connection_map_path = os.path.join(script_path, "memories", "Memory_connections_map.txt")
        with open(connection_map_path, 'r') as file:
            for line in file:
                if line.strip():
                    parts = line.split("****")
                    if len(parts) >= 3:
                        folder_name = parts[0].strip()
                        folder_path = parts[2].strip().replace("Path: ", "")
                        # Normalize the folder path:
                        folder_path = folder_path.replace("//", "/").replace("\\", "/")
                        connection_map[folder_name] = folder_path
    except FileNotFoundError:
        print(f"{RED}Error: Connection map file not found.{RESET}")
    return connection_map


counter = 0
while True:
    user_input = process_user_input()
    timestamp = datetime.now().strftime(TIMESTAMP_FORMAT)
    response1 = call_interaction_model(user_input, timestamp)
    if response1:
        response2 = call_memory_model(user_input, response1.text)
        if response2:
            memory_entries = extract_entries_smart(response2.text)
            for entry in memory_entries:
                store_memory_frame(user_input, response1.text, response2.text, entry)  # Removed the 'check' comment

File: MEMORY_frame_creation.py (C:\Users\DELL\Desktop\selfawareGemini\SelAwareAI_Gemini\test for  gemini tools\MEMORY_frame_creation.py)
Content (First 398 lines):

import google.generativeai as genai



genai.configure(api_key='AIzaSyDRJJmMsB7WQXQ8P0mKTCHf9VIx5uprTw8')  # Replace with your actual API key
import os
import re
import json
import pathlib
from datetime import datetime
from collections import defaultdict


BLACK = "\033[30m"
RED = "\033[31m"
GREEN = "\033[32m"
YELLOW = "\033[33m"
BLUE = "\033[34m"
MAGENTA = "\033[35m"
CYAN = "\033[36m"
WHITE = "\033[37m"
RESET = "\033[0m"
BOLD = "\033[1m"
UNDERLINE = "\033[4m"
REVERSE = "\033[7m"

MEMORY_FRAME_NUMBER = 1
EDIT_NUMBER = 0
TIMESTAMP_FORMAT = '%Y-%m-%d_%H-%M'

def sanitize_href(href, memories_folder_path):
    """Sanitizes a given href string by replacing spaces with %20."""
    href = href.replace(" ", "%20")
    return href

def update_html_logs(memory_frame_number, proposed_name, timestamp, memory_frame_paths, memories_folder_path):
    """Updates the HTML log file with CORRECT absolute paths for href links."""
    try:
        log_file_path = os.path.join(memories_folder_path, 'Memory_logs.html')

        if not os.path.exists(log_file_path):
            with open(log_file_path, 'w') as log_file:
                log_file.write("""
                   <!DOCTYPE html>
                   <html>
                   <head>
                       <title>Memory Logs</title>
                   </head>
                   <body>
                       <h1>Memory Logs</h1>
                       <ul>
                   """)

        html_insertion = f"""
               <li><h2>Memory Frame {memory_frame_number:05d} - {proposed_name} ({timestamp})</h2></li>
               <ul>
           """

        for memory_frame_path in memory_frame_paths:
            relative_path = os.path.relpath(memory_frame_path, memories_folder_path)
            href = sanitize_href(relative_path, memories_folder_path)
            html_insertion += f"""
                       <li><a href='{href}'>{os.path.basename(href)}</a></li> 
                   """

        html_insertion += "</ul>"

        with open(log_file_path, 'a') as log_file:
            log_file.write(html_insertion)

        print(f"{GREEN}HTML logs updated successfully.{RESET}")
    except Exception as e:
        print(f"Error updating HTML logs: {e}")

def Get_path_of_memories_folder():
    """Returns the absolute path to the 'memories' folder."""
    current = pathlib.Path.cwd()
    memories_path = current / "memories"
    return memories_path.absolute()

def process_user_input():
    user_input = input(f"{GREEN}Enter input: {RESET}")
    print(f"{MAGENTA}User input received: {user_input}{RESET}")
    return user_input

def call_interaction_model(user_input, timestamp):
    print(f"\n{CYAN}--- Calling Interaction Model ---{RESET}")
    try:
        interaction_model = genai.GenerativeModel(
            model_name='gemini-1.5-flash-latest',
            safety_settings={'HARASSMENT': 'block_none'},
            system_instruction='You follow orders and generate creative text interactions'
        )
        chat = interaction_model.start_chat(history=[])
        response = chat.send_message(f"currentTime: {timestamp} create {user_input}")
        print(f"AI Response: {response.text}")
        return response
    except Exception as e:
        print(f"Error in Interaction Model: {e}")
        return None

def call_memory_model(user_input, response1_text):
    print(f"\n{CYAN}--- Calling Memory Model ---{RESET}")
    try:
        memory_model = genai.GenerativeModel(
            model_name='gemini-1.5-flash-latest',
            safety_settings={'HARASSMENT': 'block_none'},
            system_instruction="""You are a sophisticated AI assistant helping to organize memories. 
            Analyze and summarize the above user-AI conversation, focusing on elements that would be most useful for storing and retrieving this memory later. Don't hallucinate. 
            Use the provided JSON schema for your response and fill in all fields with relevant information.
            You can omit entries if they don't seem appropriate for memory storage and would be empty.
            Never omit the "memory_folders_storage" entry.

            **JSON Schema:**

            ```json
            {
              "metadata": {
                "creation_date": "", 
                "source": "", 
                "author": "" 
              },
              "type": "conversation", // OR "technical_concept" 
              "core": {
                "main_topic": "", 
                "category": "", 
                "subcategory": "", 
                "memory_about": "" 
              },
              "summary": {
                "concise_summary": "", 
                "description": "" 
              },
              "content": {
                "keywords": [], 
                "entities": [], 
                "tags": [], 
                "observations": [], 
                "facts": [], 
                "contradictions": [], 
                "paradoxes": [], 
                "scientific_data": [], 
                "visualizations": [] 
              },
              "interaction": {
                "interaction_type": [], 
                "people": [], 
                "objects": [], 
                "animals": [], 
                "actions": [], 
                "observed_interactions": [] 
              },
              "impact": {
                "obtained_knowledge": "", 
                "positive_impact": "", 
                "negative_impact": "", 
                "expectations": "", 
                "strength_of_experience": "" 
              },
              "importance": {
                "reason": "", 
                "potential_uses": [], 
                "importance_level": "0-100" 
              },
              "technical_details": {
                "problem_solved": "", 
                "concept_definition": "", 
                "implementation_steps": [], 
                "tools_and_technologies": [], 
                "example_projects": [], 
                "best_practices": [], 
                "common_challenges": [], 
                "debugging_tips": [], 
                "related_concepts": [], 
                "resources": [], 
                "code_examples": [] 
              },
              "storage": {
                "storage_method": "", 
                "location": "", 
                "memory_folders_storage": [
                  {
                    "folder_path": "", 
                    "probability": 0  
                  }
                ],
                "strength_of_matching_memory_to_given_folder": [] 
              },
              "naming_suggestion": {
                "memory_frame_name": "Give  Same  meaning full name for  Memory File",
                "explanation": "" 
              }
            }
            ```

            **Memory Storage Suggestions:**
            Provide your suggestions for where this memory frame should be stored using the following format within the "memory_folders_storage" field:

            * **"folder_path":** The relative path for storing the memory frame (use '/' as the path separator).
            * **"probability":** The strength of probability (from 0 to 10) that the memory frame should be stored in the suggested folder. Use a scale from 0 (least likely) to 10 (most likely) to express your confidence. 
        """
        )
        chat = memory_model.start_chat(history=[])
        create_memory_prompt = f"User: {user_input}\nAI: {response1_text}"
        response = chat.send_message(create_memory_prompt)
        print(f"Memory Model Response:\n{response.text}")
        return response
    except Exception as e:
        print(f"Error in Memory Model: {e}")
        return None

def extract_entries_smart(response_message):
    print("\n--- Extracting Structured Entries ---")
    entries = []
    json_match = re.search(r"```json\n(.*?)\n```", response_message, re.DOTALL)
    if json_match:
        print("Found JSON data in the response.")
        try:
            json_data = json_match.group(1)
            print("Parsing JSON data...")
            response_data = json.loads(json_data)
            print("JSON data parsed successfully.")
            single_value_fields = {
                "metadata.creation_date": "metadata",
                "metadata.source": "metadata",
                "metadata.author": "metadata",
                "type": "core",
                "core.main_topic": "core",
                "core.category": "core",
                "core.subcategory": "core",
                "core.memory_about": "core",
                "summary.concise_summary": "summary",
                "summary.description": "summary",
                "impact.obtained_knowledge": "impact",
                "impact.positive_impact": "impact",
                "impact.negative_impact": "impact",
                "impact.expectations": "impact",
                "impact.strength_of_experience": "impact",
                "importance.reason": "importance",
                "importance.importance_level": "importance",
                "technical_details.problem_solved": "technical_details",
                "naming_suggestion.memory_frame_name": "naming_suggestion",
                "naming_suggestion.explanation": "naming_suggestion"
            }
            list_type_fields = {
                "content.keywords": "content",
                "content.entities": "content",
                "content.tags": "content",
                "content.observations": "content",
                "content.facts": "content",
                "content.contradictions": "content",
                "content.paradoxes": "content",
                "content.scientific_data": "content",
                "content.visualizations": "content",
                "interaction.interaction_type": "interaction",
                "interaction.people": "interaction",
                "interaction.objects": "interaction",
                "interaction.animals": "interaction",
                "interaction.actions": "interaction",
                "interaction.observed_interactions": "interaction",
                "importance.potential_uses": "importance",
                "technical_details.implementation_steps": "technical_details",
                "technical_details.tools_and_technologies": "technical_details",
                "technical_details.example_projects": "technical_details",
                "technical_details.best_practices": "technical_details",
                "technical_details.common_challenges": "technical_details",
                "technical_details.debugging_tips": "technical_details",
                "technical_details.related_concepts": "technical_details",
                "technical_details.resources": "technical_details",
                "technical_details.code_examples": "technical_details"
            }
            print("Extracting entries from JSON data...")
            for key, value in response_data.items():
                entry = defaultdict(list)
                if key in single_value_fields:
                    print(f"Processing single value field: {key}")
                    field_name = key.split('.')[-1]
                    section = single_value_fields[key]
                    if not isinstance(section, list):
                        section = [section]
                    try:
                        entry[section[0]][field_name] = value if not isinstance(value, list) else (
                            value[0] if value else ""
                        )
                    except IndexError as e:
                        print(f"Error accessing field: {key}. Details: {e}")
                    except Exception as e:
                        print(f"Unexpected error processing single value field '{key}': {e}")
                elif key in list_type_fields:
                    print(f"Processing list type field: {key}")
                    field_name = key.split('.')[-1]
                    section = list_type_fields[key]
                    try:
                        entry[section][field_name].extend(value if isinstance(value, list) else [value])
                    except Exception as e:
                        print(f"Unexpected error processing list type field '{key}': {e}")
            print("Handling 'storage' field...")
            entry["storage"] = {
                "storage_method": "",
                "location": "",
                "memory_folders_storage": response_data.get("storage", {}).get("memory_folders_storage", []),
                "strength_of_matching_memory_to_given_folder": []
            }
            print("Validating probabilities in 'memory_folders_storage'...")
            for folder_info in entry["storage"]["memory_folders_storage"]:
                try:
                    probability = folder_info.get("probability")
                    if probability is not None and isinstance(probability, int) and not 0 <= probability <= 10:
                        print(
                            f"Warning: Invalid probability value '{probability}' found in memory_folders_storage. Valid range is 0 to 10."
                        )
                except Exception as e:
                    print(f"Error validating probability in 'memory_folders_storage': {e}")
            print(f"Appending extracted entry: {dict(entry)}")
            entries.append(dict(entry))
        except json.JSONDecodeError:
            print("Error: Invalid JSON in the AI response.")
        except Exception as e:
            print(f"Error extracting entry: {e}")
    return entries


def store_memory_frame(user_input, response1_text, response2_text, memory_data):
    global MEMORY_FRAME_NUMBER, EDIT_NUMBER
    print(f"\n{YELLOW}--- Storing Memory Frame ---{RESET}")
    connection_map = {}
    memories_folder_path = Get_path_of_memories_folder()
    memory_frame_paths = []

    try:
        script_path = os.path.abspath(os.path.dirname(__file__))
        connection_map_path = os.path.join(script_path, "memories", "Memory_connections_map.txt")
        with open(connection_map_path, 'r') as file:
            content = file.read()
            folder_matches = re.findall(r'\*\*\*\*(.*?)\*\*\*\*(.*?)Path:\s*(.*?)\n', content, re.DOTALL)
            for match in folder_matches:
                folder_name, folder_info, folder_path = match
                connection_map[folder_name.strip()] = folder_path.strip()
    except FileNotFoundError:
        print("Error: Connection map file not found.")

    storage_folders = memory_data.get("storage", {}).get("memory_folders_storage", [])
    print(f"Suggested storage folders: {storage_folders}")
    timestamp = datetime.now().strftime(TIMESTAMP_FORMAT)
    proposed_name = memory_data.get("naming_suggestion", {}).get("memory_frame_name", "UnnamedMemory")
    importance = memory_data.get("importance", {}).get("importance_level", "UnknownImportance")

    for folder_info in storage_folders:
        folder_path = folder_info.get("folder_path", "")
        probability = folder_info.get("probability", 0)
        print(f"Processing folder: {folder_path} (Probability: {probability})")
        if folder_path in connection_map:
            print(f"Folder '{folder_path}' found in connection map.")
            target_folder_path = connection_map[folder_path]
        else:
            print(f"Folder '{folder_path}' not in connection map. Creating in 'NewGeneratedbyAI'...")
            target_folder_path = os.path.join(script_path, "memories", "NewGeneratedbyAI", folder_path)
            os.makedirs(target_folder_path, exist_ok=True)
        highest_probability = max([folder.get("probability", 0) for folder in storage_folders], default=0)

        # Improved filename structure
        memory_frame_name = f"{proposed_name}_MemoryFrame_{MEMORY_FRAME_NUMBER:05d}_{timestamp}_Probability_{highest_probability}_Importance_{importance}.json"
        memory_frame_path = os.path.join(target_folder_path, memory_frame_name)
        print(f"Memory frame name: {memory_frame_name}")
        print(f"Memory frame path: {memory_frame_path}")
        memory_frame_data = {
            "input": user_input,
            "response1": response1_text,
            "response2": response2_text,
            "memory_data": memory_data,
            "timestamp": timestamp,
            "edit_number": EDIT_NUMBER
            # ... (Add other fields as needed) ...
        }
        try:
            with open(memory_frame_path, 'w') as file:
                json.dump(memory_frame_data, file, indent=4)
            print(f"{YELLOW}Memory frame saved successfully at: {memory_frame_path}{RESET}")
            memory_frame_paths.append(memory_frame_path)
        except Exception as e:
            print(f"Error saving memory frame: {e}")

    update_html_logs(MEMORY_FRAME_NUMBER, proposed_name, timestamp, memory_frame_paths, memories_folder_path)

    MEMORY_FRAME_NUMBER += 1
    EDIT_NUMBER = 0

while True:
    user_input = process_user_input()
    timestamp = datetime.now().strftime(TIMESTAMP_FORMAT)
    response1 = call_interaction_model(user_input, timestamp)
    if response1:
        response2 = call_memory_model(user_input, response1.text)
        if response2:
            memory_entries = extract_entries_smart(response2.text)
            for entry in memory_entries:
                store_memory_frame(user_input, response1.text, response2.text, entry)

File: MEMORY_initializer.py (C:\Users\DELL\Desktop\selfawareGemini\SelAwareAI_Gemini\test for  gemini tools\MEMORY_initializer.py)
Content (First 10 lines):
import os
from collections import defaultdict
from fuzzywuzzy import fuzz
from datetime import datetime
import sys
import  json
memory_templates = {
"CoreMemory": {
"structure": {
"Core Experiences": {


File: MEMORY_retrival4.py (C:\Users\DELL\Desktop\selfawareGemini\SelAwareAI_Gemini\test for  gemini tools\MEMORY_retrival4.py)
Content (First 517 lines):
import os
import json
import re
from collections import defaultdict

import nltk
from nltk.corpus import stopwords
from nltk.stem import PorterStemmer
import spacy
from whoosh import index
from whoosh.fields import Schema, TEXT, ID, NUMERIC, KEYWORD
from whoosh.qparser import MultifieldParser, QueryParser
from whoosh.analysis import StandardAnalyzer
from fuzzywuzzy import fuzz, process
from colorama import Fore, Style

# Use SpaCy for word embeddings and similarity calculations
try:
    nlp = spacy.load("en_core_web_md")  # Use 'md' or 'lg' for word vectors
except OSError:
    os.system("python -m spacy download en_core_web_md")
    nlp = spacy.load("en_core_web_md")

nltk.download('stopwords', quiet=True)
nltk.download('punkt', quiet=True)

def create_schema():
    """Defines the schema for the Whoosh index."""
    print(f"{Fore.CYAN}--- Creating Schema ---{Style.RESET_ALL}")
    return Schema(
        filepath=ID(stored=True),
        creation_date=TEXT(stored=True),
        concise_summary=TEXT(stored=True),
        description=TEXT(analyzer=StandardAnalyzer(), stored=True),
        keywords=KEYWORD(commas=True, scorable=True),
        entities=KEYWORD(commas=True, scorable=True),
        main_topic=TEXT(stored=True),
        input=TEXT(stored=True),
        response1=TEXT(stored=True),
        response2=TEXT(stored=True),
        importance_level=NUMERIC(stored=True),
        strength_of_matching=NUMERIC(stored=True),
        storage_method=TEXT(stored=True),
        location=TEXT(stored=True),
        memory_folders_storage=KEYWORD(commas=True, stored=True),
        memory_frame_name=TEXT(stored=True),
        frame_name_keywords=KEYWORD(commas=True, scorable=True),
        linked_concepts=KEYWORD(commas=True, scorable=True)
    )


def load_connection_map(connection_map_path):
    """Loads the connection map from the specified file."""
    connection_map = defaultdict(list)
    print(f"{Fore.CYAN}--- Loading Connection Map ---{Style.RESET_ALL}")
    if os.path.exists(connection_map_path):
        with open(connection_map_path, 'r', encoding='utf-8') as file:
            content = file.read()
            folder_matches = re.findall(
                r'\*\*\*\*(.*?)\*\*\*\*(.*?)Path:\s*(.*?)\n',
                content,
                re.DOTALL
            )
            for match in folder_matches:
                folder_name, _, folder_path = match
                connection_map[folder_name.strip()].append(
                    folder_path.strip()
                )
                print(
                    f"{Fore.GREEN}Folder: {folder_name.strip()} => Path: "
                    f"{folder_path.strip()}{Style.RESET_ALL}"
                )
    return connection_map


def build_knowledge_graph(connection_map):
    """Builds a knowledge graph from the connection map."""
    print(f"{Fore.CYAN}--- Building Knowledge Graph ---{Style.RESET_ALL}")
    graph = {}
    for concept, paths in connection_map.items():
        graph[concept] = set()
        for path in paths:
            terms = path.split("/")
            for term in terms:
                graph[concept].add(term)
    return graph


def index_memory_frames(schema, index_dir, connection_map):
    """Indexes the memory frames from the 'memories' folder."""
    if not os.path.exists(index_dir):
        os.mkdir(index_dir)

    ix = index.create_in(index_dir, schema)
    writer = ix.writer()

    frames_indexed = 0
    print(f"{Fore.CYAN}--- Indexing Memory Frames ---{Style.RESET_ALL}")
    for root, _, files in os.walk("memories"):
        for file in files:
            if file.endswith(".json"):
                file_path = os.path.join(root, file)
                print(f"{Fore.GREEN}Indexing Frame: {file_path}{Style.RESET_ALL}")

                try:
                    with open(file_path, 'r', encoding='utf-8') as json_file:
                        frame_data = json.load(json_file)
                        memory_data = frame_data.get('memory_data', {})

                        importance_level = int(memory_data.get(
                            'importance', {}
                        ).get('importance_level', '0'))
                        strength_of_matching = int(memory_data.get(
                            'storage', {}
                        ).get('memory_folders_storage', [{
                            'probability': '0'
                        }])[0].get('probability', '0'))
                        folder_paths = ",".join(
                            f["folder_path"] for f in memory_data.get(
                                'storage', {}
                            ).get('memory_folders_storage', [])
                        )

                        memory_frame_name = memory_data.get(
                            'naming_suggestion', {}
                        ).get('memory_frame_name', 'N/A')
                        frame_name_keywords = extract_keywords_from_name(
                            memory_frame_name
                        )

                        entities = memory_data.get('content', {}).get(
                            'entities', []
                        )
                        entities_list = [
                            e if isinstance(e, str) else str(e)
                            for e in entities
                        ]

                        extracted_content = []

                        def extract_text(data):
                            """Recursively extracts text from the data."""
                            if isinstance(data, str):
                                extracted_content.append(data)
                            elif isinstance(data, list):
                                for item in data:
                                    extract_text(item)
                            elif isinstance(data, dict):
                                for key, value in data.items():
                                    extract_text(key)
                                    extract_text(value)

                        extract_text(frame_data)
                        all_content = " ".join(extracted_content)

                        knowledge_graph = build_knowledge_graph(
                            connection_map
                        )
                        linked_concepts = []
                        for concept, related_terms in knowledge_graph.items():
                            extracted_content = []
                            extract_text(frame_data)
                            if any(
                                term in related_terms
                                for term in extracted_content
                            ):
                                linked_concepts.append(concept)

                        writer.add_document(
                            filepath=file_path,
                            creation_date=memory_data.get(
                                'metadata', {}
                            ).get('creation_date', 'N/A'),
                            concise_summary=memory_data.get(
                                'summary', {}
                            ).get('concise_summary', 'N/A'),
                            description=all_content,
                            keywords=",".join(memory_data.get(
                                'content', {}
                            ).get('keywords', [])),
                            entities=",".join(entities_list),
                            main_topic=memory_data.get(
                                'core', {}
                            ).get('main_topic', ''),
                            input=frame_data.get('input', ''),
                            response1=frame_data.get('response1', ''),
                            response2=frame_data.get('response2', ''),
                            importance_level=importance_level,
                            strength_of_matching=strength_of_matching,
                            storage_method=memory_data.get(
                                'storage', {}
                            ).get('storage_method', 'N/A'),
                            location=memory_data.get(
                                'storage', {}
                            ).get('location', 'N/A'),
                            memory_folders_storage=folder_paths,
                            memory_frame_name=memory_frame_name,
                            frame_name_keywords=",".join(
                                frame_name_keywords
                            ),
                            linked_concepts=",".join(linked_concepts)
                        )
                        frames_indexed += 1
                except json.JSONDecodeError as e:
                    print(
                        f"{Fore.RED}Error decoding JSON file {file_path}: {e}{Style.RESET_ALL}"
                    )

    writer.commit()
    print(f"\n{Fore.GREEN}Indexed {frames_indexed} memory frames.{Style.RESET_ALL}")
    return ix

def search_memory_frames(ix, query, knowledge_graph, fuzzy_threshold=80):
    """Searches the memory frames based on the given query."""
    print(f"{Fore.CYAN}--- Searching Memory Frames ---{Style.RESET_ALL}")
    with ix.searcher() as searcher:
        try:
            parser = MultifieldParser(
                [
                    "description",
                    "input",
                    "response1",
                    "response2",
                    "linked_concepts"
                ],
                schema=ix.schema
            )
            processed_query = preprocess_text(query)

            fuzzy_terms = []
            for term in processed_query.split():
                combined_lexicon = set()
                for field in [
                    "description",
                    "input",
                    "response1",
                    "response2"
                ]:
                    combined_lexicon.update(searcher.lexicon(field))

                fuzzy_matches = process.extractBests(
                    term,
                    combined_lexicon,
                    scorer=fuzz.token_sort_ratio,
                    score_cutoff=fuzzy_threshold,
                    limit=3
                )
                fuzzy_terms.extend(
                    [match[0] for match in fuzzy_matches]
                )

            if fuzzy_terms:
                fuzzy_query = " OR ".join(
                    [str(term, 'utf-8') for term in fuzzy_terms]
                )
                parser = QueryParser("description", schema=ix.schema)
                fuzzy_q = parser.parse(fuzzy_query)
                processed_query = (
                    f"{processed_query} OR {fuzzy_q}"
                )

            # Calculate query embedding using SpaCy
            query_doc = nlp(processed_query)

            concept_similarities = {}
            for concept in knowledge_graph:
                try:
                    concept_doc = nlp(concept)
                    similarity = query_doc.similarity(concept_doc)
                    concept_similarities[concept] = similarity
                except Exception as e:
                    print(f"{Fore.RED}Error calculating similarity: {e}{Style.RESET_ALL}")
                    pass  

            sorted_concepts = sorted(
                concept_similarities,
                key=concept_similarities.get,
                reverse=True
            )

            latent_space_query = " OR ".join(
                [f'linked_concepts:"{concept}"'
                 for concept in sorted_concepts]
            )
            combined_query = (
                f"{processed_query} OR ({latent_space_query})"
            )

            myquery = parser.parse(combined_query)
            results = searcher.search(myquery, limit=None)

            # Modify the results (create copies)
            modified_results = []
            for result in results:
                modified_result = dict(result)  # Create a copy
                for field in [
                    "description",
                    "input",
                    "response1",
                    "response2"
                ]:
                    content = modified_result.get(field, '') 
                    for term in processed_query.split():
                        highlighted_content = re.sub(
                            rf"\b({re.escape(term)})\b",
                            rf"{Fore.RED}\1{Style.RESET_ALL}",
                            content,
                            flags=re.IGNORECASE
                        )
                        modified_result[field] = highlighted_content
                modified_results.append(modified_result) 

            return modified_results 

        except Exception as e:
            print(f"{Fore.RED}An error occurred during search: {e}{Style.RESET_ALL}")
            return []


def preprocess_text(text):
    """Preprocesses the text for searching."""
    print(f"{Fore.CYAN}--- Preprocessing Text ---{Style.RESET_ALL}")
    stemmer = PorterStemmer()
    stop_words = set(stopwords.words('english'))
    words = nltk.word_tokenize(text)
    processed_words = [
        stemmer.stem(word.lower())
        if word.lower() not in ["deep learning"]
        else word.lower()
        for word in words
        if word.lower() not in stop_words
    ]
    return " ".join(processed_words)


def retrieve_contextual_frames(
    memory_frames,
    main_frame_index,
    num_frames_before=1,
    num_frames_after=1
):
    """Retrieves contextual frames around a given frame."""
    print(f"{Fore.CYAN}--- Retrieving Contextual Frames ---{Style.RESET_ALL}")
    selected_frames = []
    start_index = max(0, main_frame_index - num_frames_before)
    end_index = min(
        len(memory_frames), main_frame_index + num_frames_after + 1
    )
    selected_frames.extend(memory_frames[start_index:end_index])
    return selected_frames


def find_similar_folders(connection_map, query, threshold=80):
    """Finds similar folders based on the query."""
    print(f"{Fore.CYAN}--- Finding Similar Folders ---{Style.RESET_ALL}")
    similar_folders = {}
    for folder_name, folder_paths in connection_map.items():
        similarity_score = fuzz.token_sort_ratio(folder_name, query)
        if similarity_score >= threshold:
            similar_folders[folder_name] = folder_paths
    return similar_folders


def retrieve_by_importance(memory_frames, threshold=50):
    """Retrieves frames based on importance level."""
    print(f"{Fore.CYAN}--- Retrieving by Importance ---{Style.RESET_ALL}")
    return [
        frame
        for frame in memory_frames
        if frame.get('importance_level', 0) >= threshold
    ]


def retrieve_by_strength(memory_frames, threshold=50):
    """Retrieves frames based on strength of matching."""
    print(f"{Fore.CYAN}--- Retrieving by Strength ---{Style.RESET_ALL}")
    return [
        frame
        for frame in memory_frames
        if frame.get('strength_of_matching', 0) >= threshold
    ]


def retrieve_by_folder_match(connection_map, query, threshold=80):
    """Retrieves frames based on folder matching."""
    print(f"{Fore.CYAN}--- Retrieving by Folder Match ---{Style.RESET_ALL}")
    return find_similar_folders(connection_map, query, threshold)


def analyze_query_in_context(connection_map, query):
    """Analyzes the query in the context of the connection map."""
    print(f"{Fore.CYAN}--- Analyzing Query in Context ---{Style.RESET_ALL}")
    matching_folders = find_similar_folders(connection_map, query)

    if matching_folders:
        print(f"{Fore.GREEN}Query '{query}' found in the following categories:{Style.RESET_ALL}")
        for folder_name, paths in matching_folders.items():
            print(f"{Fore.BLUE}  Category: {folder_name}{Style.RESET_ALL}")
            print(f"{Fore.BLUE}    Paths: {paths}{Style.RESET_ALL}")
    else:
        print(f"{Fore.RED}Query '{query}' not found in any specific category.{Style.RESET_ALL}")


def extract_keywords_from_name(frame_name):
    """Extracts keywords from the frame name using spaCy."""
    print(f"{Fore.CYAN}--- Extracting Keywords from Name ---{Style.RESET_ALL}")
    doc = nlp(frame_name)
    keywords = [
        token.text
        for token in doc
        if token.pos_ in {"NOUN", "PROPN", "ADJ"}
    ]
    return keywords


def path_based_retrieval(connection_map, query, threshold=80):
    """Performs path-based retrieval using fuzzy matching."""
    print(f"{Fore.CYAN}--- Path-Based Retrieval ---{Style.RESET_ALL}")
    matching_paths = []

    for folder_name, folder_paths in connection_map.items():
        for path in folder_paths:
            path_terms = path.split('/')
            similarity_score = 0
            for term in path_terms:
                similarity_score += fuzz.token_sort_ratio(term, query)
            if similarity_score / len(path_terms) >= threshold:
                matching_paths.append(path)

    if matching_paths:
        print(f"{Fore.GREEN}Matching paths for '{query}':{Style.RESET_ALL}")
        for path in matching_paths:
            print(f"{Fore.BLUE}  {path}{Style.RESET_ALL}")
    else:
        print(f"{Fore.RED}No matching paths found for '{query}'.{Style.RESET_ALL}")

    return matching_paths


def process_retrieval(connection_map, ix, knowledge_graph):
    """Handles the memory retrieval process."""
    print(f"{Fore.CYAN}--- Memory Retrieval Process ---{Style.RESET_ALL}")
    while True:
        user_query = input("Enter your memory query: ")
        analyze_query_in_context(connection_map, user_query)
        print(f"{Fore.CYAN}--- Searching All Frames ---{Style.RESET_ALL}")

        with ix.searcher() as searcher:
            results = search_memory_frames(
                ix, user_query, knowledge_graph
            )

        if results:
            print(f"\n{Fore.GREEN}Retrieved {len(results)} memory frames:{Style.RESET_ALL}")
            results.sort(
                key=lambda x: x['strength_of_matching'],
                reverse=True
            )
            for i, frame in enumerate(results):
                folders_storage = frame['memory_folders_storage']
                print(f"{Fore.BLUE}{i+1}. Frame: {frame}{Style.RESET_ALL}")
                print(
                    f"   {Fore.GREEN}Folders: "
                    f"{folders_storage}{Style.RESET_ALL}"
                )
        else:
            print(f"{Fore.RED}No memory frames found matching the query.{Style.RESET_ALL}")

        matching_paths = path_based_retrieval(
            connection_map, user_query
        )

        if matching_paths:
            print(f"{Fore.CYAN}--- Searching Frames in Matching Paths ---{Style.RESET_ALL}")
            # Implement logic to search within matching paths

        if input("Continue searching? (y/n): ").lower() != 'y':
            break


def main():
    """Main function for memory retrieval system."""
    print(f"{Fore.CYAN}--- Memory Retrieval System ---{Style.RESET_ALL}")
    script_path = os.path.abspath(os.path.dirname(__file__))
    connection_map_path = os.path.join(
        script_path,
        "memories",
        "Memory_connections_map.txt"
    )
    index_dir = os.path.join(script_path, "memory_index")

    print(f"Current directory: {script_path}")
    print(f"Connection map path: {connection_map_path}")

    # Load the connection map
    connection_map = load_connection_map(connection_map_path)
    knowledge_graph = build_knowledge_graph(connection_map)

    # Create/load the Whoosh index
    if not os.path.exists(index_dir):
        print(f"Creating new index at: {index_dir}")
        os.mkdir(index_dir)
        schema = create_schema()
        ix = index.create_in(index_dir, schema)
        index_memory_frames(schema, index_dir, connection_map)
    else:
        print(f"Loading existing index from: {index_dir}")
        ix = index.open_dir(index_dir)

    try:
        process_retrieval(connection_map, ix, knowledge_graph)
    finally:
        ix.close()


if __name__ == "__main__":
    main()

